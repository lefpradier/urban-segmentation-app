{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.append(\"src/data_structure/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**init**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} initialisation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**holdout**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tubingen', 'zurich', 'erfurt', 'jena')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = \"data/raw/P8_Cityscapes_leftImg8bit_trainvaltest/leftImg8bit\"\n",
    "mask_dir = \"data/raw/P8_Cityscapes_gtFine_trainvaltest/gtFine\"\n",
    "\n",
    "utils.holdout(image_dir, mask_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ModÃ¨le simple**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model whithout data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-18 12:18:12.211775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-18 12:18:12.645840: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-18 12:18:12.645897: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-18 12:18:12.645904: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/18 12:18:14 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/18 12:18:14 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_1 (Conv2D)               (None, 128, 256, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_2 (Conv2D)               (None, 128, 256, 32  9248        ['conv1_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool_1 (MaxPooling2D)          (None, 64, 128, 32)  0           ['conv1_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2_1 (Conv2D)               (None, 64, 128, 64)  18496       ['pool_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2_2 (Conv2D)               (None, 64, 128, 64)  36928       ['conv2_1[0][0]']                \n",
      "                                                                                                  \n",
      " pool_2 (MaxPooling2D)          (None, 32, 64, 64)   0           ['conv2_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv3_1 (Conv2D)               (None, 32, 64, 128)  73856       ['pool_2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv3_2 (Conv2D)               (None, 32, 64, 128)  147584      ['conv3_1[0][0]']                \n",
      "                                                                                                  \n",
      " pool_3 (MaxPooling2D)          (None, 16, 32, 128)  0           ['conv3_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv4_1 (Conv2D)               (None, 16, 32, 256)  295168      ['pool_3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv4_2 (Conv2D)               (None, 16, 32, 256)  590080      ['conv4_1[0][0]']                \n",
      "                                                                                                  \n",
      " upconv5_1 (UpSampling2D)       (None, 32, 64, 256)  0           ['conv4_2[0][0]']                \n",
      "                                                                                                  \n",
      " upconv5_2 (Conv2D)             (None, 32, 64, 128)  131200      ['upconv5_1[0][0]']              \n",
      "                                                                                                  \n",
      " concat_5 (Concatenate)         (None, 32, 64, 256)  0           ['upconv5_2[0][0]',              \n",
      "                                                                  'conv3_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv5_1 (Conv2D)               (None, 32, 64, 128)  295040      ['concat_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv5_2 (Conv2D)               (None, 32, 64, 128)  147584      ['conv5_1[0][0]']                \n",
      "                                                                                                  \n",
      " upconv6_1 (UpSampling2D)       (None, 64, 128, 128  0           ['conv5_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " upconv6_2 (Conv2D)             (None, 64, 128, 64)  32832       ['upconv6_1[0][0]']              \n",
      "                                                                                                  \n",
      " concat_6 (Concatenate)         (None, 64, 128, 128  0           ['upconv6_2[0][0]',              \n",
      "                                )                                 'conv2_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv6_1 (Conv2D)               (None, 64, 128, 64)  73792       ['concat_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv6_2 (Conv2D)               (None, 64, 128, 64)  36928       ['conv6_1[0][0]']                \n",
      "                                                                                                  \n",
      " upconv7_1 (UpSampling2D)       (None, 128, 256, 64  0           ['conv6_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " upconv7_2 (Conv2D)             (None, 128, 256, 32  8224        ['upconv7_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concat_7 (Concatenate)         (None, 128, 256, 64  0           ['upconv7_2[0][0]',              \n",
      "                                )                                 'conv1_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv7_1 (Conv2D)               (None, 128, 256, 32  18464       ['concat_7[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv7_2 (Conv2D)               (None, 128, 256, 32  9248        ['conv7_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv8 (Conv2D)                 (None, 128, 256, 8)  264         ['conv7_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,925,832\n",
      "Trainable params: 1,925,832\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f71701732e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f71701732e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f71701732e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f71701732e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 45s - loss: 0.6282 - iou_score: 0.2779 - f1-score: 0.3721 - val_loss: 0.4738 - val_iou_score: 0.4179 - val_f1-score: 0.5256 - 45s/epoch - 288ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 36s - loss: 0.4457 - iou_score: 0.4511 - f1-score: 0.5546 - val_loss: 0.4308 - val_iou_score: 0.4700 - val_f1-score: 0.5706 - 36s/epoch - 231ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 36s - loss: 0.4099 - iou_score: 0.4915 - f1-score: 0.5891 - val_loss: 0.4112 - val_iou_score: 0.4819 - val_f1-score: 0.5879 - 36s/epoch - 229ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 36s - loss: 0.3742 - iou_score: 0.5217 - f1-score: 0.6243 - val_loss: 0.3523 - val_iou_score: 0.5281 - val_f1-score: 0.6474 - 36s/epoch - 228ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 39s - loss: 0.3269 - iou_score: 0.5588 - f1-score: 0.6727 - val_loss: 0.3299 - val_iou_score: 0.5473 - val_f1-score: 0.6694 - 39s/epoch - 248ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 36s - loss: 0.3007 - iou_score: 0.5839 - f1-score: 0.6993 - val_loss: 0.3307 - val_iou_score: 0.5409 - val_f1-score: 0.6685 - 36s/epoch - 231ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 39s - loss: 0.2837 - iou_score: 0.6022 - f1-score: 0.7162 - val_loss: 0.2978 - val_iou_score: 0.5821 - val_f1-score: 0.7026 - 39s/epoch - 251ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 37s - loss: 0.2772 - iou_score: 0.6085 - f1-score: 0.7227 - val_loss: 0.2951 - val_iou_score: 0.5801 - val_f1-score: 0.7041 - 37s/epoch - 235ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 36s - loss: 0.2738 - iou_score: 0.6115 - f1-score: 0.7259 - val_loss: 0.2866 - val_iou_score: 0.5944 - val_f1-score: 0.7126 - 36s/epoch - 231ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 40s - loss: 0.2519 - iou_score: 0.6362 - f1-score: 0.7477 - val_loss: 0.2714 - val_iou_score: 0.6104 - val_f1-score: 0.7274 - 40s/epoch - 254ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 37s - loss: 0.2424 - iou_score: 0.6463 - f1-score: 0.7564 - val_loss: 0.2695 - val_iou_score: 0.6129 - val_f1-score: 0.7294 - 37s/epoch - 235ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 37s - loss: 0.2395 - iou_score: 0.6492 - f1-score: 0.7603 - val_loss: 0.2580 - val_iou_score: 0.6263 - val_f1-score: 0.7424 - 37s/epoch - 237ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 36s - loss: 0.2298 - iou_score: 0.6613 - f1-score: 0.7698 - val_loss: 0.2480 - val_iou_score: 0.6384 - val_f1-score: 0.7535 - 36s/epoch - 233ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 37s - loss: 0.2179 - iou_score: 0.6753 - f1-score: 0.7816 - val_loss: 0.2375 - val_iou_score: 0.6497 - val_f1-score: 0.7631 - 37s/epoch - 237ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 37s - loss: 0.2138 - iou_score: 0.6798 - f1-score: 0.7861 - val_loss: 0.2442 - val_iou_score: 0.6389 - val_f1-score: 0.7537 - 37s/epoch - 239ms/step\n",
      "2023/09/18 12:27:52 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
      "2023/09/18 12:27:56 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpy4mhb618/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/18 12:27:56 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/18 12:27:56 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'UNET_VANILLA' already exists. Creating a new version of this model...\n",
      "2023/09/18 12:27:56 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: UNET_VANILLA, version 4\n",
      "Created version '4' of model 'UNET_VANILLA'.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/baseline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model with vanilla Unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-14 15:42:55.615252: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 15:42:56.047881: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-14 15:42:56.047919: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-14 15:42:56.047925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/14 15:42:57 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/14 15:42:57 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 256, 16  432         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 256, 16  64         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " spatial_dropout2d (SpatialDrop  (None, 128, 256, 16  0          ['batch_normalization[0][0]']    \n",
      " out2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 256, 16  2304        ['spatial_dropout2d[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 256, 16  64         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 128, 16)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 128, 32)  4608        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 128, 32)  128        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_1 (SpatialDr  (None, 64, 128, 32)  0          ['batch_normalization_2[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 128, 32)  9216        ['spatial_dropout2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 128, 32)  128        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 64, 32)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 64, 64)   18432       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 64, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_2 (SpatialDr  (None, 32, 64, 64)  0           ['batch_normalization_4[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 64, 64)   36864       ['spatial_dropout2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 64, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 32, 64)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 32, 128)  73728       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 32, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_3 (SpatialDr  (None, 16, 32, 128)  0          ['batch_normalization_6[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 32, 128)  147456      ['spatial_dropout2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 32, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 16, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 16, 256)   294912      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 8, 16, 256)  1024        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_4 (SpatialDr  (None, 8, 16, 256)  0           ['batch_normalization_8[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 16, 256)   589824      ['spatial_dropout2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 16, 256)  1024        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 16, 32, 128)  131200     ['batch_normalization_9[0][0]']  \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 32, 256)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 32, 128)  294912      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 32, 128)  512        ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 32, 128)  147456      ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 32, 128)  512        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 32, 64, 64)  32832       ['batch_normalization_11[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 64, 128)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 64, 64)   73728       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 64, 64)  256         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 64, 64)   36864       ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 64, 64)  256         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 64, 128, 32)  8224       ['batch_normalization_13[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 64, 128, 64)  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 128, 32)  18432       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 64, 128, 32)  128        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 128, 32)  9216        ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 64, 128, 32)  128        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 128, 256, 16  2064       ['batch_normalization_15[0][0]'] \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 256, 32  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 256, 16  4608        ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 128, 256, 16  64         ['conv2d_16[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 256, 16  2304        ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 128, 256, 16  64         ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 128, 256, 8)  136         ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,945,640\n",
      "Trainable params: 1,942,696\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f2334d17f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f2334d17f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f2334d17f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f2334d17f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 42s - loss: 0.5642 - iou_score: 0.3229 - f1-score: 0.4360 - val_loss: 0.7661 - val_iou_score: 0.1690 - val_f1-score: 0.2335 - 42s/epoch - 272ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 34s - loss: 0.3973 - iou_score: 0.4840 - f1-score: 0.6027 - val_loss: 0.5334 - val_iou_score: 0.3556 - val_f1-score: 0.4652 - 34s/epoch - 221ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 34s - loss: 0.3484 - iou_score: 0.5323 - f1-score: 0.6514 - val_loss: 0.3778 - val_iou_score: 0.5061 - val_f1-score: 0.6209 - 34s/epoch - 217ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 35s - loss: 0.3207 - iou_score: 0.5605 - f1-score: 0.6793 - val_loss: 0.3157 - val_iou_score: 0.5640 - val_f1-score: 0.6843 - 35s/epoch - 225ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 35s - loss: 0.3044 - iou_score: 0.5773 - f1-score: 0.6954 - val_loss: 0.3063 - val_iou_score: 0.5779 - val_f1-score: 0.6927 - 35s/epoch - 223ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 35s - loss: 0.2907 - iou_score: 0.5915 - f1-score: 0.7082 - val_loss: 0.2871 - val_iou_score: 0.5947 - val_f1-score: 0.7130 - 35s/epoch - 226ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 36s - loss: 0.2783 - iou_score: 0.6067 - f1-score: 0.7216 - val_loss: 0.2761 - val_iou_score: 0.6084 - val_f1-score: 0.7253 - 36s/epoch - 233ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 36s - loss: 0.2723 - iou_score: 0.6112 - f1-score: 0.7268 - val_loss: 0.2746 - val_iou_score: 0.6072 - val_f1-score: 0.7261 - 36s/epoch - 228ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 38s - loss: 0.2620 - iou_score: 0.6242 - f1-score: 0.7378 - val_loss: 0.2593 - val_iou_score: 0.6231 - val_f1-score: 0.7400 - 38s/epoch - 241ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 34s - loss: 0.2586 - iou_score: 0.6267 - f1-score: 0.7406 - val_loss: 0.2542 - val_iou_score: 0.6317 - val_f1-score: 0.7462 - 34s/epoch - 219ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 36s - loss: 0.2530 - iou_score: 0.6335 - f1-score: 0.7465 - val_loss: 0.2519 - val_iou_score: 0.6362 - val_f1-score: 0.7492 - 36s/epoch - 228ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 35s - loss: 0.2439 - iou_score: 0.6444 - f1-score: 0.7554 - val_loss: 0.2438 - val_iou_score: 0.6407 - val_f1-score: 0.7547 - 35s/epoch - 226ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 39s - loss: 0.2428 - iou_score: 0.6448 - f1-score: 0.7560 - val_loss: 0.2528 - val_iou_score: 0.6347 - val_f1-score: 0.7469 - 39s/epoch - 250ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 39s - loss: 0.2388 - iou_score: 0.6505 - f1-score: 0.7613 - val_loss: 0.2400 - val_iou_score: 0.6496 - val_f1-score: 0.7605 - 39s/epoch - 251ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 35s - loss: 0.2311 - iou_score: 0.6598 - f1-score: 0.7690 - val_loss: 0.2304 - val_iou_score: 0.6586 - val_f1-score: 0.7686 - 35s/epoch - 228ms/step\n",
      "2023/09/14 15:52:14 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 23). These functions will not be directly callable after loading.\n",
      "2023/09/14 15:52:21 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpr4sl6e8z/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/14 15:52:21 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/14 15:52:21 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'UNET_VANILLA' already exists. Creating a new version of this model...\n",
      "2023/09/14 15:52:21 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: UNET_VANILLA, version 3\n",
      "Created version '3' of model 'UNET_VANILLA'.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/baseline.py user_config=config/baseline_unet.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model with data augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRETRAINED MODEL + SEGMENTATION UNET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning fore models without aug with Optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-20 14:41:01.433861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-20 14:41:02.304388: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-20 14:41:02.304434: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-20 14:41:02.304439: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "[2023-09-20 14:41:05,132][HYDRA] Updating num of trials to 4 due to using GridSampler.\n",
      "\u001b[32m[I 2023-09-20 14:41:05,132]\u001b[0m A new study created in memory with name: no-name-5aa9e92b-d48a-4d35-96b4-594bc18e1320\u001b[0m\n",
      "[2023-09-20 14:41:05,132][HYDRA] Study name: no-name-5aa9e92b-d48a-4d35-96b4-594bc18e1320\n",
      "[2023-09-20 14:41:05,132][HYDRA] Storage: None\n",
      "[2023-09-20 14:41:05,132][HYDRA] Sampler: GridSampler\n",
      "[2023-09-20 14:41:05,132][HYDRA] Directions: ['maximize', 'maximize']\n",
      "[2023-09-20 14:41:05,134][HYDRA] Launching 1 jobs locally\n",
      "[2023-09-20 14:41:05,134][HYDRA] \t#0 : model.model_type=unet model.backbone=resnet101\n",
      "2023/09/20 14:41:05 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/20 14:41:05 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data (InputLayer)              [(None, 128, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " bn_data (BatchNormalization)   (None, 128, 256, 3)  9           ['data[0][0]']                   \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 134, 262, 3)  0          ['bn_data[0][0]']                \n",
      "                                                                                                  \n",
      " conv0 (Conv2D)                 (None, 64, 128, 64)  9408        ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " bn0 (BatchNormalization)       (None, 64, 128, 64)  256         ['conv0[0][0]']                  \n",
      "                                                                                                  \n",
      " relu0 (Activation)             (None, 64, 128, 64)  0           ['bn0[0][0]']                    \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 66, 130, 64)  0          ['relu0[0][0]']                  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " pooling0 (MaxPooling2D)        (None, 32, 64, 64)   0           ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit1_bn1 (BatchNormali  (None, 32, 64, 64)  256         ['pooling0[0][0]']               \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu1 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit1_conv1 (Conv2D)    (None, 32, 64, 64)   4096        ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit1_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadding2  (None, 34, 66, 64)  0           ['stage1_unit1_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage1_unit1_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_2[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit1_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit1_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit1_sc (Conv2D)       (None, 32, 64, 256)  16384       ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 64, 256)  0           ['stage1_unit1_conv3[0][0]',     \n",
      "                                                                  'stage1_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage1_unit2_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add[0][0]']                    \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu1 (Activation  (None, 32, 64, 256)  0          ['stage1_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit2_conv1 (Conv2D)    (None, 32, 64, 64)   16384       ['stage1_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit2_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadding2  (None, 34, 66, 64)  0           ['stage1_unit2_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage1_unit2_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_3[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit2_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit2_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 64, 256)  0           ['stage1_unit2_conv3[0][0]',     \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " stage1_unit3_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add_1[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu1 (Activation  (None, 32, 64, 256)  0          ['stage1_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit3_conv1 (Conv2D)    (None, 32, 64, 64)   16384       ['stage1_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit3_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 34, 66, 64)  0           ['stage1_unit3_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage1_unit3_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_4[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit3_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit3_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 64, 256)  0           ['stage1_unit3_conv3[0][0]',     \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " stage2_unit1_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add_2[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu1 (Activation  (None, 32, 64, 256)  0          ['stage2_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit1_conv1 (Conv2D)    (None, 32, 64, 128)  32768       ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit1_bn2 (BatchNormali  (None, 32, 64, 128)  512        ['stage2_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu2 (Activation  (None, 32, 64, 128)  0          ['stage2_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadding2  (None, 34, 66, 128)  0          ['stage2_unit1_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit1_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_5[0][0]']       \n",
      "                                                                                                  \n",
      " stage2_unit1_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit1_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit1_sc (Conv2D)       (None, 16, 32, 512)  131072      ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 16, 32, 512)  0           ['stage2_unit1_conv3[0][0]',     \n",
      "                                                                  'stage2_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage2_unit2_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_3[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit2_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit2_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadding2  (None, 18, 34, 128)  0          ['stage2_unit2_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit2_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_6[0][0]']       \n",
      "                                                                                                  \n",
      " stage2_unit2_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit2_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 16, 32, 512)  0           ['stage2_unit2_conv3[0][0]',     \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " stage2_unit3_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_4[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit3_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit3_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadding2  (None, 18, 34, 128)  0          ['stage2_unit3_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit3_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_7[0][0]']       \n",
      "                                                                                                  \n",
      " stage2_unit3_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit3_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 16, 32, 512)  0           ['stage2_unit3_conv3[0][0]',     \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " stage2_unit4_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_5[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit4_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit4_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit4_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit4_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit4_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit4_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_8 (ZeroPadding2  (None, 18, 34, 128)  0          ['stage2_unit4_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit4_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_8[0][0]']       \n",
      "                                                                                                  \n",
      " stage2_unit4_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit4_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit4_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit4_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit4_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 16, 32, 512)  0           ['stage2_unit4_conv3[0][0]',     \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " stage3_unit1_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_6[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu1 (Activation  (None, 16, 32, 512)  0          ['stage3_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit1_conv1 (Conv2D)    (None, 16, 32, 256)  131072      ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit1_bn2 (BatchNormali  (None, 16, 32, 256)  1024       ['stage3_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu2 (Activation  (None, 16, 32, 256)  0          ['stage3_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_9 (ZeroPadding2  (None, 18, 34, 256)  0          ['stage3_unit1_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit1_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_9[0][0]']       \n",
      "                                                                                                  \n",
      " stage3_unit1_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit1_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit1_sc (Conv2D)       (None, 8, 16, 1024)  524288      ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 8, 16, 1024)  0           ['stage3_unit1_conv3[0][0]',     \n",
      "                                                                  'stage3_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage3_unit2_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_7[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit2_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit2_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_10 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit2_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_10[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit2_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit2_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 8, 16, 1024)  0           ['stage3_unit2_conv3[0][0]',     \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " stage3_unit3_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_8[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit3_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit3_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_11 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit3_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_11[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit3_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit3_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 8, 16, 1024)  0           ['stage3_unit3_conv3[0][0]',     \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " stage3_unit4_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_9[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit4_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit4_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit4_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit4_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit4_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit4_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_12 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit4_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit4_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_12[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit4_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit4_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit4_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit4_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit4_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit4_conv3[0][0]',     \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " stage3_unit5_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_10[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit5_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit5_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit5_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit5_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit5_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit5_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_13 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit5_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit5_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_13[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit5_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit5_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit5_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit5_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit5_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit5_conv3[0][0]',     \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit6_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_11[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit6_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit6_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit6_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit6_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit6_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit6_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_14 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit6_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit6_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_14[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit6_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit6_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit6_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit6_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit6_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit6_conv3[0][0]',     \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit7_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_12[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit7_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit7_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit7_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit7_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit7_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit7_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_15 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit7_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit7_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_15[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit7_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit7_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit7_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit7_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit7_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit7_conv3[0][0]',     \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit8_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_13[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit8_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit8_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit8_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit8_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit8_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit8_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_16 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit8_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit8_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_16[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit8_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit8_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit8_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit8_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit8_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit8_conv3[0][0]',     \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit9_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_14[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit9_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit9_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit9_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit9_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit9_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit9_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_17 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit9_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit9_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_17[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit9_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit9_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit9_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit9_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit9_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit9_conv3[0][0]',     \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit10_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_15[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit10_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit10_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit10_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit10_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit10_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit10_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_18 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit10_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit10_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_18[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit10_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit10_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit10_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit10_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit10_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit10_conv3[0][0]',    \n",
      "                                                                  'add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit11_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_16[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit11_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit11_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit11_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit11_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit11_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit11_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_19 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit11_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit11_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_19[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit11_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit11_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit11_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit11_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit11_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit11_conv3[0][0]',    \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit12_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_17[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit12_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit12_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit12_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit12_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit12_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit12_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_20 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit12_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit12_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_20[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit12_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit12_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit12_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit12_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit12_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit12_conv3[0][0]',    \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit13_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_18[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit13_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit13_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit13_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit13_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit13_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit13_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_21 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit13_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit13_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_21[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit13_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit13_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit13_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit13_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit13_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit13_conv3[0][0]',    \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit14_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_19[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit14_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit14_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit14_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit14_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit14_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit14_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_22 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit14_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit14_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_22[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit14_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit14_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit14_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit14_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit14_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit14_conv3[0][0]',    \n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit15_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_20[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit15_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit15_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit15_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit15_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit15_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit15_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_23 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit15_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit15_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_23[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit15_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit15_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit15_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit15_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit15_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit15_conv3[0][0]',    \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit16_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_21[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit16_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit16_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit16_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit16_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit16_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit16_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_24 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit16_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit16_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_24[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit16_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit16_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit16_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit16_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit16_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit16_conv3[0][0]',    \n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit17_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_22[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit17_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit17_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit17_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit17_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit17_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit17_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_25 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit17_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit17_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_25[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit17_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit17_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit17_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit17_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit17_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit17_conv3[0][0]',    \n",
      "                                                                  'add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit18_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_23[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit18_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit18_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit18_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit18_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit18_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit18_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_26 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit18_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit18_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_26[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit18_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit18_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit18_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit18_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit18_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit18_conv3[0][0]',    \n",
      "                                                                  'add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit19_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_24[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit19_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit19_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit19_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit19_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit19_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit19_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_27 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit19_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit19_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_27[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit19_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit19_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit19_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit19_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit19_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit19_conv3[0][0]',    \n",
      "                                                                  'add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit20_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_25[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit20_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit20_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit20_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit20_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit20_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit20_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_28 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit20_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit20_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_28[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit20_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit20_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit20_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit20_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit20_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit20_conv3[0][0]',    \n",
      "                                                                  'add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit21_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_26[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit21_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit21_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit21_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit21_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit21_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit21_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_29 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit21_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit21_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_29[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit21_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit21_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit21_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit21_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit21_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit21_conv3[0][0]',    \n",
      "                                                                  'add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit22_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_27[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit22_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit22_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit22_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit22_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit22_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit22_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_30 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit22_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit22_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_30[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit22_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit22_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit22_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit22_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit22_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit22_conv3[0][0]',    \n",
      "                                                                  'add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit23_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_28[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit23_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit23_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit23_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit23_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit23_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit23_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_31 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit23_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit23_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_31[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit23_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit23_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit23_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit23_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit23_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit23_conv3[0][0]',    \n",
      "                                                                  'add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " stage4_unit1_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_29[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage4_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit1_conv1 (Conv2D)    (None, 8, 16, 512)   524288      ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit1_bn2 (BatchNormali  (None, 8, 16, 512)  2048        ['stage4_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu2 (Activation  (None, 8, 16, 512)  0           ['stage4_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_32 (ZeroPadding  (None, 10, 18, 512)  0          ['stage4_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit1_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_32[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit1_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit1_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit1_sc (Conv2D)       (None, 4, 8, 2048)   2097152     ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit1_conv3[0][0]',     \n",
      "                                                                  'stage4_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage4_unit2_bn1 (BatchNormali  (None, 4, 8, 2048)  8192        ['add_30[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu1 (Activation  (None, 4, 8, 2048)  0           ['stage4_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit2_conv1 (Conv2D)    (None, 4, 8, 512)    1048576     ['stage4_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit2_bn2 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu2 (Activation  (None, 4, 8, 512)   0           ['stage4_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_33 (ZeroPadding  (None, 6, 10, 512)  0           ['stage4_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit2_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_33[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit2_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit2_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit2_conv3[0][0]',     \n",
      "                                                                  'add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " stage4_unit3_bn1 (BatchNormali  (None, 4, 8, 2048)  8192        ['add_31[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu1 (Activation  (None, 4, 8, 2048)  0           ['stage4_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit3_conv1 (Conv2D)    (None, 4, 8, 512)    1048576     ['stage4_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit3_bn2 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu2 (Activation  (None, 4, 8, 512)   0           ['stage4_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_34 (ZeroPadding  (None, 6, 10, 512)  0           ['stage4_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit3_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_34[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit3_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit3_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit3_conv3[0][0]',     \n",
      "                                                                  'add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 4, 8, 2048)   8192        ['add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 4, 8, 2048)   0           ['bn1[0][0]']                    \n",
      "                                                                                                  \n",
      " decoder_stage0_upsampling (UpS  (None, 8, 16, 2048)  0          ['relu1[0][0]']                  \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage0_concat (Concate  (None, 8, 16, 3072)  0          ['decoder_stage0_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " decoder_stage0a_conv (Conv2D)  (None, 8, 16, 256)   7077888     ['decoder_stage0_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage0a_bn (BatchNorma  (None, 8, 16, 256)  1024        ['decoder_stage0a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage0a_relu (Activati  (None, 8, 16, 256)  0           ['decoder_stage0a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage0b_conv (Conv2D)  (None, 8, 16, 256)   589824      ['decoder_stage0a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage0b_bn (BatchNorma  (None, 8, 16, 256)  1024        ['decoder_stage0b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage0b_relu (Activati  (None, 8, 16, 256)  0           ['decoder_stage0b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1_upsampling (UpS  (None, 16, 32, 256)  0          ['decoder_stage0b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage1_concat (Concate  (None, 16, 32, 768)  0          ['decoder_stage1_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " decoder_stage1a_conv (Conv2D)  (None, 16, 32, 128)  884736      ['decoder_stage1_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage1a_bn (BatchNorma  (None, 16, 32, 128)  512        ['decoder_stage1a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage1a_relu (Activati  (None, 16, 32, 128)  0          ['decoder_stage1a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1b_conv (Conv2D)  (None, 16, 32, 128)  147456      ['decoder_stage1a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage1b_bn (BatchNorma  (None, 16, 32, 128)  512        ['decoder_stage1b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage1b_relu (Activati  (None, 16, 32, 128)  0          ['decoder_stage1b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2_upsampling (UpS  (None, 32, 64, 128)  0          ['decoder_stage1b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage2_concat (Concate  (None, 32, 64, 384)  0          ['decoder_stage2_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " decoder_stage2a_conv (Conv2D)  (None, 32, 64, 64)   221184      ['decoder_stage2_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage2a_bn (BatchNorma  (None, 32, 64, 64)  256         ['decoder_stage2a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage2a_relu (Activati  (None, 32, 64, 64)  0           ['decoder_stage2a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2b_conv (Conv2D)  (None, 32, 64, 64)   36864       ['decoder_stage2a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage2b_bn (BatchNorma  (None, 32, 64, 64)  256         ['decoder_stage2b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage2b_relu (Activati  (None, 32, 64, 64)  0           ['decoder_stage2b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage3_upsampling (UpS  (None, 64, 128, 64)  0          ['decoder_stage2b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage3_concat (Concate  (None, 64, 128, 128  0          ['decoder_stage3_upsampling[0][0]\n",
      " nate)                          )                                ',                               \n",
      "                                                                  'relu0[0][0]']                  \n",
      "                                                                                                  \n",
      " decoder_stage3a_conv (Conv2D)  (None, 64, 128, 32)  36864       ['decoder_stage3_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage3a_bn (BatchNorma  (None, 64, 128, 32)  128        ['decoder_stage3a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage3a_relu (Activati  (None, 64, 128, 32)  0          ['decoder_stage3a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage3b_conv (Conv2D)  (None, 64, 128, 32)  9216        ['decoder_stage3a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage3b_bn (BatchNorma  (None, 64, 128, 32)  128        ['decoder_stage3b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage3b_relu (Activati  (None, 64, 128, 32)  0          ['decoder_stage3b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage4_upsampling (UpS  (None, 128, 256, 32  0          ['decoder_stage3b_relu[0][0]']   \n",
      " ampling2D)                     )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4a_conv (Conv2D)  (None, 128, 256, 16  4608        ['decoder_stage4_upsampling[0][0]\n",
      "                                )                                ']                               \n",
      "                                                                                                  \n",
      " decoder_stage4a_bn (BatchNorma  (None, 128, 256, 16  64         ['decoder_stage4a_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4a_relu (Activati  (None, 128, 256, 16  0          ['decoder_stage4a_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_conv (Conv2D)  (None, 128, 256, 16  2304        ['decoder_stage4a_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_bn (BatchNorma  (None, 128, 256, 16  64         ['decoder_stage4b_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_relu (Activati  (None, 128, 256, 16  0          ['decoder_stage4b_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " final_conv (Conv2D)            (None, 128, 256, 8)  1160        ['decoder_stage4b_relu[0][0]']   \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 128, 256, 8)  0           ['final_conv[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51,606,481\n",
      "Trainable params: 51,506,699\n",
      "Non-trainable params: 99,782\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f6550185090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f6550185090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f6550185090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f6550185090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 90s - loss: 0.4137 - iou_score: 0.4734 - f1-score: 0.5861 - val_loss: 0.7370 - val_iou_score: 0.1994 - val_f1-score: 0.2621 - 90s/epoch - 574ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 63s - loss: 0.2659 - iou_score: 0.6194 - f1-score: 0.7332 - val_loss: 0.8245 - val_iou_score: 0.1181 - val_f1-score: 0.1762 - 63s/epoch - 405ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 64s - loss: 0.2400 - iou_score: 0.6476 - f1-score: 0.7591 - val_loss: 0.7982 - val_iou_score: 0.1490 - val_f1-score: 0.2020 - 64s/epoch - 408ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 64s - loss: 0.2230 - iou_score: 0.6661 - f1-score: 0.7758 - val_loss: 0.7099 - val_iou_score: 0.2244 - val_f1-score: 0.2913 - 64s/epoch - 412ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 65s - loss: 0.2119 - iou_score: 0.6805 - f1-score: 0.7877 - val_loss: 0.7155 - val_iou_score: 0.2256 - val_f1-score: 0.2838 - 65s/epoch - 414ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 64s - loss: 0.1996 - iou_score: 0.6944 - f1-score: 0.7993 - val_loss: 0.6013 - val_iou_score: 0.3047 - val_f1-score: 0.3981 - 64s/epoch - 408ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 65s - loss: 0.2247 - iou_score: 0.6637 - f1-score: 0.7744 - val_loss: 0.4393 - val_iou_score: 0.4391 - val_f1-score: 0.5602 - 65s/epoch - 415ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 64s - loss: 0.2019 - iou_score: 0.6905 - f1-score: 0.7967 - val_loss: 0.2626 - val_iou_score: 0.6213 - val_f1-score: 0.7367 - 64s/epoch - 412ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 64s - loss: 0.1889 - iou_score: 0.7071 - f1-score: 0.8106 - val_loss: 0.2705 - val_iou_score: 0.6132 - val_f1-score: 0.7297 - 64s/epoch - 410ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 65s - loss: 0.1835 - iou_score: 0.7136 - f1-score: 0.8155 - val_loss: 0.3223 - val_iou_score: 0.5537 - val_f1-score: 0.6760 - 65s/epoch - 415ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 65s - loss: 0.1838 - iou_score: 0.7131 - f1-score: 0.8158 - val_loss: 0.2354 - val_iou_score: 0.6469 - val_f1-score: 0.7626 - 65s/epoch - 414ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 65s - loss: 0.1807 - iou_score: 0.7171 - f1-score: 0.8191 - val_loss: 0.2320 - val_iou_score: 0.6563 - val_f1-score: 0.7690 - 65s/epoch - 415ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 64s - loss: 0.1741 - iou_score: 0.7253 - f1-score: 0.8252 - val_loss: 0.2239 - val_iou_score: 0.6633 - val_f1-score: 0.7755 - 64s/epoch - 413ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 65s - loss: 0.1689 - iou_score: 0.7314 - f1-score: 0.8303 - val_loss: 0.2269 - val_iou_score: 0.6614 - val_f1-score: 0.7725 - 65s/epoch - 420ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 65s - loss: 0.1620 - iou_score: 0.7406 - f1-score: 0.8376 - val_loss: 0.2198 - val_iou_score: 0.6673 - val_f1-score: 0.7773 - 65s/epoch - 420ms/step\n",
      "<keras.callbacks.History object at 0x7f6550252800>\n",
      "2023/09/20 14:57:51 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 115). These functions will not be directly callable after loading.\n",
      "2023/09/20 14:58:18 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpbftesg12/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/20 14:58:18 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/20 14:58:18 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'unet' already exists. Creating a new version of this model...\n",
      "2023/09/20 14:58:18 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: unet, version 10\n",
      "Created version '10' of model 'unet'.\n",
      "[2023-09-20 14:58:18,557][HYDRA] Launching 1 jobs locally\n",
      "[2023-09-20 14:58:18,557][HYDRA] \t#1 : model.model_type=fpn model.backbone=resnet101\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data (InputLayer)              [(None, 128, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " bn_data (BatchNormalization)   (None, 128, 256, 3)  9           ['data[0][0]']                   \n",
      "                                                                                                  \n",
      " zero_padding2d_35 (ZeroPadding  (None, 134, 262, 3)  0          ['bn_data[0][0]']                \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv0 (Conv2D)                 (None, 64, 128, 64)  9408        ['zero_padding2d_35[0][0]']      \n",
      "                                                                                                  \n",
      " bn0 (BatchNormalization)       (None, 64, 128, 64)  256         ['conv0[0][0]']                  \n",
      "                                                                                                  \n",
      " relu0 (Activation)             (None, 64, 128, 64)  0           ['bn0[0][0]']                    \n",
      "                                                                                                  \n",
      " zero_padding2d_36 (ZeroPadding  (None, 66, 130, 64)  0          ['relu0[0][0]']                  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pooling0 (MaxPooling2D)        (None, 32, 64, 64)   0           ['zero_padding2d_36[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit1_bn1 (BatchNormali  (None, 32, 64, 64)  256         ['pooling0[0][0]']               \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu1 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit1_conv1 (Conv2D)    (None, 32, 64, 64)   4096        ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit1_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_37 (ZeroPadding  (None, 34, 66, 64)  0           ['stage1_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit1_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_37[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit1_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit1_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit1_sc (Conv2D)       (None, 32, 64, 256)  16384       ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 32, 64, 256)  0           ['stage1_unit1_conv3[0][0]',     \n",
      "                                                                  'stage1_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage1_unit2_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add_33[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu1 (Activation  (None, 32, 64, 256)  0          ['stage1_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit2_conv1 (Conv2D)    (None, 32, 64, 64)   16384       ['stage1_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit2_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_38 (ZeroPadding  (None, 34, 66, 64)  0           ['stage1_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit2_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_38[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit2_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit2_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 32, 64, 256)  0           ['stage1_unit2_conv3[0][0]',     \n",
      "                                                                  'add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " stage1_unit3_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add_34[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu1 (Activation  (None, 32, 64, 256)  0          ['stage1_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit3_conv1 (Conv2D)    (None, 32, 64, 64)   16384       ['stage1_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit3_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_39 (ZeroPadding  (None, 34, 66, 64)  0           ['stage1_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit3_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_39[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit3_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit3_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 32, 64, 256)  0           ['stage1_unit3_conv3[0][0]',     \n",
      "                                                                  'add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit1_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add_35[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu1 (Activation  (None, 32, 64, 256)  0          ['stage2_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit1_conv1 (Conv2D)    (None, 32, 64, 128)  32768       ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit1_bn2 (BatchNormali  (None, 32, 64, 128)  512        ['stage2_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu2 (Activation  (None, 32, 64, 128)  0          ['stage2_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_40 (ZeroPadding  (None, 34, 66, 128)  0          ['stage2_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit1_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_40[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit1_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit1_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit1_sc (Conv2D)       (None, 16, 32, 512)  131072      ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 16, 32, 512)  0           ['stage2_unit1_conv3[0][0]',     \n",
      "                                                                  'stage2_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage2_unit2_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_36[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit2_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit2_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_41 (ZeroPadding  (None, 18, 34, 128)  0          ['stage2_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit2_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_41[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit2_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit2_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, 16, 32, 512)  0           ['stage2_unit2_conv3[0][0]',     \n",
      "                                                                  'add_36[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit3_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_37[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit3_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit3_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_42 (ZeroPadding  (None, 18, 34, 128)  0          ['stage2_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit3_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_42[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit3_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit3_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, 16, 32, 512)  0           ['stage2_unit3_conv3[0][0]',     \n",
      "                                                                  'add_37[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit4_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_38[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit4_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit4_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit4_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit4_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit4_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit4_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_43 (ZeroPadding  (None, 18, 34, 128)  0          ['stage2_unit4_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit4_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_43[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit4_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit4_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit4_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit4_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit4_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, 16, 32, 512)  0           ['stage2_unit4_conv3[0][0]',     \n",
      "                                                                  'add_38[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit1_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_39[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu1 (Activation  (None, 16, 32, 512)  0          ['stage3_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit1_conv1 (Conv2D)    (None, 16, 32, 256)  131072      ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit1_bn2 (BatchNormali  (None, 16, 32, 256)  1024       ['stage3_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu2 (Activation  (None, 16, 32, 256)  0          ['stage3_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_44 (ZeroPadding  (None, 18, 34, 256)  0          ['stage3_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit1_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_44[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit1_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit1_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit1_sc (Conv2D)       (None, 8, 16, 1024)  524288      ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit1_conv3[0][0]',     \n",
      "                                                                  'stage3_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage3_unit2_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_40[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit2_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit2_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_45 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit2_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_45[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit2_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit2_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit2_conv3[0][0]',     \n",
      "                                                                  'add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit3_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_41[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit3_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit3_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_46 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit3_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_46[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit3_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit3_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit3_conv3[0][0]',     \n",
      "                                                                  'add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit4_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_42[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit4_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit4_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit4_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit4_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit4_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit4_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_47 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit4_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit4_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_47[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit4_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit4_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit4_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit4_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit4_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit4_conv3[0][0]',     \n",
      "                                                                  'add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit5_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_43[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit5_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit5_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit5_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit5_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit5_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit5_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_48 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit5_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit5_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_48[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit5_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit5_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit5_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit5_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit5_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit5_conv3[0][0]',     \n",
      "                                                                  'add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit6_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_44[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit6_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit6_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit6_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit6_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit6_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit6_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_49 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit6_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit6_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_49[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit6_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit6_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit6_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit6_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit6_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit6_conv3[0][0]',     \n",
      "                                                                  'add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit7_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_45[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit7_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit7_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit7_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit7_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit7_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit7_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_50 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit7_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit7_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_50[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit7_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit7_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit7_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit7_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit7_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit7_conv3[0][0]',     \n",
      "                                                                  'add_45[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit8_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_46[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit8_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit8_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit8_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit8_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit8_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit8_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_51 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit8_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit8_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_51[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit8_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit8_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit8_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit8_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit8_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit8_conv3[0][0]',     \n",
      "                                                                  'add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit9_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_47[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit9_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit9_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit9_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit9_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit9_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit9_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_52 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit9_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit9_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_52[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit9_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit9_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit9_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit9_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit9_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_48 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit9_conv3[0][0]',     \n",
      "                                                                  'add_47[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit10_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_48[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit10_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit10_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit10_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit10_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit10_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit10_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_53 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit10_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit10_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_53[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit10_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit10_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit10_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit10_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit10_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_49 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit10_conv3[0][0]',    \n",
      "                                                                  'add_48[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit11_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_49[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit11_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit11_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit11_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit11_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit11_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit11_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_54 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit11_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit11_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_54[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit11_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit11_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit11_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit11_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit11_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_50 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit11_conv3[0][0]',    \n",
      "                                                                  'add_49[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit12_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_50[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit12_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit12_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit12_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit12_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit12_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit12_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_55 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit12_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit12_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_55[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit12_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit12_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit12_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit12_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit12_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_51 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit12_conv3[0][0]',    \n",
      "                                                                  'add_50[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit13_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_51[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit13_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit13_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit13_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit13_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit13_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit13_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_56 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit13_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit13_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_56[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit13_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit13_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit13_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit13_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit13_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_52 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit13_conv3[0][0]',    \n",
      "                                                                  'add_51[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit14_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_52[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit14_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit14_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit14_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit14_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit14_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit14_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_57 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit14_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit14_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_57[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit14_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit14_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit14_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit14_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit14_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_53 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit14_conv3[0][0]',    \n",
      "                                                                  'add_52[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit15_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_53[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit15_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit15_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit15_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit15_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit15_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit15_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_58 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit15_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit15_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_58[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit15_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit15_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit15_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit15_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit15_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_54 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit15_conv3[0][0]',    \n",
      "                                                                  'add_53[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit16_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_54[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit16_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit16_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit16_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit16_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit16_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit16_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_59 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit16_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit16_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_59[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit16_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit16_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit16_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit16_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit16_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_55 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit16_conv3[0][0]',    \n",
      "                                                                  'add_54[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit17_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_55[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit17_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit17_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit17_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit17_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit17_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit17_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_60 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit17_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit17_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_60[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit17_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit17_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit17_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit17_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit17_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_56 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit17_conv3[0][0]',    \n",
      "                                                                  'add_55[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit18_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_56[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit18_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit18_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit18_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit18_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit18_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit18_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_61 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit18_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit18_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_61[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit18_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit18_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit18_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit18_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit18_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_57 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit18_conv3[0][0]',    \n",
      "                                                                  'add_56[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit19_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_57[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit19_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit19_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit19_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit19_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit19_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit19_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_62 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit19_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit19_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_62[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit19_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit19_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit19_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit19_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit19_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_58 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit19_conv3[0][0]',    \n",
      "                                                                  'add_57[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit20_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_58[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit20_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit20_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit20_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit20_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit20_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit20_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_63 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit20_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit20_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_63[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit20_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit20_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit20_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit20_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit20_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_59 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit20_conv3[0][0]',    \n",
      "                                                                  'add_58[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit21_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_59[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit21_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit21_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit21_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit21_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit21_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit21_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_64 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit21_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit21_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_64[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit21_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit21_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit21_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit21_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit21_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_60 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit21_conv3[0][0]',    \n",
      "                                                                  'add_59[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit22_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_60[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit22_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit22_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit22_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit22_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit22_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit22_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_65 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit22_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit22_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_65[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit22_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit22_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit22_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit22_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit22_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_61 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit22_conv3[0][0]',    \n",
      "                                                                  'add_60[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit23_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_61[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit23_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit23_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit23_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit23_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit23_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit23_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_66 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit23_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit23_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_66[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit23_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit23_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit23_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit23_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit23_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_62 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit23_conv3[0][0]',    \n",
      "                                                                  'add_61[0][0]']                 \n",
      "                                                                                                  \n",
      " stage4_unit1_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_62[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage4_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit1_conv1 (Conv2D)    (None, 8, 16, 512)   524288      ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit1_bn2 (BatchNormali  (None, 8, 16, 512)  2048        ['stage4_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu2 (Activation  (None, 8, 16, 512)  0           ['stage4_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_67 (ZeroPadding  (None, 10, 18, 512)  0          ['stage4_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit1_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_67[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit1_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit1_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit1_sc (Conv2D)       (None, 4, 8, 2048)   2097152     ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_63 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit1_conv3[0][0]',     \n",
      "                                                                  'stage4_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage4_unit2_bn1 (BatchNormali  (None, 4, 8, 2048)  8192        ['add_63[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu1 (Activation  (None, 4, 8, 2048)  0           ['stage4_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit2_conv1 (Conv2D)    (None, 4, 8, 512)    1048576     ['stage4_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit2_bn2 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu2 (Activation  (None, 4, 8, 512)   0           ['stage4_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_68 (ZeroPadding  (None, 6, 10, 512)  0           ['stage4_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit2_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_68[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit2_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit2_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_64 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit2_conv3[0][0]',     \n",
      "                                                                  'add_63[0][0]']                 \n",
      "                                                                                                  \n",
      " stage4_unit3_bn1 (BatchNormali  (None, 4, 8, 2048)  8192        ['add_64[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu1 (Activation  (None, 4, 8, 2048)  0           ['stage4_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit3_conv1 (Conv2D)    (None, 4, 8, 512)    1048576     ['stage4_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit3_bn2 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu2 (Activation  (None, 4, 8, 512)   0           ['stage4_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_69 (ZeroPadding  (None, 6, 10, 512)  0           ['stage4_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit3_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_69[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit3_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit3_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_65 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit3_conv3[0][0]',     \n",
      "                                                                  'add_64[0][0]']                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 4, 8, 2048)   8192        ['add_65[0][0]']                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 4, 8, 2048)   0           ['bn1[0][0]']                    \n",
      "                                                                                                  \n",
      " fpn_stage_p5_pre_conv (Conv2D)  (None, 4, 8, 256)   524544      ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " fpn_stage_p5_upsampling (UpSam  (None, 8, 16, 256)  0           ['fpn_stage_p5_pre_conv[0][0]']  \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p5_conv (Conv2D)     (None, 8, 16, 256)   262400      ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " fpn_stage_p5_add (Add)         (None, 8, 16, 256)   0           ['fpn_stage_p5_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p5_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p4_upsampling (UpSam  (None, 16, 32, 256)  0          ['fpn_stage_p5_add[0][0]']       \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p4_conv (Conv2D)     (None, 16, 32, 256)  131328      ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " fpn_stage_p4_add (Add)         (None, 16, 32, 256)  0           ['fpn_stage_p4_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p4_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p3_upsampling (UpSam  (None, 32, 64, 256)  0          ['fpn_stage_p4_add[0][0]']       \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p3_conv (Conv2D)     (None, 32, 64, 256)  65792       ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " fpn_stage_p3_add (Add)         (None, 32, 64, 256)  0           ['fpn_stage_p3_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p3_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p2_upsampling (UpSam  (None, 64, 128, 256  0          ['fpn_stage_p3_add[0][0]']       \n",
      " pling2D)                       )                                                                 \n",
      "                                                                                                  \n",
      " fpn_stage_p2_conv (Conv2D)     (None, 64, 128, 256  16640       ['relu0[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " fpn_stage_p2_add (Add)         (None, 64, 128, 256  0           ['fpn_stage_p2_upsampling[0][0]',\n",
      "                                )                                 'fpn_stage_p2_conv[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage3a_conv (Conv2D)     (None, 32, 64, 128)  294912      ['fpn_stage_p3_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage4a_conv (Conv2D)     (None, 16, 32, 128)  294912      ['fpn_stage_p4_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage5a_conv (Conv2D)     (None, 8, 16, 128)   294912      ['fpn_stage_p5_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage2a_conv (Conv2D)     (None, 64, 128, 128  294912      ['fpn_stage_p2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3a_bn (BatchNormaliz  (None, 32, 64, 128)  512        ['segm_stage3a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage4a_bn (BatchNormaliz  (None, 16, 32, 128)  512        ['segm_stage4a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage5a_bn (BatchNormaliz  (None, 8, 16, 128)  512         ['segm_stage5a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage2a_bn (BatchNormaliz  (None, 64, 128, 128  512        ['segm_stage2a_conv[0][0]']      \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3a_relu (Activation)  (None, 32, 64, 128)  0          ['segm_stage3a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage4a_relu (Activation)  (None, 16, 32, 128)  0          ['segm_stage4a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage5a_relu (Activation)  (None, 8, 16, 128)  0           ['segm_stage5a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage2a_relu (Activation)  (None, 64, 128, 128  0          ['segm_stage2a_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_conv (Conv2D)     (None, 32, 64, 128)  147456      ['segm_stage3a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage4b_conv (Conv2D)     (None, 16, 32, 128)  147456      ['segm_stage4a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage5b_conv (Conv2D)     (None, 8, 16, 128)   147456      ['segm_stage5a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage2b_conv (Conv2D)     (None, 64, 128, 128  147456      ['segm_stage2a_relu[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_bn (BatchNormaliz  (None, 32, 64, 128)  512        ['segm_stage3b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage4b_bn (BatchNormaliz  (None, 16, 32, 128)  512        ['segm_stage4b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage5b_bn (BatchNormaliz  (None, 8, 16, 128)  512         ['segm_stage5b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage2b_bn (BatchNormaliz  (None, 64, 128, 128  512        ['segm_stage2b_conv[0][0]']      \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_relu (Activation)  (None, 32, 64, 128)  0          ['segm_stage3b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage4b_relu (Activation)  (None, 16, 32, 128)  0          ['segm_stage4b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage5b_relu (Activation)  (None, 8, 16, 128)  0           ['segm_stage5b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage2b_relu (Activation)  (None, 64, 128, 128  0          ['segm_stage2b_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage3 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage3b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage4 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage4b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage5 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage5b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " aggregation_concat (Concatenat  (None, 64, 128, 512  0          ['segm_stage2b_relu[0][0]',      \n",
      " e)                             )                                 'upsampling_stage3[0][0]',      \n",
      "                                                                  'upsampling_stage4[0][0]',      \n",
      "                                                                  'upsampling_stage5[0][0]']      \n",
      "                                                                                                  \n",
      " final_stage_conv (Conv2D)      (None, 64, 128, 128  589824      ['aggregation_concat[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " final_stage_bn (BatchNormaliza  (None, 64, 128, 128  512        ['final_stage_conv[0][0]']       \n",
      " tion)                          )                                                                 \n",
      "                                                                                                  \n",
      " final_stage_relu (Activation)  (None, 64, 128, 128  0           ['final_stage_bn[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " final_upsampling (UpSampling2D  (None, 128, 256, 12  0          ['final_stage_relu[0][0]']       \n",
      " )                              8)                                                                \n",
      "                                                                                                  \n",
      " head_conv (Conv2D)             (None, 128, 256, 8)  9224        ['final_upsampling[0][0]']       \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 128, 256, 8)  0           ['head_conv[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 45,964,241\n",
      "Trainable params: 45,864,139\n",
      "Non-trainable params: 100,102\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "156/156 - 102s - loss: 0.3634 - iou_score: 0.5199 - f1-score: 0.6366 - val_loss: 0.7798 - val_iou_score: 0.1585 - val_f1-score: 0.2197 - 102s/epoch - 653ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 78s - loss: 0.2658 - iou_score: 0.6200 - f1-score: 0.7333 - val_loss: 0.7377 - val_iou_score: 0.2064 - val_f1-score: 0.2621 - 78s/epoch - 498ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 77s - loss: 0.2376 - iou_score: 0.6506 - f1-score: 0.7616 - val_loss: 0.7670 - val_iou_score: 0.1723 - val_f1-score: 0.2325 - 77s/epoch - 495ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 79s - loss: 0.2210 - iou_score: 0.6695 - f1-score: 0.7779 - val_loss: 0.7499 - val_iou_score: 0.1949 - val_f1-score: 0.2512 - 79s/epoch - 504ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 79s - loss: 0.2073 - iou_score: 0.6871 - f1-score: 0.7922 - val_loss: 0.7444 - val_iou_score: 0.1960 - val_f1-score: 0.2548 - 79s/epoch - 509ms/step\n",
      "<keras.callbacks.History object at 0x7f6590b30f70>\n",
      "2023/09/20 15:05:27 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "[2023-09-20 15:05:44,485][absl][WARNING] - Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 119). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpb06yozeo/model/data/model/assets\n",
      "[2023-09-20 15:05:50,421][tensorflow][INFO] - Assets written to: /tmp/tmpb06yozeo/model/data/model/assets\n",
      "2023/09/20 15:05:53 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpb06yozeo/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/20 15:05:53 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 7\n",
      "Created version '7' of model 'fpn'.\n",
      "[2023-09-20 15:05:53,599][HYDRA] Launching 1 jobs locally\n",
      "[2023-09-20 15:05:53,599][HYDRA] \t#2 : model.model_type=fpn model.backbone=mobilenetv2\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1_pad (ZeroPadding2D)      (None, 129, 257, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 64, 128, 32)  864         ['Conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 64, 128, 32)  128         ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 64, 128, 32)  0           ['bn_Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 64, 128, 32)  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 64, 128, 32)  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 64, 128, 32)  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                                                           ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 64, 128, 16)  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 64, 128, 16)  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 64, 128, 96)  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 64, 128, 96)  384        ['block_1_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 64, 128, 96)  0           ['block_1_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 65, 129, 96)  0           ['block_1_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 32, 64, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 32, 64, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 32, 64, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 32, 64, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 32, 64, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 32, 64, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 32, 64, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 32, 64, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 32, 64, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 32, 64, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 32, 64, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 32, 64, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 32, 64, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 32, 64, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 32, 64, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 32, 64, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 32, 64, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 33, 65, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 16, 32, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 16, 32, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 16, 32, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 16, 32, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 16, 32, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 16, 32, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 16, 32, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 16, 32, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 16, 32, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 16, 32, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 16, 32, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 16, 32, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 16, 32, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 16, 32, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 16, 32, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 16, 32, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 16, 32, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 16, 32, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 16, 32, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 16, 32, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 16, 32, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 16, 32, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 16, 32, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 16, 32, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 16, 32, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 16, 32, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 17, 33, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 8, 16, 192)  1728        ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 8, 16, 192)  768         ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 8, 16, 192)   0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 8, 16, 64)    12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 8, 16, 384)   24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 8, 16, 384)  1536        ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 8, 16, 384)   0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 8, 16, 384)  3456        ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 8, 16, 384)  1536        ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 8, 16, 384)   0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 8, 16, 64)    24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 8, 16, 64)    0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 8, 16, 384)   24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 8, 16, 384)  1536        ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 8, 16, 384)   0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 8, 16, 384)  3456        ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 8, 16, 384)  1536        ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 8, 16, 384)   0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 8, 16, 64)    24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 8, 16, 64)    0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 8, 16, 384)   24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 8, 16, 384)  1536        ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 8, 16, 384)   0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 8, 16, 384)  3456        ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 8, 16, 384)  1536        ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 8, 16, 384)   0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 8, 16, 64)    24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 8, 16, 64)    0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 8, 16, 384)   24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 8, 16, 384)  1536        ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 8, 16, 384)   0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 8, 16, 384)  3456        ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 8, 16, 384)  1536        ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 8, 16, 384)  0           ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 8, 16, 96)    36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 8, 16, 96)   384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 8, 16, 576)   55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 8, 16, 576)  2304        ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 8, 16, 576)   0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 8, 16, 576)  5184        ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 8, 16, 576)  2304        ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 8, 16, 576)  0           ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 8, 16, 96)    55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 8, 16, 96)   384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 8, 16, 96)    0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 8, 16, 576)   55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 8, 16, 576)  2304        ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 8, 16, 576)   0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 8, 16, 576)  5184        ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 8, 16, 576)  2304        ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 8, 16, 576)  0           ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 8, 16, 96)    55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 8, 16, 96)   384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 8, 16, 96)    0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 8, 16, 576)   55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 8, 16, 576)  2304        ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 8, 16, 576)   0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 9, 17, 576)   0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 4, 8, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 4, 8, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 4, 8, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 4, 8, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 4, 8, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 4, 8, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 4, 8, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 4, 8, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 4, 8, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 4, 8, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 4, 8, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 4, 8, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 4, 8, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 4, 8, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 4, 8, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 4, 8, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 4, 8, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 4, 8, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 4, 8, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 4, 8, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 4, 8, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 4, 8, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 4, 8, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 4, 8, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 4, 8, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 4, 8, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 4, 8, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 4, 8, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 4, 8, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 4, 8, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 4, 8, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 4, 8, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 4, 8, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 4, 8, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " fpn_stage_p5_pre_conv (Conv2D)  (None, 4, 8, 256)   327936      ['out_relu[0][0]']               \n",
      "                                                                                                  \n",
      " fpn_stage_p5_upsampling (UpSam  (None, 8, 16, 256)  0           ['fpn_stage_p5_pre_conv[0][0]']  \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p5_conv (Conv2D)     (None, 8, 16, 256)   147712      ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " fpn_stage_p5_add (Add)         (None, 8, 16, 256)   0           ['fpn_stage_p5_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p5_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p4_upsampling (UpSam  (None, 16, 32, 256)  0          ['fpn_stage_p5_add[0][0]']       \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p4_conv (Conv2D)     (None, 16, 32, 256)  49408       ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " fpn_stage_p4_add (Add)         (None, 16, 32, 256)  0           ['fpn_stage_p4_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p4_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p3_upsampling (UpSam  (None, 32, 64, 256)  0          ['fpn_stage_p4_add[0][0]']       \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p3_conv (Conv2D)     (None, 32, 64, 256)  37120       ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " fpn_stage_p3_add (Add)         (None, 32, 64, 256)  0           ['fpn_stage_p3_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p3_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p2_upsampling (UpSam  (None, 64, 128, 256  0          ['fpn_stage_p3_add[0][0]']       \n",
      " pling2D)                       )                                                                 \n",
      "                                                                                                  \n",
      " fpn_stage_p2_conv (Conv2D)     (None, 64, 128, 256  24832       ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " fpn_stage_p2_add (Add)         (None, 64, 128, 256  0           ['fpn_stage_p2_upsampling[0][0]',\n",
      "                                )                                 'fpn_stage_p2_conv[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage3a_conv (Conv2D)     (None, 32, 64, 128)  294912      ['fpn_stage_p3_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage4a_conv (Conv2D)     (None, 16, 32, 128)  294912      ['fpn_stage_p4_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage5a_conv (Conv2D)     (None, 8, 16, 128)   294912      ['fpn_stage_p5_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage2a_conv (Conv2D)     (None, 64, 128, 128  294912      ['fpn_stage_p2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3a_bn (BatchNormaliz  (None, 32, 64, 128)  512        ['segm_stage3a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage4a_bn (BatchNormaliz  (None, 16, 32, 128)  512        ['segm_stage4a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage5a_bn (BatchNormaliz  (None, 8, 16, 128)  512         ['segm_stage5a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage2a_bn (BatchNormaliz  (None, 64, 128, 128  512        ['segm_stage2a_conv[0][0]']      \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3a_relu (Activation)  (None, 32, 64, 128)  0          ['segm_stage3a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage4a_relu (Activation)  (None, 16, 32, 128)  0          ['segm_stage4a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage5a_relu (Activation)  (None, 8, 16, 128)  0           ['segm_stage5a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage2a_relu (Activation)  (None, 64, 128, 128  0          ['segm_stage2a_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_conv (Conv2D)     (None, 32, 64, 128)  147456      ['segm_stage3a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage4b_conv (Conv2D)     (None, 16, 32, 128)  147456      ['segm_stage4a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage5b_conv (Conv2D)     (None, 8, 16, 128)   147456      ['segm_stage5a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage2b_conv (Conv2D)     (None, 64, 128, 128  147456      ['segm_stage2a_relu[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_bn (BatchNormaliz  (None, 32, 64, 128)  512        ['segm_stage3b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage4b_bn (BatchNormaliz  (None, 16, 32, 128)  512        ['segm_stage4b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage5b_bn (BatchNormaliz  (None, 8, 16, 128)  512         ['segm_stage5b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage2b_bn (BatchNormaliz  (None, 64, 128, 128  512        ['segm_stage2b_conv[0][0]']      \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_relu (Activation)  (None, 32, 64, 128)  0          ['segm_stage3b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage4b_relu (Activation)  (None, 16, 32, 128)  0          ['segm_stage4b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage5b_relu (Activation)  (None, 8, 16, 128)  0           ['segm_stage5b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage2b_relu (Activation)  (None, 64, 128, 128  0          ['segm_stage2b_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage3 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage3b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage4 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage4b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage5 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage5b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " aggregation_concat (Concatenat  (None, 64, 128, 512  0          ['segm_stage2b_relu[0][0]',      \n",
      " e)                             )                                 'upsampling_stage3[0][0]',      \n",
      "                                                                  'upsampling_stage4[0][0]',      \n",
      "                                                                  'upsampling_stage5[0][0]']      \n",
      "                                                                                                  \n",
      " final_stage_conv (Conv2D)      (None, 64, 128, 128  589824      ['aggregation_concat[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " final_stage_bn (BatchNormaliza  (None, 64, 128, 128  512        ['final_stage_conv[0][0]']       \n",
      " tion)                          )                                                                 \n",
      "                                                                                                  \n",
      " final_stage_relu (Activation)  (None, 64, 128, 128  0           ['final_stage_bn[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " final_upsampling (UpSampling2D  (None, 128, 256, 12  0          ['final_stage_relu[0][0]']       \n",
      " )                              8)                                                                \n",
      "                                                                                                  \n",
      " head_conv (Conv2D)             (None, 128, 256, 8)  9224        ['final_upsampling[0][0]']       \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 128, 256, 8)  0           ['head_conv[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,218,120\n",
      "Trainable params: 5,181,704\n",
      "Non-trainable params: 36,416\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "Error executing job with overrides: ['model.model_type=fpn', 'model.backbone=mobilenetv2']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lpradier/Bureau/FORMATION/PROJET_8/src/modeling/pretrained-models.py\", line 172, in makerun\n",
      "    history = model.fit(\n",
      "  File \"/home/lpradier/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/lpradier/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InternalError: Failed to load in-memory CUBIN: CUDA_ERROR_OUT_OF_MEMORY: out of memory [Op:__inference__update_step_xla_12849842]\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "2023-09-20 15:06:11.805375: W tensorflow/core/kernels/data/generator_dataset_op.cc:108] Error occurred when finalizing GeneratorDataset iterator: FAILED_PRECONDITION: Python interpreter state is not initialized. The process may be terminated.\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models.py -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-20 15:12:44.184410: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-20 15:12:45.003343: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-20 15:12:45.003389: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-20 15:12:45.003396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "[2023-09-20 15:12:47,303][HYDRA] Updating num of trials to 4 due to using GridSampler.\n",
      "\u001b[32m[I 2023-09-20 15:12:47,303]\u001b[0m A new study created in memory with name: no-name-be64603e-1210-4f72-8d9d-b78a82548d4d\u001b[0m\n",
      "[2023-09-20 15:12:47,303][HYDRA] Study name: no-name-be64603e-1210-4f72-8d9d-b78a82548d4d\n",
      "[2023-09-20 15:12:47,303][HYDRA] Storage: None\n",
      "[2023-09-20 15:12:47,303][HYDRA] Sampler: GridSampler\n",
      "[2023-09-20 15:12:47,303][HYDRA] Directions: ['maximize', 'maximize']\n",
      "[2023-09-20 15:12:47,305][HYDRA] Launching 1 jobs locally\n",
      "[2023-09-20 15:12:47,305][HYDRA] \t#0 : model.model_type=fpn model.backbone=mobilenetv2\n",
      "2023/09/20 15:12:47 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/20 15:12:47 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1_pad (ZeroPadding2D)      (None, 129, 257, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 64, 128, 32)  864         ['Conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 64, 128, 32)  128         ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 64, 128, 32)  0           ['bn_Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 64, 128, 32)  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 64, 128, 32)  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 64, 128, 32)  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                                                           ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 64, 128, 16)  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 64, 128, 16)  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 64, 128, 96)  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 64, 128, 96)  384        ['block_1_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 64, 128, 96)  0           ['block_1_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 65, 129, 96)  0           ['block_1_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 32, 64, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 32, 64, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 32, 64, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 32, 64, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 32, 64, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 32, 64, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 32, 64, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 32, 64, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 32, 64, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 32, 64, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 32, 64, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 32, 64, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 32, 64, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 32, 64, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 32, 64, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 32, 64, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 32, 64, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 33, 65, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 16, 32, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 16, 32, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 16, 32, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 16, 32, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 16, 32, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 16, 32, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 16, 32, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 16, 32, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 16, 32, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 16, 32, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 16, 32, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 16, 32, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 16, 32, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 16, 32, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 16, 32, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 16, 32, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 16, 32, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 16, 32, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 16, 32, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 16, 32, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 16, 32, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 16, 32, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 16, 32, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 16, 32, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 16, 32, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 16, 32, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 17, 33, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 8, 16, 192)  1728        ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 8, 16, 192)  768         ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 8, 16, 192)   0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 8, 16, 64)    12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 8, 16, 384)   24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 8, 16, 384)  1536        ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 8, 16, 384)   0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 8, 16, 384)  3456        ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 8, 16, 384)  1536        ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 8, 16, 384)   0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 8, 16, 64)    24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 8, 16, 64)    0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 8, 16, 384)   24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 8, 16, 384)  1536        ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 8, 16, 384)   0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 8, 16, 384)  3456        ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 8, 16, 384)  1536        ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 8, 16, 384)   0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 8, 16, 64)    24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 8, 16, 64)    0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 8, 16, 384)   24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 8, 16, 384)  1536        ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 8, 16, 384)   0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 8, 16, 384)  3456        ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 8, 16, 384)  1536        ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 8, 16, 384)   0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 8, 16, 64)    24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 8, 16, 64)    0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 8, 16, 384)   24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 8, 16, 384)  1536        ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 8, 16, 384)   0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 8, 16, 384)  3456        ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 8, 16, 384)  1536        ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 8, 16, 384)  0           ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 8, 16, 96)    36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 8, 16, 96)   384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 8, 16, 576)   55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 8, 16, 576)  2304        ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 8, 16, 576)   0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 8, 16, 576)  5184        ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 8, 16, 576)  2304        ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 8, 16, 576)  0           ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 8, 16, 96)    55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 8, 16, 96)   384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 8, 16, 96)    0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 8, 16, 576)   55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 8, 16, 576)  2304        ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 8, 16, 576)   0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 8, 16, 576)  5184        ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 8, 16, 576)  2304        ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 8, 16, 576)  0           ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 8, 16, 96)    55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 8, 16, 96)   384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 8, 16, 96)    0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 8, 16, 576)   55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 8, 16, 576)  2304        ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 8, 16, 576)   0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 9, 17, 576)   0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 4, 8, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 4, 8, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 4, 8, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 4, 8, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 4, 8, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 4, 8, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 4, 8, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 4, 8, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 4, 8, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 4, 8, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 4, 8, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 4, 8, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 4, 8, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 4, 8, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 4, 8, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 4, 8, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 4, 8, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 4, 8, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 4, 8, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 4, 8, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 4, 8, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 4, 8, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 4, 8, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 4, 8, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 4, 8, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 4, 8, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 4, 8, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 4, 8, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 4, 8, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 4, 8, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 4, 8, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 4, 8, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 4, 8, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 4, 8, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " fpn_stage_p5_pre_conv (Conv2D)  (None, 4, 8, 256)   327936      ['out_relu[0][0]']               \n",
      "                                                                                                  \n",
      " fpn_stage_p5_upsampling (UpSam  (None, 8, 16, 256)  0           ['fpn_stage_p5_pre_conv[0][0]']  \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p5_conv (Conv2D)     (None, 8, 16, 256)   147712      ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " fpn_stage_p5_add (Add)         (None, 8, 16, 256)   0           ['fpn_stage_p5_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p5_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p4_upsampling (UpSam  (None, 16, 32, 256)  0          ['fpn_stage_p5_add[0][0]']       \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p4_conv (Conv2D)     (None, 16, 32, 256)  49408       ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " fpn_stage_p4_add (Add)         (None, 16, 32, 256)  0           ['fpn_stage_p4_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p4_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p3_upsampling (UpSam  (None, 32, 64, 256)  0          ['fpn_stage_p4_add[0][0]']       \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p3_conv (Conv2D)     (None, 32, 64, 256)  37120       ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " fpn_stage_p3_add (Add)         (None, 32, 64, 256)  0           ['fpn_stage_p3_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p3_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p2_upsampling (UpSam  (None, 64, 128, 256  0          ['fpn_stage_p3_add[0][0]']       \n",
      " pling2D)                       )                                                                 \n",
      "                                                                                                  \n",
      " fpn_stage_p2_conv (Conv2D)     (None, 64, 128, 256  24832       ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " fpn_stage_p2_add (Add)         (None, 64, 128, 256  0           ['fpn_stage_p2_upsampling[0][0]',\n",
      "                                )                                 'fpn_stage_p2_conv[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage3a_conv (Conv2D)     (None, 32, 64, 128)  294912      ['fpn_stage_p3_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage4a_conv (Conv2D)     (None, 16, 32, 128)  294912      ['fpn_stage_p4_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage5a_conv (Conv2D)     (None, 8, 16, 128)   294912      ['fpn_stage_p5_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage2a_conv (Conv2D)     (None, 64, 128, 128  294912      ['fpn_stage_p2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3a_bn (BatchNormaliz  (None, 32, 64, 128)  512        ['segm_stage3a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage4a_bn (BatchNormaliz  (None, 16, 32, 128)  512        ['segm_stage4a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage5a_bn (BatchNormaliz  (None, 8, 16, 128)  512         ['segm_stage5a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage2a_bn (BatchNormaliz  (None, 64, 128, 128  512        ['segm_stage2a_conv[0][0]']      \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3a_relu (Activation)  (None, 32, 64, 128)  0          ['segm_stage3a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage4a_relu (Activation)  (None, 16, 32, 128)  0          ['segm_stage4a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage5a_relu (Activation)  (None, 8, 16, 128)  0           ['segm_stage5a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage2a_relu (Activation)  (None, 64, 128, 128  0          ['segm_stage2a_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_conv (Conv2D)     (None, 32, 64, 128)  147456      ['segm_stage3a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage4b_conv (Conv2D)     (None, 16, 32, 128)  147456      ['segm_stage4a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage5b_conv (Conv2D)     (None, 8, 16, 128)   147456      ['segm_stage5a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage2b_conv (Conv2D)     (None, 64, 128, 128  147456      ['segm_stage2a_relu[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_bn (BatchNormaliz  (None, 32, 64, 128)  512        ['segm_stage3b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage4b_bn (BatchNormaliz  (None, 16, 32, 128)  512        ['segm_stage4b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage5b_bn (BatchNormaliz  (None, 8, 16, 128)  512         ['segm_stage5b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage2b_bn (BatchNormaliz  (None, 64, 128, 128  512        ['segm_stage2b_conv[0][0]']      \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_relu (Activation)  (None, 32, 64, 128)  0          ['segm_stage3b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage4b_relu (Activation)  (None, 16, 32, 128)  0          ['segm_stage4b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage5b_relu (Activation)  (None, 8, 16, 128)  0           ['segm_stage5b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage2b_relu (Activation)  (None, 64, 128, 128  0          ['segm_stage2b_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage3 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage3b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage4 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage4b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage5 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage5b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " aggregation_concat (Concatenat  (None, 64, 128, 512  0          ['segm_stage2b_relu[0][0]',      \n",
      " e)                             )                                 'upsampling_stage3[0][0]',      \n",
      "                                                                  'upsampling_stage4[0][0]',      \n",
      "                                                                  'upsampling_stage5[0][0]']      \n",
      "                                                                                                  \n",
      " final_stage_conv (Conv2D)      (None, 64, 128, 128  589824      ['aggregation_concat[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " final_stage_bn (BatchNormaliza  (None, 64, 128, 128  512        ['final_stage_conv[0][0]']       \n",
      " tion)                          )                                                                 \n",
      "                                                                                                  \n",
      " final_stage_relu (Activation)  (None, 64, 128, 128  0           ['final_stage_bn[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " final_upsampling (UpSampling2D  (None, 128, 256, 12  0          ['final_stage_relu[0][0]']       \n",
      " )                              8)                                                                \n",
      "                                                                                                  \n",
      " head_conv (Conv2D)             (None, 128, 256, 8)  9224        ['final_upsampling[0][0]']       \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 128, 256, 8)  0           ['head_conv[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,218,120\n",
      "Trainable params: 5,181,704\n",
      "Non-trainable params: 36,416\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f757c1bab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f757c1bab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f757c1bab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f757c1bab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 67s - loss: 0.2803 - iou_score: 0.6052 - f1-score: 0.7190 - val_loss: 0.7201 - val_iou_score: 0.2163 - val_f1-score: 0.2790 - 67s/epoch - 427ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 49s - loss: 0.2129 - iou_score: 0.6783 - f1-score: 0.7858 - val_loss: 0.7600 - val_iou_score: 0.1712 - val_f1-score: 0.2404 - 49s/epoch - 311ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 49s - loss: 0.1972 - iou_score: 0.6969 - f1-score: 0.8015 - val_loss: 0.7757 - val_iou_score: 0.1545 - val_f1-score: 0.2241 - 49s/epoch - 312ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 47s - loss: 0.1859 - iou_score: 0.7105 - f1-score: 0.8133 - val_loss: 0.7254 - val_iou_score: 0.2084 - val_f1-score: 0.2751 - 47s/epoch - 302ms/step\n",
      "<keras.callbacks.History object at 0x7f758825f820>\n",
      "2023/09/20 15:16:29 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 67). These functions will not be directly callable after loading.\n",
      "2023/09/20 15:16:44 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp5hk0jxe4/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/20 15:16:44 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/20 15:16:44 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/20 15:16:44 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 8\n",
      "Created version '8' of model 'fpn'.\n",
      "[2023-09-20 15:16:44,555][HYDRA] Launching 1 jobs locally\n",
      "[2023-09-20 15:16:44,555][HYDRA] \t#1 : model.model_type=unet model.backbone=mobilenetv2\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1_pad (ZeroPadding2D)      (None, 129, 257, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 64, 128, 32)  864         ['Conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 64, 128, 32)  128         ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 64, 128, 32)  0           ['bn_Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 64, 128, 32)  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 64, 128, 32)  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 64, 128, 32)  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                                                           ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 64, 128, 16)  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 64, 128, 16)  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 64, 128, 96)  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 64, 128, 96)  384        ['block_1_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 64, 128, 96)  0           ['block_1_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 65, 129, 96)  0           ['block_1_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 32, 64, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 32, 64, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 32, 64, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 32, 64, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 32, 64, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 32, 64, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 32, 64, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 32, 64, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 32, 64, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 32, 64, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 32, 64, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 32, 64, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 32, 64, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 32, 64, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 32, 64, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 32, 64, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 32, 64, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 33, 65, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 16, 32, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 16, 32, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 16, 32, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 16, 32, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 16, 32, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 16, 32, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 16, 32, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 16, 32, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 16, 32, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 16, 32, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 16, 32, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 16, 32, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 16, 32, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 16, 32, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 16, 32, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 16, 32, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 16, 32, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 16, 32, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 16, 32, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 16, 32, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 16, 32, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 16, 32, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 16, 32, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 16, 32, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 16, 32, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 16, 32, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 17, 33, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 8, 16, 192)  1728        ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 8, 16, 192)  768         ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 8, 16, 192)   0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 8, 16, 64)    12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 8, 16, 384)   24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 8, 16, 384)  1536        ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 8, 16, 384)   0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 8, 16, 384)  3456        ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 8, 16, 384)  1536        ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 8, 16, 384)   0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 8, 16, 64)    24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 8, 16, 64)    0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 8, 16, 384)   24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 8, 16, 384)  1536        ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 8, 16, 384)   0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 8, 16, 384)  3456        ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 8, 16, 384)  1536        ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 8, 16, 384)   0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 8, 16, 64)    24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 8, 16, 64)    0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 8, 16, 384)   24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 8, 16, 384)  1536        ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 8, 16, 384)   0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 8, 16, 384)  3456        ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 8, 16, 384)  1536        ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 8, 16, 384)   0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 8, 16, 64)    24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 8, 16, 64)   256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 8, 16, 64)    0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 8, 16, 384)   24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 8, 16, 384)  1536        ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 8, 16, 384)   0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 8, 16, 384)  3456        ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 8, 16, 384)  1536        ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 8, 16, 384)  0           ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 8, 16, 96)    36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 8, 16, 96)   384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 8, 16, 576)   55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 8, 16, 576)  2304        ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 8, 16, 576)   0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 8, 16, 576)  5184        ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 8, 16, 576)  2304        ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 8, 16, 576)  0           ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 8, 16, 96)    55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 8, 16, 96)   384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 8, 16, 96)    0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 8, 16, 576)   55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 8, 16, 576)  2304        ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 8, 16, 576)   0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 8, 16, 576)  5184        ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 8, 16, 576)  2304        ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 8, 16, 576)  0           ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 8, 16, 96)    55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 8, 16, 96)   384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 8, 16, 96)    0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 8, 16, 576)   55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 8, 16, 576)  2304        ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 8, 16, 576)   0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 9, 17, 576)   0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 4, 8, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 4, 8, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 4, 8, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 4, 8, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 4, 8, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 4, 8, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 4, 8, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 4, 8, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 4, 8, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 4, 8, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 4, 8, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 4, 8, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 4, 8, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 4, 8, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 4, 8, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 4, 8, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 4, 8, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 4, 8, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 4, 8, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 4, 8, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 4, 8, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 4, 8, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 4, 8, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 4, 8, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 4, 8, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 4, 8, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 4, 8, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 4, 8, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 4, 8, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 4, 8, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 4, 8, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 4, 8, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 4, 8, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 4, 8, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " decoder_stage0_upsampling (UpS  (None, 8, 16, 1280)  0          ['out_relu[0][0]']               \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage0_concat (Concate  (None, 8, 16, 1856)  0          ['decoder_stage0_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage0a_conv (Conv2D)  (None, 8, 16, 256)   4276224     ['decoder_stage0_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage0a_bn (BatchNorma  (None, 8, 16, 256)  1024        ['decoder_stage0a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage0a_relu (Activati  (None, 8, 16, 256)  0           ['decoder_stage0a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage0b_conv (Conv2D)  (None, 8, 16, 256)   589824      ['decoder_stage0a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage0b_bn (BatchNorma  (None, 8, 16, 256)  1024        ['decoder_stage0b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage0b_relu (Activati  (None, 8, 16, 256)  0           ['decoder_stage0b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1_upsampling (UpS  (None, 16, 32, 256)  0          ['decoder_stage0b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage1_concat (Concate  (None, 16, 32, 448)  0          ['decoder_stage1_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " decoder_stage1a_conv (Conv2D)  (None, 16, 32, 128)  516096      ['decoder_stage1_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage1a_bn (BatchNorma  (None, 16, 32, 128)  512        ['decoder_stage1a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage1a_relu (Activati  (None, 16, 32, 128)  0          ['decoder_stage1a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1b_conv (Conv2D)  (None, 16, 32, 128)  147456      ['decoder_stage1a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage1b_bn (BatchNorma  (None, 16, 32, 128)  512        ['decoder_stage1b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage1b_relu (Activati  (None, 16, 32, 128)  0          ['decoder_stage1b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2_upsampling (UpS  (None, 32, 64, 128)  0          ['decoder_stage1b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage2_concat (Concate  (None, 32, 64, 272)  0          ['decoder_stage2_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " decoder_stage2a_conv (Conv2D)  (None, 32, 64, 64)   156672      ['decoder_stage2_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage2a_bn (BatchNorma  (None, 32, 64, 64)  256         ['decoder_stage2a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage2a_relu (Activati  (None, 32, 64, 64)  0           ['decoder_stage2a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2b_conv (Conv2D)  (None, 32, 64, 64)   36864       ['decoder_stage2a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage2b_bn (BatchNorma  (None, 32, 64, 64)  256         ['decoder_stage2b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage2b_relu (Activati  (None, 32, 64, 64)  0           ['decoder_stage2b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage3_upsampling (UpS  (None, 64, 128, 64)  0          ['decoder_stage2b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage3_concat (Concate  (None, 64, 128, 160  0          ['decoder_stage3_upsampling[0][0]\n",
      " nate)                          )                                ',                               \n",
      "                                                                  'block_1_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " decoder_stage3a_conv (Conv2D)  (None, 64, 128, 32)  46080       ['decoder_stage3_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage3a_bn (BatchNorma  (None, 64, 128, 32)  128        ['decoder_stage3a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage3a_relu (Activati  (None, 64, 128, 32)  0          ['decoder_stage3a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage3b_conv (Conv2D)  (None, 64, 128, 32)  9216        ['decoder_stage3a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage3b_bn (BatchNorma  (None, 64, 128, 32)  128        ['decoder_stage3b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage3b_relu (Activati  (None, 64, 128, 32)  0          ['decoder_stage3b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage4_upsampling (UpS  (None, 128, 256, 32  0          ['decoder_stage3b_relu[0][0]']   \n",
      " ampling2D)                     )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4a_conv (Conv2D)  (None, 128, 256, 16  4608        ['decoder_stage4_upsampling[0][0]\n",
      "                                )                                ']                               \n",
      "                                                                                                  \n",
      " decoder_stage4a_bn (BatchNorma  (None, 128, 256, 16  64         ['decoder_stage4a_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4a_relu (Activati  (None, 128, 256, 16  0          ['decoder_stage4a_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_conv (Conv2D)  (None, 128, 256, 16  2304        ['decoder_stage4a_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_bn (BatchNorma  (None, 128, 256, 16  64         ['decoder_stage4b_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_relu (Activati  (None, 128, 256, 16  0          ['decoder_stage4b_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " final_conv (Conv2D)            (None, 128, 256, 8)  1160        ['decoder_stage4b_relu[0][0]']   \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 128, 256, 8)  0           ['final_conv[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,048,456\n",
      "Trainable params: 8,012,360\n",
      "Non-trainable params: 36,096\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "156/156 - 59s - loss: 0.3764 - iou_score: 0.5142 - f1-score: 0.6228 - val_loss: 0.7866 - val_iou_score: 0.1376 - val_f1-score: 0.2129 - 59s/epoch - 379ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 46s - loss: 0.2324 - iou_score: 0.6579 - f1-score: 0.7664 - val_loss: 0.6815 - val_iou_score: 0.2344 - val_f1-score: 0.3190 - 46s/epoch - 297ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 47s - loss: 0.2107 - iou_score: 0.6822 - f1-score: 0.7885 - val_loss: 0.8532 - val_iou_score: 0.0983 - val_f1-score: 0.1469 - 47s/epoch - 299ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 46s - loss: 0.1982 - iou_score: 0.6962 - f1-score: 0.8009 - val_loss: 0.9075 - val_iou_score: 0.0542 - val_f1-score: 0.0929 - 46s/epoch - 297ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 47s - loss: 0.1902 - iou_score: 0.7069 - f1-score: 0.8092 - val_loss: 0.8611 - val_iou_score: 0.0829 - val_f1-score: 0.1381 - 47s/epoch - 302ms/step\n",
      "<keras.callbacks.History object at 0x7f76c4c87640>\n",
      "2023/09/20 15:21:00 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "[2023-09-20 15:21:09,132][absl][WARNING] - Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 63). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpwxi3j7jv/model/data/model/assets\n",
      "[2023-09-20 15:21:12,295][tensorflow][INFO] - Assets written to: /tmp/tmpwxi3j7jv/model/data/model/assets\n",
      "2023/09/20 15:21:15 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpwxi3j7jv/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "Registered model 'unet' already exists. Creating a new version of this model...\n",
      "2023/09/20 15:21:15 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: unet, version 11\n",
      "Created version '11' of model 'unet'.\n",
      "[2023-09-20 15:21:15,500][HYDRA] Launching 1 jobs locally\n",
      "[2023-09-20 15:21:15,500][HYDRA] \t#2 : model.model_type=unet model.backbone=resnet101\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data (InputLayer)              [(None, 128, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " bn_data (BatchNormalization)   (None, 128, 256, 3)  9           ['data[0][0]']                   \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 134, 262, 3)  0          ['bn_data[0][0]']                \n",
      "                                                                                                  \n",
      " conv0 (Conv2D)                 (None, 64, 128, 64)  9408        ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " bn0 (BatchNormalization)       (None, 64, 128, 64)  256         ['conv0[0][0]']                  \n",
      "                                                                                                  \n",
      " relu0 (Activation)             (None, 64, 128, 64)  0           ['bn0[0][0]']                    \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 66, 130, 64)  0          ['relu0[0][0]']                  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " pooling0 (MaxPooling2D)        (None, 32, 64, 64)   0           ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit1_bn1 (BatchNormali  (None, 32, 64, 64)  256         ['pooling0[0][0]']               \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu1 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit1_conv1 (Conv2D)    (None, 32, 64, 64)   4096        ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit1_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadding2  (None, 34, 66, 64)  0           ['stage1_unit1_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage1_unit1_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_2[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit1_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit1_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit1_sc (Conv2D)       (None, 32, 64, 256)  16384       ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 64, 256)  0           ['stage1_unit1_conv3[0][0]',     \n",
      "                                                                  'stage1_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage1_unit2_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add[0][0]']                    \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu1 (Activation  (None, 32, 64, 256)  0          ['stage1_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit2_conv1 (Conv2D)    (None, 32, 64, 64)   16384       ['stage1_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit2_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadding2  (None, 34, 66, 64)  0           ['stage1_unit2_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage1_unit2_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_3[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit2_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit2_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 64, 256)  0           ['stage1_unit2_conv3[0][0]',     \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " stage1_unit3_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add_1[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu1 (Activation  (None, 32, 64, 256)  0          ['stage1_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit3_conv1 (Conv2D)    (None, 32, 64, 64)   16384       ['stage1_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit3_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 34, 66, 64)  0           ['stage1_unit3_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage1_unit3_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_4[0][0]']       \n",
      "                                                                                                  \n",
      " stage1_unit3_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit3_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 64, 256)  0           ['stage1_unit3_conv3[0][0]',     \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " stage2_unit1_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add_2[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu1 (Activation  (None, 32, 64, 256)  0          ['stage2_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit1_conv1 (Conv2D)    (None, 32, 64, 128)  32768       ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit1_bn2 (BatchNormali  (None, 32, 64, 128)  512        ['stage2_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu2 (Activation  (None, 32, 64, 128)  0          ['stage2_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadding2  (None, 34, 66, 128)  0          ['stage2_unit1_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit1_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_5[0][0]']       \n",
      "                                                                                                  \n",
      " stage2_unit1_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit1_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit1_sc (Conv2D)       (None, 16, 32, 512)  131072      ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 16, 32, 512)  0           ['stage2_unit1_conv3[0][0]',     \n",
      "                                                                  'stage2_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage2_unit2_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_3[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit2_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit2_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadding2  (None, 18, 34, 128)  0          ['stage2_unit2_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit2_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_6[0][0]']       \n",
      "                                                                                                  \n",
      " stage2_unit2_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit2_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 16, 32, 512)  0           ['stage2_unit2_conv3[0][0]',     \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " stage2_unit3_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_4[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit3_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit3_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadding2  (None, 18, 34, 128)  0          ['stage2_unit3_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit3_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_7[0][0]']       \n",
      "                                                                                                  \n",
      " stage2_unit3_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit3_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 16, 32, 512)  0           ['stage2_unit3_conv3[0][0]',     \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " stage2_unit4_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_5[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit4_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit4_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit4_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit4_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit4_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit4_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_8 (ZeroPadding2  (None, 18, 34, 128)  0          ['stage2_unit4_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage2_unit4_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_8[0][0]']       \n",
      "                                                                                                  \n",
      " stage2_unit4_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit4_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit4_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit4_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit4_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 16, 32, 512)  0           ['stage2_unit4_conv3[0][0]',     \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " stage3_unit1_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_6[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu1 (Activation  (None, 16, 32, 512)  0          ['stage3_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit1_conv1 (Conv2D)    (None, 16, 32, 256)  131072      ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit1_bn2 (BatchNormali  (None, 16, 32, 256)  1024       ['stage3_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu2 (Activation  (None, 16, 32, 256)  0          ['stage3_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_9 (ZeroPadding2  (None, 18, 34, 256)  0          ['stage3_unit1_relu2[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit1_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_9[0][0]']       \n",
      "                                                                                                  \n",
      " stage3_unit1_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit1_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit1_sc (Conv2D)       (None, 8, 16, 1024)  524288      ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 8, 16, 1024)  0           ['stage3_unit1_conv3[0][0]',     \n",
      "                                                                  'stage3_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage3_unit2_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_7[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit2_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit2_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_10 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit2_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_10[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit2_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit2_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 8, 16, 1024)  0           ['stage3_unit2_conv3[0][0]',     \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " stage3_unit3_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_8[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit3_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit3_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_11 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit3_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_11[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit3_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit3_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 8, 16, 1024)  0           ['stage3_unit3_conv3[0][0]',     \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " stage3_unit4_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_9[0][0]']                  \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit4_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit4_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit4_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit4_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit4_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit4_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_12 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit4_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit4_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_12[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit4_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit4_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit4_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit4_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit4_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit4_conv3[0][0]',     \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " stage3_unit5_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_10[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit5_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit5_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit5_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit5_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit5_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit5_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_13 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit5_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit5_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_13[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit5_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit5_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit5_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit5_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit5_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit5_conv3[0][0]',     \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit6_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_11[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit6_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit6_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit6_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit6_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit6_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit6_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_14 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit6_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit6_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_14[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit6_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit6_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit6_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit6_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit6_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit6_conv3[0][0]',     \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit7_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_12[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit7_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit7_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit7_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit7_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit7_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit7_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_15 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit7_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit7_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_15[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit7_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit7_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit7_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit7_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit7_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit7_conv3[0][0]',     \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit8_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_13[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit8_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit8_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit8_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit8_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit8_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit8_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_16 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit8_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit8_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_16[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit8_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit8_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit8_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit8_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit8_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit8_conv3[0][0]',     \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit9_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_14[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit9_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit9_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit9_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit9_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit9_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit9_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_17 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit9_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit9_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_17[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit9_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit9_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit9_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit9_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit9_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit9_conv3[0][0]',     \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit10_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_15[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit10_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit10_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit10_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit10_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit10_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit10_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_18 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit10_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit10_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_18[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit10_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit10_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit10_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit10_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit10_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit10_conv3[0][0]',    \n",
      "                                                                  'add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit11_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_16[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit11_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit11_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit11_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit11_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit11_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit11_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_19 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit11_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit11_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_19[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit11_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit11_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit11_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit11_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit11_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit11_conv3[0][0]',    \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit12_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_17[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit12_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit12_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit12_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit12_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit12_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit12_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_20 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit12_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit12_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_20[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit12_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit12_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit12_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit12_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit12_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit12_conv3[0][0]',    \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit13_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_18[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit13_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit13_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit13_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit13_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit13_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit13_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_21 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit13_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit13_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_21[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit13_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit13_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit13_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit13_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit13_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit13_conv3[0][0]',    \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit14_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_19[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit14_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit14_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit14_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit14_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit14_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit14_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_22 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit14_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit14_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_22[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit14_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit14_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit14_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit14_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit14_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit14_conv3[0][0]',    \n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit15_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_20[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit15_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit15_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit15_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit15_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit15_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit15_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_23 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit15_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit15_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_23[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit15_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit15_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit15_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit15_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit15_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit15_conv3[0][0]',    \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit16_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_21[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit16_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit16_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit16_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit16_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit16_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit16_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_24 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit16_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit16_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_24[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit16_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit16_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit16_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit16_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit16_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit16_conv3[0][0]',    \n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit17_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_22[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit17_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit17_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit17_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit17_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit17_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit17_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_25 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit17_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit17_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_25[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit17_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit17_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit17_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit17_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit17_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit17_conv3[0][0]',    \n",
      "                                                                  'add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit18_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_23[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit18_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit18_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit18_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit18_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit18_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit18_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_26 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit18_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit18_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_26[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit18_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit18_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit18_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit18_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit18_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit18_conv3[0][0]',    \n",
      "                                                                  'add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit19_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_24[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit19_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit19_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit19_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit19_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit19_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit19_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_27 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit19_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit19_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_27[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit19_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit19_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit19_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit19_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit19_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit19_conv3[0][0]',    \n",
      "                                                                  'add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit20_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_25[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit20_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit20_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit20_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit20_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit20_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit20_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_28 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit20_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit20_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_28[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit20_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit20_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit20_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit20_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit20_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit20_conv3[0][0]',    \n",
      "                                                                  'add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit21_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_26[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit21_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit21_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit21_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit21_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit21_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit21_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_29 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit21_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit21_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_29[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit21_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit21_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit21_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit21_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit21_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit21_conv3[0][0]',    \n",
      "                                                                  'add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit22_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_27[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit22_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit22_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit22_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit22_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit22_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit22_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_30 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit22_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit22_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_30[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit22_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit22_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit22_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit22_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit22_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit22_conv3[0][0]',    \n",
      "                                                                  'add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit23_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_28[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit23_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit23_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit23_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit23_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit23_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit23_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_31 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit23_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit23_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_31[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit23_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit23_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit23_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit23_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit23_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit23_conv3[0][0]',    \n",
      "                                                                  'add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " stage4_unit1_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_29[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage4_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit1_conv1 (Conv2D)    (None, 8, 16, 512)   524288      ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit1_bn2 (BatchNormali  (None, 8, 16, 512)  2048        ['stage4_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu2 (Activation  (None, 8, 16, 512)  0           ['stage4_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_32 (ZeroPadding  (None, 10, 18, 512)  0          ['stage4_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit1_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_32[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit1_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit1_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit1_sc (Conv2D)       (None, 4, 8, 2048)   2097152     ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit1_conv3[0][0]',     \n",
      "                                                                  'stage4_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage4_unit2_bn1 (BatchNormali  (None, 4, 8, 2048)  8192        ['add_30[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu1 (Activation  (None, 4, 8, 2048)  0           ['stage4_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit2_conv1 (Conv2D)    (None, 4, 8, 512)    1048576     ['stage4_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit2_bn2 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu2 (Activation  (None, 4, 8, 512)   0           ['stage4_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_33 (ZeroPadding  (None, 6, 10, 512)  0           ['stage4_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit2_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_33[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit2_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit2_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit2_conv3[0][0]',     \n",
      "                                                                  'add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " stage4_unit3_bn1 (BatchNormali  (None, 4, 8, 2048)  8192        ['add_31[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu1 (Activation  (None, 4, 8, 2048)  0           ['stage4_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit3_conv1 (Conv2D)    (None, 4, 8, 512)    1048576     ['stage4_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit3_bn2 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu2 (Activation  (None, 4, 8, 512)   0           ['stage4_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_34 (ZeroPadding  (None, 6, 10, 512)  0           ['stage4_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit3_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_34[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit3_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit3_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit3_conv3[0][0]',     \n",
      "                                                                  'add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 4, 8, 2048)   8192        ['add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 4, 8, 2048)   0           ['bn1[0][0]']                    \n",
      "                                                                                                  \n",
      " decoder_stage0_upsampling (UpS  (None, 8, 16, 2048)  0          ['relu1[0][0]']                  \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage0_concat (Concate  (None, 8, 16, 3072)  0          ['decoder_stage0_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " decoder_stage0a_conv (Conv2D)  (None, 8, 16, 256)   7077888     ['decoder_stage0_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage0a_bn (BatchNorma  (None, 8, 16, 256)  1024        ['decoder_stage0a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage0a_relu (Activati  (None, 8, 16, 256)  0           ['decoder_stage0a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage0b_conv (Conv2D)  (None, 8, 16, 256)   589824      ['decoder_stage0a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage0b_bn (BatchNorma  (None, 8, 16, 256)  1024        ['decoder_stage0b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage0b_relu (Activati  (None, 8, 16, 256)  0           ['decoder_stage0b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1_upsampling (UpS  (None, 16, 32, 256)  0          ['decoder_stage0b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage1_concat (Concate  (None, 16, 32, 768)  0          ['decoder_stage1_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " decoder_stage1a_conv (Conv2D)  (None, 16, 32, 128)  884736      ['decoder_stage1_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage1a_bn (BatchNorma  (None, 16, 32, 128)  512        ['decoder_stage1a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage1a_relu (Activati  (None, 16, 32, 128)  0          ['decoder_stage1a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1b_conv (Conv2D)  (None, 16, 32, 128)  147456      ['decoder_stage1a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage1b_bn (BatchNorma  (None, 16, 32, 128)  512        ['decoder_stage1b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage1b_relu (Activati  (None, 16, 32, 128)  0          ['decoder_stage1b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2_upsampling (UpS  (None, 32, 64, 128)  0          ['decoder_stage1b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage2_concat (Concate  (None, 32, 64, 384)  0          ['decoder_stage2_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " decoder_stage2a_conv (Conv2D)  (None, 32, 64, 64)   221184      ['decoder_stage2_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage2a_bn (BatchNorma  (None, 32, 64, 64)  256         ['decoder_stage2a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage2a_relu (Activati  (None, 32, 64, 64)  0           ['decoder_stage2a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2b_conv (Conv2D)  (None, 32, 64, 64)   36864       ['decoder_stage2a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage2b_bn (BatchNorma  (None, 32, 64, 64)  256         ['decoder_stage2b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage2b_relu (Activati  (None, 32, 64, 64)  0           ['decoder_stage2b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage3_upsampling (UpS  (None, 64, 128, 64)  0          ['decoder_stage2b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage3_concat (Concate  (None, 64, 128, 128  0          ['decoder_stage3_upsampling[0][0]\n",
      " nate)                          )                                ',                               \n",
      "                                                                  'relu0[0][0]']                  \n",
      "                                                                                                  \n",
      " decoder_stage3a_conv (Conv2D)  (None, 64, 128, 32)  36864       ['decoder_stage3_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage3a_bn (BatchNorma  (None, 64, 128, 32)  128        ['decoder_stage3a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage3a_relu (Activati  (None, 64, 128, 32)  0          ['decoder_stage3a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage3b_conv (Conv2D)  (None, 64, 128, 32)  9216        ['decoder_stage3a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage3b_bn (BatchNorma  (None, 64, 128, 32)  128        ['decoder_stage3b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage3b_relu (Activati  (None, 64, 128, 32)  0          ['decoder_stage3b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage4_upsampling (UpS  (None, 128, 256, 32  0          ['decoder_stage3b_relu[0][0]']   \n",
      " ampling2D)                     )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4a_conv (Conv2D)  (None, 128, 256, 16  4608        ['decoder_stage4_upsampling[0][0]\n",
      "                                )                                ']                               \n",
      "                                                                                                  \n",
      " decoder_stage4a_bn (BatchNorma  (None, 128, 256, 16  64         ['decoder_stage4a_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4a_relu (Activati  (None, 128, 256, 16  0          ['decoder_stage4a_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_conv (Conv2D)  (None, 128, 256, 16  2304        ['decoder_stage4a_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_bn (BatchNorma  (None, 128, 256, 16  64         ['decoder_stage4b_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_relu (Activati  (None, 128, 256, 16  0          ['decoder_stage4b_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " final_conv (Conv2D)            (None, 128, 256, 8)  1160        ['decoder_stage4b_relu[0][0]']   \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 128, 256, 8)  0           ['final_conv[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51,606,481\n",
      "Trainable params: 51,506,699\n",
      "Non-trainable params: 99,782\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "156/156 - 91s - loss: 0.4135 - iou_score: 0.4738 - f1-score: 0.5862 - val_loss: 0.7643 - val_iou_score: 0.1564 - val_f1-score: 0.2354 - 91s/epoch - 583ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 66s - loss: 0.2589 - iou_score: 0.6270 - f1-score: 0.7401 - val_loss: 0.7395 - val_iou_score: 0.2019 - val_f1-score: 0.2607 - 66s/epoch - 426ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 70s - loss: 0.2451 - iou_score: 0.6409 - f1-score: 0.7537 - val_loss: 0.7364 - val_iou_score: 0.2087 - val_f1-score: 0.2630 - 70s/epoch - 446ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 72s - loss: 0.2240 - iou_score: 0.6649 - f1-score: 0.7746 - val_loss: 0.7442 - val_iou_score: 0.1974 - val_f1-score: 0.2571 - 72s/epoch - 459ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 71s - loss: 0.2323 - iou_score: 0.6551 - f1-score: 0.7671 - val_loss: 0.5569 - val_iou_score: 0.3306 - val_f1-score: 0.4417 - 71s/epoch - 455ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 71s - loss: 0.2111 - iou_score: 0.6802 - f1-score: 0.7881 - val_loss: 0.6592 - val_iou_score: 0.2579 - val_f1-score: 0.3397 - 71s/epoch - 455ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 71s - loss: 0.2038 - iou_score: 0.6888 - f1-score: 0.7952 - val_loss: 0.3471 - val_iou_score: 0.5238 - val_f1-score: 0.6522 - 71s/epoch - 455ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 71s - loss: 0.1941 - iou_score: 0.7002 - f1-score: 0.8046 - val_loss: 0.2752 - val_iou_score: 0.6025 - val_f1-score: 0.7249 - 71s/epoch - 458ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 71s - loss: 0.1872 - iou_score: 0.7090 - f1-score: 0.8121 - val_loss: 0.2205 - val_iou_score: 0.6661 - val_f1-score: 0.7786 - 71s/epoch - 453ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 71s - loss: 0.1838 - iou_score: 0.7130 - f1-score: 0.8150 - val_loss: 0.2569 - val_iou_score: 0.6198 - val_f1-score: 0.7410 - 71s/epoch - 457ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 70s - loss: 0.1795 - iou_score: 0.7187 - f1-score: 0.8199 - val_loss: 0.2850 - val_iou_score: 0.5886 - val_f1-score: 0.7128 - 70s/epoch - 451ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 72s - loss: 0.1754 - iou_score: 0.7243 - f1-score: 0.8244 - val_loss: 0.2183 - val_iou_score: 0.6721 - val_f1-score: 0.7825 - 72s/epoch - 459ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 72s - loss: 0.1712 - iou_score: 0.7287 - f1-score: 0.8280 - val_loss: 0.2226 - val_iou_score: 0.6654 - val_f1-score: 0.7771 - 72s/epoch - 462ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 72s - loss: 0.1666 - iou_score: 0.7341 - f1-score: 0.8324 - val_loss: 0.2168 - val_iou_score: 0.6746 - val_f1-score: 0.7834 - 72s/epoch - 461ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 70s - loss: 0.1636 - iou_score: 0.7385 - f1-score: 0.8359 - val_loss: 0.2590 - val_iou_score: 0.6201 - val_f1-score: 0.7391 - 70s/epoch - 447ms/step\n",
      "<keras.callbacks.History object at 0x7f755ff4f250>\n",
      "2023/09/20 15:39:42 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "[2023-09-20 15:39:59,335][absl][WARNING] - Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 115). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp325y3g9d/model/data/model/assets\n",
      "[2023-09-20 15:40:05,516][tensorflow][INFO] - Assets written to: /tmp/tmp325y3g9d/model/data/model/assets\n",
      "2023/09/20 15:40:20 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp325y3g9d/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "Registered model 'unet' already exists. Creating a new version of this model...\n",
      "2023/09/20 15:40:20 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: unet, version 12\n",
      "Created version '12' of model 'unet'.\n",
      "[2023-09-20 15:40:20,625][HYDRA] Launching 1 jobs locally\n",
      "[2023-09-20 15:40:20,625][HYDRA] \t#3 : model.model_type=fpn model.backbone=resnet101\n",
      "/home/lpradier/.local/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data (InputLayer)              [(None, 128, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " bn_data (BatchNormalization)   (None, 128, 256, 3)  9           ['data[0][0]']                   \n",
      "                                                                                                  \n",
      " zero_padding2d_35 (ZeroPadding  (None, 134, 262, 3)  0          ['bn_data[0][0]']                \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv0 (Conv2D)                 (None, 64, 128, 64)  9408        ['zero_padding2d_35[0][0]']      \n",
      "                                                                                                  \n",
      " bn0 (BatchNormalization)       (None, 64, 128, 64)  256         ['conv0[0][0]']                  \n",
      "                                                                                                  \n",
      " relu0 (Activation)             (None, 64, 128, 64)  0           ['bn0[0][0]']                    \n",
      "                                                                                                  \n",
      " zero_padding2d_36 (ZeroPadding  (None, 66, 130, 64)  0          ['relu0[0][0]']                  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pooling0 (MaxPooling2D)        (None, 32, 64, 64)   0           ['zero_padding2d_36[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit1_bn1 (BatchNormali  (None, 32, 64, 64)  256         ['pooling0[0][0]']               \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu1 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit1_conv1 (Conv2D)    (None, 32, 64, 64)   4096        ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit1_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_37 (ZeroPadding  (None, 34, 66, 64)  0           ['stage1_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit1_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_37[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit1_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit1_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit1_sc (Conv2D)       (None, 32, 64, 256)  16384       ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 32, 64, 256)  0           ['stage1_unit1_conv3[0][0]',     \n",
      "                                                                  'stage1_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage1_unit2_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add_33[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu1 (Activation  (None, 32, 64, 256)  0          ['stage1_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit2_conv1 (Conv2D)    (None, 32, 64, 64)   16384       ['stage1_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit2_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_38 (ZeroPadding  (None, 34, 66, 64)  0           ['stage1_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit2_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_38[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit2_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit2_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 32, 64, 256)  0           ['stage1_unit2_conv3[0][0]',     \n",
      "                                                                  'add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " stage1_unit3_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add_34[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu1 (Activation  (None, 32, 64, 256)  0          ['stage1_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit3_conv1 (Conv2D)    (None, 32, 64, 64)   16384       ['stage1_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage1_unit3_bn2 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu2 (Activation  (None, 32, 64, 64)  0           ['stage1_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_39 (ZeroPadding  (None, 34, 66, 64)  0           ['stage1_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit3_conv2 (Conv2D)    (None, 32, 64, 64)   36864       ['zero_padding2d_39[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit3_bn3 (BatchNormali  (None, 32, 64, 64)  256         ['stage1_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu3 (Activation  (None, 32, 64, 64)  0           ['stage1_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage1_unit3_conv3 (Conv2D)    (None, 32, 64, 256)  16384       ['stage1_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 32, 64, 256)  0           ['stage1_unit3_conv3[0][0]',     \n",
      "                                                                  'add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit1_bn1 (BatchNormali  (None, 32, 64, 256)  1024       ['add_35[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu1 (Activation  (None, 32, 64, 256)  0          ['stage2_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit1_conv1 (Conv2D)    (None, 32, 64, 128)  32768       ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit1_bn2 (BatchNormali  (None, 32, 64, 128)  512        ['stage2_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu2 (Activation  (None, 32, 64, 128)  0          ['stage2_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_40 (ZeroPadding  (None, 34, 66, 128)  0          ['stage2_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit1_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_40[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit1_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit1_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit1_sc (Conv2D)       (None, 16, 32, 512)  131072      ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 16, 32, 512)  0           ['stage2_unit1_conv3[0][0]',     \n",
      "                                                                  'stage2_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage2_unit2_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_36[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit2_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit2_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_41 (ZeroPadding  (None, 18, 34, 128)  0          ['stage2_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit2_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_41[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit2_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit2_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, 16, 32, 512)  0           ['stage2_unit2_conv3[0][0]',     \n",
      "                                                                  'add_36[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit3_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_37[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit3_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit3_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_42 (ZeroPadding  (None, 18, 34, 128)  0          ['stage2_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit3_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_42[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit3_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit3_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, 16, 32, 512)  0           ['stage2_unit3_conv3[0][0]',     \n",
      "                                                                  'add_37[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit4_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_38[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu1 (Activation  (None, 16, 32, 512)  0          ['stage2_unit4_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit4_conv1 (Conv2D)    (None, 16, 32, 128)  65536       ['stage2_unit4_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage2_unit4_bn2 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit4_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu2 (Activation  (None, 16, 32, 128)  0          ['stage2_unit4_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_43 (ZeroPadding  (None, 18, 34, 128)  0          ['stage2_unit4_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit4_conv2 (Conv2D)    (None, 16, 32, 128)  147456      ['zero_padding2d_43[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit4_bn3 (BatchNormali  (None, 16, 32, 128)  512        ['stage2_unit4_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu3 (Activation  (None, 16, 32, 128)  0          ['stage2_unit4_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage2_unit4_conv3 (Conv2D)    (None, 16, 32, 512)  65536       ['stage2_unit4_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, 16, 32, 512)  0           ['stage2_unit4_conv3[0][0]',     \n",
      "                                                                  'add_38[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit1_bn1 (BatchNormali  (None, 16, 32, 512)  2048       ['add_39[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu1 (Activation  (None, 16, 32, 512)  0          ['stage3_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit1_conv1 (Conv2D)    (None, 16, 32, 256)  131072      ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit1_bn2 (BatchNormali  (None, 16, 32, 256)  1024       ['stage3_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu2 (Activation  (None, 16, 32, 256)  0          ['stage3_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_44 (ZeroPadding  (None, 18, 34, 256)  0          ['stage3_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit1_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_44[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit1_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit1_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit1_sc (Conv2D)       (None, 8, 16, 1024)  524288      ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit1_conv3[0][0]',     \n",
      "                                                                  'stage3_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage3_unit2_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_40[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit2_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit2_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_45 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit2_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_45[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit2_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit2_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit2_conv3[0][0]',     \n",
      "                                                                  'add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit3_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_41[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit3_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit3_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_46 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit3_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_46[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit3_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit3_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit3_conv3[0][0]',     \n",
      "                                                                  'add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit4_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_42[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit4_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit4_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit4_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit4_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit4_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit4_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_47 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit4_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit4_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_47[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit4_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit4_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit4_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit4_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit4_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit4_conv3[0][0]',     \n",
      "                                                                  'add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit5_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_43[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit5_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit5_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit5_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit5_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit5_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit5_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_48 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit5_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit5_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_48[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit5_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit5_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit5_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit5_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit5_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit5_conv3[0][0]',     \n",
      "                                                                  'add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit6_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_44[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit6_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit6_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit6_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit6_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit6_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit6_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_49 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit6_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit6_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_49[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit6_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit6_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit6_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit6_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit6_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit6_conv3[0][0]',     \n",
      "                                                                  'add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit7_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_45[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit7_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit7_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit7_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit7_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit7_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit7_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_50 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit7_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit7_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_50[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit7_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit7_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit7_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit7_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit7_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit7_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit7_conv3[0][0]',     \n",
      "                                                                  'add_45[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit8_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_46[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit8_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit8_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit8_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit8_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit8_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit8_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_51 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit8_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit8_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_51[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit8_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit8_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit8_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit8_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit8_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit8_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit8_conv3[0][0]',     \n",
      "                                                                  'add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit9_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_47[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage3_unit9_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit9_conv1 (Conv2D)    (None, 8, 16, 256)   262144      ['stage3_unit9_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage3_unit9_bn2 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit9_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu2 (Activation  (None, 8, 16, 256)  0           ['stage3_unit9_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_52 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit9_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit9_conv2 (Conv2D)    (None, 8, 16, 256)   589824      ['zero_padding2d_52[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit9_bn3 (BatchNormali  (None, 8, 16, 256)  1024        ['stage3_unit9_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit9_relu3 (Activation  (None, 8, 16, 256)  0           ['stage3_unit9_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage3_unit9_conv3 (Conv2D)    (None, 8, 16, 1024)  262144      ['stage3_unit9_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_48 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit9_conv3[0][0]',     \n",
      "                                                                  'add_47[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit10_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_48[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit10_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit10_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit10_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit10_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit10_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit10_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_53 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit10_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit10_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_53[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit10_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit10_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit10_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit10_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit10_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit10_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_49 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit10_conv3[0][0]',    \n",
      "                                                                  'add_48[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit11_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_49[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit11_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit11_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit11_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit11_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit11_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit11_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_54 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit11_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit11_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_54[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit11_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit11_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit11_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit11_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit11_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit11_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_50 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit11_conv3[0][0]',    \n",
      "                                                                  'add_49[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit12_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_50[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit12_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit12_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit12_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit12_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit12_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit12_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_55 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit12_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit12_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_55[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit12_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit12_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit12_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit12_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit12_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit12_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_51 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit12_conv3[0][0]',    \n",
      "                                                                  'add_50[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit13_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_51[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit13_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit13_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit13_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit13_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit13_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit13_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_56 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit13_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit13_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_56[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit13_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit13_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit13_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit13_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit13_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit13_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_52 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit13_conv3[0][0]',    \n",
      "                                                                  'add_51[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit14_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_52[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit14_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit14_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit14_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit14_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit14_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit14_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_57 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit14_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit14_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_57[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit14_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit14_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit14_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit14_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit14_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit14_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_53 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit14_conv3[0][0]',    \n",
      "                                                                  'add_52[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit15_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_53[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit15_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit15_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit15_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit15_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit15_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit15_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_58 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit15_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit15_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_58[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit15_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit15_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit15_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit15_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit15_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit15_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_54 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit15_conv3[0][0]',    \n",
      "                                                                  'add_53[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit16_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_54[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit16_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit16_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit16_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit16_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit16_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit16_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_59 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit16_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit16_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_59[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit16_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit16_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit16_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit16_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit16_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit16_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_55 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit16_conv3[0][0]',    \n",
      "                                                                  'add_54[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit17_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_55[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit17_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit17_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit17_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit17_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit17_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit17_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_60 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit17_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit17_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_60[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit17_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit17_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit17_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit17_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit17_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit17_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_56 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit17_conv3[0][0]',    \n",
      "                                                                  'add_55[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit18_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_56[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit18_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit18_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit18_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit18_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit18_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit18_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_61 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit18_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit18_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_61[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit18_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit18_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit18_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit18_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit18_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit18_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_57 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit18_conv3[0][0]',    \n",
      "                                                                  'add_56[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit19_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_57[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit19_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit19_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit19_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit19_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit19_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit19_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_62 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit19_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit19_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_62[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit19_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit19_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit19_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit19_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit19_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit19_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_58 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit19_conv3[0][0]',    \n",
      "                                                                  'add_57[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit20_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_58[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit20_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit20_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit20_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit20_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit20_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit20_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_63 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit20_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit20_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_63[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit20_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit20_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit20_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit20_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit20_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit20_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_59 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit20_conv3[0][0]',    \n",
      "                                                                  'add_58[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit21_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_59[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit21_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit21_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit21_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit21_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit21_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit21_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_64 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit21_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit21_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_64[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit21_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit21_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit21_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit21_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit21_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit21_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_60 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit21_conv3[0][0]',    \n",
      "                                                                  'add_59[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit22_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_60[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit22_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit22_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit22_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit22_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit22_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit22_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_65 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit22_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit22_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_65[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit22_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit22_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit22_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit22_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit22_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit22_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_61 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit22_conv3[0][0]',    \n",
      "                                                                  'add_60[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit23_bn1 (BatchNormal  (None, 8, 16, 1024)  4096       ['add_61[0][0]']                 \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu1 (Activatio  (None, 8, 16, 1024)  0          ['stage3_unit23_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit23_conv1 (Conv2D)   (None, 8, 16, 256)   262144      ['stage3_unit23_relu1[0][0]']    \n",
      "                                                                                                  \n",
      " stage3_unit23_bn2 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit23_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu2 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit23_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_66 (ZeroPadding  (None, 10, 18, 256)  0          ['stage3_unit23_relu2[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit23_conv2 (Conv2D)   (None, 8, 16, 256)   589824      ['zero_padding2d_66[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit23_bn3 (BatchNormal  (None, 8, 16, 256)  1024        ['stage3_unit23_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " stage3_unit23_relu3 (Activatio  (None, 8, 16, 256)  0           ['stage3_unit23_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stage3_unit23_conv3 (Conv2D)   (None, 8, 16, 1024)  262144      ['stage3_unit23_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " add_62 (Add)                   (None, 8, 16, 1024)  0           ['stage3_unit23_conv3[0][0]',    \n",
      "                                                                  'add_61[0][0]']                 \n",
      "                                                                                                  \n",
      " stage4_unit1_bn1 (BatchNormali  (None, 8, 16, 1024)  4096       ['add_62[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu1 (Activation  (None, 8, 16, 1024)  0          ['stage4_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit1_conv1 (Conv2D)    (None, 8, 16, 512)   524288      ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit1_bn2 (BatchNormali  (None, 8, 16, 512)  2048        ['stage4_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu2 (Activation  (None, 8, 16, 512)  0           ['stage4_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_67 (ZeroPadding  (None, 10, 18, 512)  0          ['stage4_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit1_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_67[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit1_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit1_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit1_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit1_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit1_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit1_sc (Conv2D)       (None, 4, 8, 2048)   2097152     ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_63 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit1_conv3[0][0]',     \n",
      "                                                                  'stage4_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage4_unit2_bn1 (BatchNormali  (None, 4, 8, 2048)  8192        ['add_63[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu1 (Activation  (None, 4, 8, 2048)  0           ['stage4_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit2_conv1 (Conv2D)    (None, 4, 8, 512)    1048576     ['stage4_unit2_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit2_bn2 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu2 (Activation  (None, 4, 8, 512)   0           ['stage4_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_68 (ZeroPadding  (None, 6, 10, 512)  0           ['stage4_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit2_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_68[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit2_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit2_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit2_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit2_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit2_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_64 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit2_conv3[0][0]',     \n",
      "                                                                  'add_63[0][0]']                 \n",
      "                                                                                                  \n",
      " stage4_unit3_bn1 (BatchNormali  (None, 4, 8, 2048)  8192        ['add_64[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu1 (Activation  (None, 4, 8, 2048)  0           ['stage4_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit3_conv1 (Conv2D)    (None, 4, 8, 512)    1048576     ['stage4_unit3_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " stage4_unit3_bn2 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu2 (Activation  (None, 4, 8, 512)   0           ['stage4_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_69 (ZeroPadding  (None, 6, 10, 512)  0           ['stage4_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit3_conv2 (Conv2D)    (None, 4, 8, 512)    2359296     ['zero_padding2d_69[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit3_bn3 (BatchNormali  (None, 4, 8, 512)   2048        ['stage4_unit3_conv2[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu3 (Activation  (None, 4, 8, 512)   0           ['stage4_unit3_bn3[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stage4_unit3_conv3 (Conv2D)    (None, 4, 8, 2048)   1048576     ['stage4_unit3_relu3[0][0]']     \n",
      "                                                                                                  \n",
      " add_65 (Add)                   (None, 4, 8, 2048)   0           ['stage4_unit3_conv3[0][0]',     \n",
      "                                                                  'add_64[0][0]']                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 4, 8, 2048)   8192        ['add_65[0][0]']                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 4, 8, 2048)   0           ['bn1[0][0]']                    \n",
      "                                                                                                  \n",
      " fpn_stage_p5_pre_conv (Conv2D)  (None, 4, 8, 256)   524544      ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " fpn_stage_p5_upsampling (UpSam  (None, 8, 16, 256)  0           ['fpn_stage_p5_pre_conv[0][0]']  \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p5_conv (Conv2D)     (None, 8, 16, 256)   262400      ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " fpn_stage_p5_add (Add)         (None, 8, 16, 256)   0           ['fpn_stage_p5_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p5_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p4_upsampling (UpSam  (None, 16, 32, 256)  0          ['fpn_stage_p5_add[0][0]']       \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p4_conv (Conv2D)     (None, 16, 32, 256)  131328      ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " fpn_stage_p4_add (Add)         (None, 16, 32, 256)  0           ['fpn_stage_p4_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p4_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p3_upsampling (UpSam  (None, 32, 64, 256)  0          ['fpn_stage_p4_add[0][0]']       \n",
      " pling2D)                                                                                         \n",
      "                                                                                                  \n",
      " fpn_stage_p3_conv (Conv2D)     (None, 32, 64, 256)  65792       ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " fpn_stage_p3_add (Add)         (None, 32, 64, 256)  0           ['fpn_stage_p3_upsampling[0][0]',\n",
      "                                                                  'fpn_stage_p3_conv[0][0]']      \n",
      "                                                                                                  \n",
      " fpn_stage_p2_upsampling (UpSam  (None, 64, 128, 256  0          ['fpn_stage_p3_add[0][0]']       \n",
      " pling2D)                       )                                                                 \n",
      "                                                                                                  \n",
      " fpn_stage_p2_conv (Conv2D)     (None, 64, 128, 256  16640       ['relu0[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " fpn_stage_p2_add (Add)         (None, 64, 128, 256  0           ['fpn_stage_p2_upsampling[0][0]',\n",
      "                                )                                 'fpn_stage_p2_conv[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage3a_conv (Conv2D)     (None, 32, 64, 128)  294912      ['fpn_stage_p3_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage4a_conv (Conv2D)     (None, 16, 32, 128)  294912      ['fpn_stage_p4_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage5a_conv (Conv2D)     (None, 8, 16, 128)   294912      ['fpn_stage_p5_add[0][0]']       \n",
      "                                                                                                  \n",
      " segm_stage2a_conv (Conv2D)     (None, 64, 128, 128  294912      ['fpn_stage_p2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3a_bn (BatchNormaliz  (None, 32, 64, 128)  512        ['segm_stage3a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage4a_bn (BatchNormaliz  (None, 16, 32, 128)  512        ['segm_stage4a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage5a_bn (BatchNormaliz  (None, 8, 16, 128)  512         ['segm_stage5a_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage2a_bn (BatchNormaliz  (None, 64, 128, 128  512        ['segm_stage2a_conv[0][0]']      \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3a_relu (Activation)  (None, 32, 64, 128)  0          ['segm_stage3a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage4a_relu (Activation)  (None, 16, 32, 128)  0          ['segm_stage4a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage5a_relu (Activation)  (None, 8, 16, 128)  0           ['segm_stage5a_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage2a_relu (Activation)  (None, 64, 128, 128  0          ['segm_stage2a_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_conv (Conv2D)     (None, 32, 64, 128)  147456      ['segm_stage3a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage4b_conv (Conv2D)     (None, 16, 32, 128)  147456      ['segm_stage4a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage5b_conv (Conv2D)     (None, 8, 16, 128)   147456      ['segm_stage5a_relu[0][0]']      \n",
      "                                                                                                  \n",
      " segm_stage2b_conv (Conv2D)     (None, 64, 128, 128  147456      ['segm_stage2a_relu[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_bn (BatchNormaliz  (None, 32, 64, 128)  512        ['segm_stage3b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage4b_bn (BatchNormaliz  (None, 16, 32, 128)  512        ['segm_stage4b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage5b_bn (BatchNormaliz  (None, 8, 16, 128)  512         ['segm_stage5b_conv[0][0]']      \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " segm_stage2b_bn (BatchNormaliz  (None, 64, 128, 128  512        ['segm_stage2b_conv[0][0]']      \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " segm_stage3b_relu (Activation)  (None, 32, 64, 128)  0          ['segm_stage3b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage4b_relu (Activation)  (None, 16, 32, 128)  0          ['segm_stage4b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage5b_relu (Activation)  (None, 8, 16, 128)  0           ['segm_stage5b_bn[0][0]']        \n",
      "                                                                                                  \n",
      " segm_stage2b_relu (Activation)  (None, 64, 128, 128  0          ['segm_stage2b_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage3 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage3b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage4 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage4b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " upsampling_stage5 (UpSampling2  (None, 64, 128, 128  0          ['segm_stage5b_relu[0][0]']      \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " aggregation_concat (Concatenat  (None, 64, 128, 512  0          ['segm_stage2b_relu[0][0]',      \n",
      " e)                             )                                 'upsampling_stage3[0][0]',      \n",
      "                                                                  'upsampling_stage4[0][0]',      \n",
      "                                                                  'upsampling_stage5[0][0]']      \n",
      "                                                                                                  \n",
      " final_stage_conv (Conv2D)      (None, 64, 128, 128  589824      ['aggregation_concat[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " final_stage_bn (BatchNormaliza  (None, 64, 128, 128  512        ['final_stage_conv[0][0]']       \n",
      " tion)                          )                                                                 \n",
      "                                                                                                  \n",
      " final_stage_relu (Activation)  (None, 64, 128, 128  0           ['final_stage_bn[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " final_upsampling (UpSampling2D  (None, 128, 256, 12  0          ['final_stage_relu[0][0]']       \n",
      " )                              8)                                                                \n",
      "                                                                                                  \n",
      " head_conv (Conv2D)             (None, 128, 256, 8)  9224        ['final_upsampling[0][0]']       \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 128, 256, 8)  0           ['head_conv[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 45,964,241\n",
      "Trainable params: 45,864,139\n",
      "Non-trainable params: 100,102\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "156/156 - 100s - loss: 0.3579 - iou_score: 0.5252 - f1-score: 0.6417 - val_loss: 0.8784 - val_iou_score: 0.0790 - val_f1-score: 0.1212 - 100s/epoch - 640ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 81s - loss: 0.2613 - iou_score: 0.6254 - f1-score: 0.7380 - val_loss: 0.8874 - val_iou_score: 0.0744 - val_f1-score: 0.1127 - 81s/epoch - 517ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 78s - loss: 0.2388 - iou_score: 0.6496 - f1-score: 0.7599 - val_loss: 0.8101 - val_iou_score: 0.1301 - val_f1-score: 0.1895 - 78s/epoch - 502ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 79s - loss: 0.2181 - iou_score: 0.6727 - f1-score: 0.7804 - val_loss: 0.8079 - val_iou_score: 0.1325 - val_f1-score: 0.1932 - 79s/epoch - 507ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 79s - loss: 0.2061 - iou_score: 0.6878 - f1-score: 0.7933 - val_loss: 0.7414 - val_iou_score: 0.1956 - val_f1-score: 0.2579 - 79s/epoch - 507ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 81s - loss: 0.1898 - iou_score: 0.7075 - f1-score: 0.8091 - val_loss: 0.7466 - val_iou_score: 0.1845 - val_f1-score: 0.2527 - 81s/epoch - 516ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 78s - loss: 0.1941 - iou_score: 0.7011 - f1-score: 0.8048 - val_loss: 0.2921 - val_iou_score: 0.5756 - val_f1-score: 0.7067 - 78s/epoch - 502ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 84s - loss: 0.1792 - iou_score: 0.7200 - f1-score: 0.8194 - val_loss: 0.2710 - val_iou_score: 0.6095 - val_f1-score: 0.7289 - 84s/epoch - 538ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 78s - loss: 0.1762 - iou_score: 0.7240 - f1-score: 0.8232 - val_loss: 0.2485 - val_iou_score: 0.6385 - val_f1-score: 0.7517 - 78s/epoch - 498ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 80s - loss: 0.1675 - iou_score: 0.7345 - f1-score: 0.8316 - val_loss: 0.2440 - val_iou_score: 0.6332 - val_f1-score: 0.7548 - 80s/epoch - 510ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 76s - loss: 0.1638 - iou_score: 0.7396 - f1-score: 0.8357 - val_loss: 0.2278 - val_iou_score: 0.6602 - val_f1-score: 0.7700 - 76s/epoch - 490ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 74s - loss: 0.1578 - iou_score: 0.7475 - f1-score: 0.8422 - val_loss: 0.2309 - val_iou_score: 0.6582 - val_f1-score: 0.7699 - 74s/epoch - 477ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 77s - loss: 0.1609 - iou_score: 0.7427 - f1-score: 0.8385 - val_loss: 0.2135 - val_iou_score: 0.6765 - val_f1-score: 0.7864 - 77s/epoch - 494ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 77s - loss: 0.1517 - iou_score: 0.7545 - f1-score: 0.8475 - val_loss: 0.2291 - val_iou_score: 0.6626 - val_f1-score: 0.7699 - 77s/epoch - 492ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 79s - loss: 0.1459 - iou_score: 0.7627 - f1-score: 0.8538 - val_loss: 0.2564 - val_iou_score: 0.6199 - val_f1-score: 0.7415 - 79s/epoch - 509ms/step\n",
      "<keras.callbacks.History object at 0x7f75ce494130>\n",
      "2023/09/20 16:00:39 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "[2023-09-20 16:00:57,348][absl][WARNING] - Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 119). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpejex7csf/model/data/model/assets\n",
      "[2023-09-20 16:01:03,638][tensorflow][INFO] - Assets written to: /tmp/tmpejex7csf/model/data/model/assets\n",
      "2023/09/20 16:01:19 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpejex7csf/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/20 16:01:19 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 9\n",
      "Created version '9' of model 'fpn'.\n",
      "[2023-09-20 16:01:19,658][HYDRA] Number of Pareto solutions: 1\n",
      "[2023-09-20 16:01:19,658][HYDRA]     Values: [0.6224431395530701, 0.7435063719749451], Params: {'model.model_type': 'fpn', 'model.backbone': 'resnet101'}\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models.py -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmentation fine tuning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-25 17:48:26.689870: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 17:48:27.131229: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 17:48:27.131278: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 17:48:27.131286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 17:48:29 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 17:48:29 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9fbfde5cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9fbfde5cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9fbfde5cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9fbfde5cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 145s - loss: 0.2745 - iou_score: 0.6119 - f1-score: 0.7243 - val_loss: 0.3061 - val_iou_score: 0.5656 - val_f1-score: 0.6928 - 145s/epoch - 928ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 109s - loss: 0.2061 - iou_score: 0.6875 - f1-score: 0.7940 - val_loss: 0.2523 - val_iou_score: 0.6283 - val_f1-score: 0.7452 - 109s/epoch - 702ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 109s - loss: 0.1895 - iou_score: 0.7073 - f1-score: 0.8103 - val_loss: 0.2100 - val_iou_score: 0.6810 - val_f1-score: 0.7900 - 109s/epoch - 697ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 108s - loss: 0.1787 - iou_score: 0.7213 - f1-score: 0.8210 - val_loss: 0.1977 - val_iou_score: 0.6950 - val_f1-score: 0.7995 - 108s/epoch - 694ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 108s - loss: 0.1700 - iou_score: 0.7308 - f1-score: 0.8289 - val_loss: 0.1942 - val_iou_score: 0.6972 - val_f1-score: 0.8043 - 108s/epoch - 693ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 109s - loss: 0.1657 - iou_score: 0.7359 - f1-score: 0.8326 - val_loss: 0.1826 - val_iou_score: 0.7151 - val_f1-score: 0.8170 - 109s/epoch - 696ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 108s - loss: 0.1598 - iou_score: 0.7452 - f1-score: 0.8398 - val_loss: 0.1785 - val_iou_score: 0.7193 - val_f1-score: 0.8213 - 108s/epoch - 692ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 107s - loss: 0.1568 - iou_score: 0.7488 - f1-score: 0.8430 - val_loss: 0.1838 - val_iou_score: 0.7155 - val_f1-score: 0.8167 - 107s/epoch - 683ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 105s - loss: 0.1502 - iou_score: 0.7574 - f1-score: 0.8493 - val_loss: 0.1809 - val_iou_score: 0.7173 - val_f1-score: 0.8190 - 105s/epoch - 671ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 106s - loss: 0.1519 - iou_score: 0.7539 - f1-score: 0.8465 - val_loss: 0.1737 - val_iou_score: 0.7221 - val_f1-score: 0.8236 - 106s/epoch - 678ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 106s - loss: 0.1483 - iou_score: 0.7592 - f1-score: 0.8505 - val_loss: 0.1830 - val_iou_score: 0.7146 - val_f1-score: 0.8174 - 106s/epoch - 682ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 105s - loss: 0.1470 - iou_score: 0.7611 - f1-score: 0.8523 - val_loss: 0.1740 - val_iou_score: 0.7236 - val_f1-score: 0.8254 - 105s/epoch - 675ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 106s - loss: 0.1450 - iou_score: 0.7631 - f1-score: 0.8539 - val_loss: 0.1689 - val_iou_score: 0.7330 - val_f1-score: 0.8319 - 106s/epoch - 677ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 106s - loss: 0.1415 - iou_score: 0.7676 - f1-score: 0.8568 - val_loss: 0.1712 - val_iou_score: 0.7288 - val_f1-score: 0.8285 - 106s/epoch - 680ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 107s - loss: 0.1399 - iou_score: 0.7710 - f1-score: 0.8599 - val_loss: 0.1671 - val_iou_score: 0.7337 - val_f1-score: 0.8333 - 107s/epoch - 684ms/step\n",
      "2023/09/25 18:16:08 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 18:16:41 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpy9j218nx/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 18:16:41 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 18:16:41 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 18:16:41 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 67\n",
      "Created version '67' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 18:17:14.280484: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 18:17:14.672023: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 18:17:14.672060: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 18:17:14.672065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 18:17:16 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 18:17:16 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f6010879d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f6010879d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f6010879d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f6010879d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 136s - loss: 0.2890 - iou_score: 0.5942 - f1-score: 0.7099 - val_loss: 0.2880 - val_iou_score: 0.5882 - val_f1-score: 0.7106 - 136s/epoch - 873ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 105s - loss: 0.2235 - iou_score: 0.6663 - f1-score: 0.7768 - val_loss: 0.2876 - val_iou_score: 0.5865 - val_f1-score: 0.7106 - 105s/epoch - 673ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 106s - loss: 0.2029 - iou_score: 0.6901 - f1-score: 0.7968 - val_loss: 0.2110 - val_iou_score: 0.6797 - val_f1-score: 0.7890 - 106s/epoch - 679ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 105s - loss: 0.1941 - iou_score: 0.7015 - f1-score: 0.8056 - val_loss: 0.2059 - val_iou_score: 0.6856 - val_f1-score: 0.7912 - 105s/epoch - 676ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 106s - loss: 0.1864 - iou_score: 0.7088 - f1-score: 0.8120 - val_loss: 0.1988 - val_iou_score: 0.6927 - val_f1-score: 0.7999 - 106s/epoch - 679ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 106s - loss: 0.1824 - iou_score: 0.7142 - f1-score: 0.8159 - val_loss: 0.1864 - val_iou_score: 0.7099 - val_f1-score: 0.8131 - 106s/epoch - 679ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 105s - loss: 0.1756 - iou_score: 0.7249 - f1-score: 0.8241 - val_loss: 0.1834 - val_iou_score: 0.7139 - val_f1-score: 0.8164 - 105s/epoch - 671ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 105s - loss: 0.1704 - iou_score: 0.7304 - f1-score: 0.8292 - val_loss: 0.1823 - val_iou_score: 0.7160 - val_f1-score: 0.8185 - 105s/epoch - 674ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 104s - loss: 0.1636 - iou_score: 0.7396 - f1-score: 0.8360 - val_loss: 0.1864 - val_iou_score: 0.7110 - val_f1-score: 0.8132 - 104s/epoch - 670ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 106s - loss: 0.1660 - iou_score: 0.7354 - f1-score: 0.8323 - val_loss: 0.1739 - val_iou_score: 0.7234 - val_f1-score: 0.8243 - 106s/epoch - 681ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 105s - loss: 0.1626 - iou_score: 0.7401 - f1-score: 0.8363 - val_loss: 0.1870 - val_iou_score: 0.7097 - val_f1-score: 0.8131 - 105s/epoch - 675ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 105s - loss: 0.1650 - iou_score: 0.7368 - f1-score: 0.8344 - val_loss: 0.1737 - val_iou_score: 0.7246 - val_f1-score: 0.8259 - 105s/epoch - 673ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 107s - loss: 0.1545 - iou_score: 0.7503 - f1-score: 0.8443 - val_loss: 0.1694 - val_iou_score: 0.7325 - val_f1-score: 0.8312 - 107s/epoch - 684ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 106s - loss: 0.1605 - iou_score: 0.7409 - f1-score: 0.8372 - val_loss: 0.1792 - val_iou_score: 0.7189 - val_f1-score: 0.8205 - 106s/epoch - 677ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 106s - loss: 0.1564 - iou_score: 0.7490 - f1-score: 0.8435 - val_loss: 0.1763 - val_iou_score: 0.7224 - val_f1-score: 0.8242 - 106s/epoch - 682ms/step\n",
      "2023/09/25 18:44:26 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 18:44:59 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpsta_z0vt/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 18:45:00 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 18:45:00 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 18:45:00 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 68\n",
      "Created version '68' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 18:45:32.740733: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 18:45:33.142005: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 18:45:33.142047: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 18:45:33.142054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 18:45:34 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 18:45:34 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f210ff91d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f210ff91d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f210ff91d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f210ff91d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 138s - loss: 0.2772 - iou_score: 0.6091 - f1-score: 0.7218 - val_loss: 0.2963 - val_iou_score: 0.5784 - val_f1-score: 0.7023 - 138s/epoch - 885ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 105s - loss: 0.2086 - iou_score: 0.6843 - f1-score: 0.7915 - val_loss: 0.2525 - val_iou_score: 0.6356 - val_f1-score: 0.7457 - 105s/epoch - 676ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 106s - loss: 0.1901 - iou_score: 0.7063 - f1-score: 0.8095 - val_loss: 0.2088 - val_iou_score: 0.6813 - val_f1-score: 0.7913 - 106s/epoch - 680ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 106s - loss: 0.1789 - iou_score: 0.7205 - f1-score: 0.8203 - val_loss: 0.1973 - val_iou_score: 0.6954 - val_f1-score: 0.7997 - 106s/epoch - 679ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 106s - loss: 0.1705 - iou_score: 0.7303 - f1-score: 0.8285 - val_loss: 0.1964 - val_iou_score: 0.6950 - val_f1-score: 0.8016 - 106s/epoch - 679ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 107s - loss: 0.1680 - iou_score: 0.7331 - f1-score: 0.8303 - val_loss: 0.1854 - val_iou_score: 0.7107 - val_f1-score: 0.8139 - 107s/epoch - 683ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 106s - loss: 0.1608 - iou_score: 0.7441 - f1-score: 0.8389 - val_loss: 0.1816 - val_iou_score: 0.7155 - val_f1-score: 0.8182 - 106s/epoch - 680ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 105s - loss: 0.1578 - iou_score: 0.7471 - f1-score: 0.8419 - val_loss: 0.1863 - val_iou_score: 0.7135 - val_f1-score: 0.8143 - 105s/epoch - 675ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 105s - loss: 0.1529 - iou_score: 0.7540 - f1-score: 0.8467 - val_loss: 0.1793 - val_iou_score: 0.7197 - val_f1-score: 0.8203 - 105s/epoch - 672ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 107s - loss: 0.1511 - iou_score: 0.7551 - f1-score: 0.8473 - val_loss: 0.1714 - val_iou_score: 0.7256 - val_f1-score: 0.8265 - 107s/epoch - 687ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 106s - loss: 0.1493 - iou_score: 0.7580 - f1-score: 0.8495 - val_loss: 0.1920 - val_iou_score: 0.7034 - val_f1-score: 0.8078 - 106s/epoch - 679ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 106s - loss: 0.1538 - iou_score: 0.7521 - f1-score: 0.8455 - val_loss: 0.1718 - val_iou_score: 0.7270 - val_f1-score: 0.8278 - 106s/epoch - 683ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 106s - loss: 0.1486 - iou_score: 0.7585 - f1-score: 0.8503 - val_loss: 0.1699 - val_iou_score: 0.7320 - val_f1-score: 0.8307 - 106s/epoch - 682ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 106s - loss: 0.1492 - iou_score: 0.7569 - f1-score: 0.8494 - val_loss: 0.1775 - val_iou_score: 0.7204 - val_f1-score: 0.8222 - 106s/epoch - 681ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 106s - loss: 0.1457 - iou_score: 0.7626 - f1-score: 0.8539 - val_loss: 0.1763 - val_iou_score: 0.7215 - val_f1-score: 0.8242 - 106s/epoch - 682ms/step\n",
      "2023/09/25 19:12:54 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 19:13:27 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpxxlzhwm_/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 19:13:27 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 19:13:27 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 19:13:27 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 69\n",
      "Created version '69' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 19:13:59.902870: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 19:14:00.304074: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 19:14:00.304130: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 19:14:00.304139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 19:14:01 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 19:14:01 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f7320e71d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f7320e71d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f7320e71d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f7320e71d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 136s - loss: 0.2935 - iou_score: 0.5890 - f1-score: 0.7054 - val_loss: 0.2892 - val_iou_score: 0.5858 - val_f1-score: 0.7099 - 136s/epoch - 873ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 106s - loss: 0.2230 - iou_score: 0.6662 - f1-score: 0.7772 - val_loss: 0.2554 - val_iou_score: 0.6326 - val_f1-score: 0.7433 - 106s/epoch - 682ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 105s - loss: 0.2049 - iou_score: 0.6869 - f1-score: 0.7948 - val_loss: 0.2064 - val_iou_score: 0.6861 - val_f1-score: 0.7936 - 105s/epoch - 676ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 106s - loss: 0.1955 - iou_score: 0.6997 - f1-score: 0.8043 - val_loss: 0.1995 - val_iou_score: 0.6908 - val_f1-score: 0.7977 - 106s/epoch - 677ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 106s - loss: 0.1871 - iou_score: 0.7091 - f1-score: 0.8120 - val_loss: 0.1936 - val_iou_score: 0.6987 - val_f1-score: 0.8048 - 106s/epoch - 677ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 106s - loss: 0.1845 - iou_score: 0.7111 - f1-score: 0.8137 - val_loss: 0.1963 - val_iou_score: 0.6952 - val_f1-score: 0.8030 - 106s/epoch - 681ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 106s - loss: 0.1770 - iou_score: 0.7222 - f1-score: 0.8227 - val_loss: 0.1830 - val_iou_score: 0.7144 - val_f1-score: 0.8166 - 106s/epoch - 681ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 106s - loss: 0.1721 - iou_score: 0.7282 - f1-score: 0.8276 - val_loss: 0.1824 - val_iou_score: 0.7158 - val_f1-score: 0.8180 - 106s/epoch - 677ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 107s - loss: 0.1674 - iou_score: 0.7345 - f1-score: 0.8322 - val_loss: 0.1837 - val_iou_score: 0.7146 - val_f1-score: 0.8162 - 107s/epoch - 687ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 106s - loss: 0.1740 - iou_score: 0.7250 - f1-score: 0.8245 - val_loss: 0.1787 - val_iou_score: 0.7162 - val_f1-score: 0.8192 - 106s/epoch - 682ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 107s - loss: 0.1677 - iou_score: 0.7333 - f1-score: 0.8311 - val_loss: 0.2156 - val_iou_score: 0.6696 - val_f1-score: 0.7847 - 107s/epoch - 685ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 107s - loss: 0.1676 - iou_score: 0.7335 - f1-score: 0.8316 - val_loss: 0.1785 - val_iou_score: 0.7183 - val_f1-score: 0.8211 - 107s/epoch - 688ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 107s - loss: 0.1643 - iou_score: 0.7350 - f1-score: 0.8327 - val_loss: 0.1760 - val_iou_score: 0.7246 - val_f1-score: 0.8249 - 107s/epoch - 688ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 107s - loss: 0.1607 - iou_score: 0.7416 - f1-score: 0.8379 - val_loss: 0.1751 - val_iou_score: 0.7233 - val_f1-score: 0.8245 - 107s/epoch - 685ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 107s - loss: 0.1587 - iou_score: 0.7453 - f1-score: 0.8411 - val_loss: 0.1804 - val_iou_score: 0.7186 - val_f1-score: 0.8203 - 107s/epoch - 685ms/step\n",
      "2023/09/25 19:41:25 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 19:41:58 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmph8nwisxk/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 19:41:58 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 19:41:58 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 19:41:58 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 70\n",
      "Created version '70' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 19:42:30.937870: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 19:42:31.337069: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 19:42:31.337110: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 19:42:31.337117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 19:42:33 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 19:42:33 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fe0bb071d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fe0bb071d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fe0bb071d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fe0bb071d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 139s - loss: 0.2801 - iou_score: 0.6063 - f1-score: 0.7186 - val_loss: 0.2776 - val_iou_score: 0.5996 - val_f1-score: 0.7209 - 139s/epoch - 894ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 109s - loss: 0.2100 - iou_score: 0.6831 - f1-score: 0.7901 - val_loss: 0.2511 - val_iou_score: 0.6338 - val_f1-score: 0.7469 - 109s/epoch - 697ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 108s - loss: 0.1944 - iou_score: 0.7007 - f1-score: 0.8051 - val_loss: 0.2133 - val_iou_score: 0.6794 - val_f1-score: 0.7870 - 108s/epoch - 694ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 108s - loss: 0.1841 - iou_score: 0.7143 - f1-score: 0.8157 - val_loss: 0.1926 - val_iou_score: 0.7014 - val_f1-score: 0.8047 - 108s/epoch - 693ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 110s - loss: 0.1739 - iou_score: 0.7261 - f1-score: 0.8251 - val_loss: 0.1865 - val_iou_score: 0.7082 - val_f1-score: 0.8119 - 110s/epoch - 707ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 109s - loss: 0.1686 - iou_score: 0.7324 - f1-score: 0.8296 - val_loss: 0.1909 - val_iou_score: 0.7042 - val_f1-score: 0.8087 - 109s/epoch - 700ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 109s - loss: 0.1626 - iou_score: 0.7415 - f1-score: 0.8370 - val_loss: 0.1805 - val_iou_score: 0.7171 - val_f1-score: 0.8193 - 109s/epoch - 701ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 110s - loss: 0.1583 - iou_score: 0.7467 - f1-score: 0.8414 - val_loss: 0.1809 - val_iou_score: 0.7178 - val_f1-score: 0.8197 - 110s/epoch - 707ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 109s - loss: 0.1534 - iou_score: 0.7533 - f1-score: 0.8461 - val_loss: 0.1802 - val_iou_score: 0.7189 - val_f1-score: 0.8198 - 109s/epoch - 697ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 110s - loss: 0.1604 - iou_score: 0.7431 - f1-score: 0.8381 - val_loss: 0.1756 - val_iou_score: 0.7214 - val_f1-score: 0.8229 - 110s/epoch - 704ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 109s - loss: 0.1512 - iou_score: 0.7555 - f1-score: 0.8477 - val_loss: 0.1783 - val_iou_score: 0.7212 - val_f1-score: 0.8220 - 109s/epoch - 701ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 109s - loss: 0.1491 - iou_score: 0.7583 - f1-score: 0.8501 - val_loss: 0.1723 - val_iou_score: 0.7270 - val_f1-score: 0.8274 - 109s/epoch - 701ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 110s - loss: 0.1475 - iou_score: 0.7601 - f1-score: 0.8517 - val_loss: 0.1705 - val_iou_score: 0.7304 - val_f1-score: 0.8301 - 110s/epoch - 702ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 109s - loss: 0.1454 - iou_score: 0.7625 - f1-score: 0.8533 - val_loss: 0.1720 - val_iou_score: 0.7278 - val_f1-score: 0.8277 - 109s/epoch - 699ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 109s - loss: 0.1440 - iou_score: 0.7648 - f1-score: 0.8554 - val_loss: 0.1890 - val_iou_score: 0.7042 - val_f1-score: 0.8110 - 109s/epoch - 701ms/step\n",
      "2023/09/25 20:10:39 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 20:11:12 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp0ycwog2y/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 20:11:12 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 20:11:12 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 20:11:12 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 71\n",
      "Created version '71' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 20:11:45.438338: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 20:11:45.839747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 20:11:45.839786: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 20:11:45.839790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 20:11:47 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 20:11:47 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9a247a1d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9a247a1d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9a247a1d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9a247a1d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 139s - loss: 0.2953 - iou_score: 0.5883 - f1-score: 0.7034 - val_loss: 0.2828 - val_iou_score: 0.5958 - val_f1-score: 0.7160 - 139s/epoch - 893ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 107s - loss: 0.2239 - iou_score: 0.6660 - f1-score: 0.7763 - val_loss: 0.2410 - val_iou_score: 0.6432 - val_f1-score: 0.7567 - 107s/epoch - 689ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 108s - loss: 0.2086 - iou_score: 0.6828 - f1-score: 0.7911 - val_loss: 0.2098 - val_iou_score: 0.6818 - val_f1-score: 0.7903 - 108s/epoch - 692ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 109s - loss: 0.1984 - iou_score: 0.6958 - f1-score: 0.8014 - val_loss: 0.2000 - val_iou_score: 0.6909 - val_f1-score: 0.7967 - 109s/epoch - 696ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 108s - loss: 0.1913 - iou_score: 0.7042 - f1-score: 0.8081 - val_loss: 0.1924 - val_iou_score: 0.7021 - val_f1-score: 0.8060 - 108s/epoch - 691ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 108s - loss: 0.1861 - iou_score: 0.7095 - f1-score: 0.8121 - val_loss: 0.1888 - val_iou_score: 0.7074 - val_f1-score: 0.8112 - 108s/epoch - 695ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 107s - loss: 0.1815 - iou_score: 0.7155 - f1-score: 0.8168 - val_loss: 0.1886 - val_iou_score: 0.7081 - val_f1-score: 0.8109 - 107s/epoch - 688ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 108s - loss: 0.1752 - iou_score: 0.7244 - f1-score: 0.8247 - val_loss: 0.1813 - val_iou_score: 0.7182 - val_f1-score: 0.8194 - 108s/epoch - 691ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 107s - loss: 0.1677 - iou_score: 0.7341 - f1-score: 0.8320 - val_loss: 0.1783 - val_iou_score: 0.7211 - val_f1-score: 0.8215 - 107s/epoch - 688ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 109s - loss: 0.1692 - iou_score: 0.7309 - f1-score: 0.8293 - val_loss: 0.1799 - val_iou_score: 0.7146 - val_f1-score: 0.8182 - 109s/epoch - 696ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 109s - loss: 0.1674 - iou_score: 0.7339 - f1-score: 0.8316 - val_loss: 0.1907 - val_iou_score: 0.7073 - val_f1-score: 0.8095 - 109s/epoch - 698ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 108s - loss: 0.1656 - iou_score: 0.7364 - f1-score: 0.8337 - val_loss: 0.1839 - val_iou_score: 0.7099 - val_f1-score: 0.8155 - 108s/epoch - 695ms/step\n",
      "2023/09/25 20:34:44 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 20:35:17 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpyp8f1lho/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 20:35:17 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 20:35:17 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 20:35:17 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 72\n",
      "Created version '72' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 20:35:50.825494: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 20:35:51.228757: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 20:35:51.228795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 20:35:51.228800: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 20:35:52 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 20:35:52 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fb73ec79d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fb73ec79d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fb73ec79d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fb73ec79d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 138s - loss: 0.2828 - iou_score: 0.6029 - f1-score: 0.7160 - val_loss: 0.3036 - val_iou_score: 0.5701 - val_f1-score: 0.6954 - 138s/epoch - 885ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 107s - loss: 0.2136 - iou_score: 0.6784 - f1-score: 0.7866 - val_loss: 0.2481 - val_iou_score: 0.6406 - val_f1-score: 0.7498 - 107s/epoch - 688ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 108s - loss: 0.1957 - iou_score: 0.6994 - f1-score: 0.8040 - val_loss: 0.2121 - val_iou_score: 0.6800 - val_f1-score: 0.7881 - 108s/epoch - 693ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 109s - loss: 0.1843 - iou_score: 0.7143 - f1-score: 0.8155 - val_loss: 0.2034 - val_iou_score: 0.6896 - val_f1-score: 0.7938 - 109s/epoch - 697ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 109s - loss: 0.1774 - iou_score: 0.7218 - f1-score: 0.8216 - val_loss: 0.1986 - val_iou_score: 0.6931 - val_f1-score: 0.8000 - 109s/epoch - 697ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 109s - loss: 0.1735 - iou_score: 0.7261 - f1-score: 0.8249 - val_loss: 0.1894 - val_iou_score: 0.7061 - val_f1-score: 0.8104 - 109s/epoch - 697ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 108s - loss: 0.1668 - iou_score: 0.7361 - f1-score: 0.8328 - val_loss: 0.1849 - val_iou_score: 0.7118 - val_f1-score: 0.8148 - 108s/epoch - 695ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 109s - loss: 0.1613 - iou_score: 0.7426 - f1-score: 0.8383 - val_loss: 0.1900 - val_iou_score: 0.7085 - val_f1-score: 0.8105 - 109s/epoch - 696ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 109s - loss: 0.1588 - iou_score: 0.7455 - f1-score: 0.8405 - val_loss: 0.1883 - val_iou_score: 0.7087 - val_f1-score: 0.8116 - 109s/epoch - 700ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 109s - loss: 0.1590 - iou_score: 0.7447 - f1-score: 0.8395 - val_loss: 0.1725 - val_iou_score: 0.7246 - val_f1-score: 0.8254 - 109s/epoch - 696ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 109s - loss: 0.1525 - iou_score: 0.7537 - f1-score: 0.8466 - val_loss: 0.1805 - val_iou_score: 0.7185 - val_f1-score: 0.8198 - 109s/epoch - 696ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 109s - loss: 0.1532 - iou_score: 0.7526 - f1-score: 0.8459 - val_loss: 0.1973 - val_iou_score: 0.6918 - val_f1-score: 0.8022 - 109s/epoch - 696ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 108s - loss: 0.1518 - iou_score: 0.7542 - f1-score: 0.8472 - val_loss: 0.1722 - val_iou_score: 0.7294 - val_f1-score: 0.8286 - 108s/epoch - 694ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 109s - loss: 0.1531 - iou_score: 0.7519 - f1-score: 0.8457 - val_loss: 0.1785 - val_iou_score: 0.7187 - val_f1-score: 0.8209 - 109s/epoch - 698ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 109s - loss: 0.1484 - iou_score: 0.7595 - f1-score: 0.8515 - val_loss: 0.1704 - val_iou_score: 0.7307 - val_f1-score: 0.8303 - 109s/epoch - 697ms/step\n",
      "2023/09/25 21:03:47 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 21:04:20 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpnl0jvkux/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 21:04:20 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 21:04:20 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 21:04:20 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 73\n",
      "Created version '73' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 21:04:53.275074: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 21:04:53.676208: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 21:04:53.676246: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 21:04:53.676251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 21:04:55 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 21:04:55 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5eccde9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5eccde9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5eccde9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5eccde9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 137s - loss: 0.2985 - iou_score: 0.5859 - f1-score: 0.7004 - val_loss: 0.2704 - val_iou_score: 0.6074 - val_f1-score: 0.7281 - 137s/epoch - 881ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 107s - loss: 0.2281 - iou_score: 0.6611 - f1-score: 0.7721 - val_loss: 0.2435 - val_iou_score: 0.6400 - val_f1-score: 0.7545 - 107s/epoch - 683ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 108s - loss: 0.2101 - iou_score: 0.6814 - f1-score: 0.7897 - val_loss: 0.2135 - val_iou_score: 0.6763 - val_f1-score: 0.7867 - 108s/epoch - 690ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 108s - loss: 0.2029 - iou_score: 0.6905 - f1-score: 0.7967 - val_loss: 0.2068 - val_iou_score: 0.6845 - val_f1-score: 0.7905 - 108s/epoch - 691ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 108s - loss: 0.1931 - iou_score: 0.7012 - f1-score: 0.8060 - val_loss: 0.2014 - val_iou_score: 0.6893 - val_f1-score: 0.7974 - 108s/epoch - 692ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 108s - loss: 0.1882 - iou_score: 0.7066 - f1-score: 0.8102 - val_loss: 0.1876 - val_iou_score: 0.7077 - val_f1-score: 0.8121 - 108s/epoch - 691ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 108s - loss: 0.1806 - iou_score: 0.7180 - f1-score: 0.8191 - val_loss: 0.1881 - val_iou_score: 0.7077 - val_f1-score: 0.8113 - 108s/epoch - 695ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 107s - loss: 0.1766 - iou_score: 0.7228 - f1-score: 0.8232 - val_loss: 0.1823 - val_iou_score: 0.7176 - val_f1-score: 0.8185 - 107s/epoch - 688ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 109s - loss: 0.1712 - iou_score: 0.7296 - f1-score: 0.8284 - val_loss: 0.1835 - val_iou_score: 0.7149 - val_f1-score: 0.8161 - 109s/epoch - 697ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 110s - loss: 0.1689 - iou_score: 0.7313 - f1-score: 0.8296 - val_loss: 0.1768 - val_iou_score: 0.7204 - val_f1-score: 0.8215 - 110s/epoch - 703ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 109s - loss: 0.1686 - iou_score: 0.7324 - f1-score: 0.8304 - val_loss: 0.1941 - val_iou_score: 0.6995 - val_f1-score: 0.8062 - 109s/epoch - 697ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 108s - loss: 0.1722 - iou_score: 0.7263 - f1-score: 0.8254 - val_loss: 0.1765 - val_iou_score: 0.7211 - val_f1-score: 0.8229 - 108s/epoch - 694ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 109s - loss: 0.1671 - iou_score: 0.7338 - f1-score: 0.8320 - val_loss: 0.1708 - val_iou_score: 0.7305 - val_f1-score: 0.8299 - 109s/epoch - 700ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 109s - loss: 0.1639 - iou_score: 0.7376 - f1-score: 0.8350 - val_loss: 0.1820 - val_iou_score: 0.7140 - val_f1-score: 0.8176 - 109s/epoch - 697ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 108s - loss: 0.1614 - iou_score: 0.7420 - f1-score: 0.8385 - val_loss: 0.1766 - val_iou_score: 0.7232 - val_f1-score: 0.8240 - 108s/epoch - 693ms/step\n",
      "2023/09/25 21:32:44 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 21:33:18 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpx5mfhppn/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 21:33:18 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 21:33:18 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 21:33:18 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 74\n",
      "Created version '74' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 21:33:51.599651: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 21:33:52.003291: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 21:33:52.003328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 21:33:52.003333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 21:33:53 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 21:33:53 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f89cd7edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f89cd7edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f89cd7edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f89cd7edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 136s - loss: 0.3014 - iou_score: 0.5777 - f1-score: 0.6969 - val_loss: 0.2991 - val_iou_score: 0.5706 - val_f1-score: 0.6992 - 136s/epoch - 869ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 105s - loss: 0.2277 - iou_score: 0.6588 - f1-score: 0.7724 - val_loss: 0.2468 - val_iou_score: 0.6415 - val_f1-score: 0.7522 - 105s/epoch - 672ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 105s - loss: 0.2048 - iou_score: 0.6870 - f1-score: 0.7951 - val_loss: 0.2127 - val_iou_score: 0.6768 - val_f1-score: 0.7873 - 105s/epoch - 672ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 105s - loss: 0.1942 - iou_score: 0.6997 - f1-score: 0.8051 - val_loss: 0.1947 - val_iou_score: 0.6978 - val_f1-score: 0.8024 - 105s/epoch - 674ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 105s - loss: 0.1901 - iou_score: 0.7053 - f1-score: 0.8093 - val_loss: 0.2043 - val_iou_score: 0.6865 - val_f1-score: 0.7935 - 105s/epoch - 675ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 105s - loss: 0.1862 - iou_score: 0.7094 - f1-score: 0.8123 - val_loss: 0.1919 - val_iou_score: 0.7026 - val_f1-score: 0.8077 - 105s/epoch - 673ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 106s - loss: 0.1783 - iou_score: 0.7208 - f1-score: 0.8214 - val_loss: 0.1855 - val_iou_score: 0.7119 - val_f1-score: 0.8141 - 106s/epoch - 678ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 105s - loss: 0.1729 - iou_score: 0.7262 - f1-score: 0.8258 - val_loss: 0.1808 - val_iou_score: 0.7182 - val_f1-score: 0.8198 - 105s/epoch - 673ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 106s - loss: 0.1694 - iou_score: 0.7317 - f1-score: 0.8301 - val_loss: 0.1820 - val_iou_score: 0.7160 - val_f1-score: 0.8181 - 106s/epoch - 678ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 105s - loss: 0.1687 - iou_score: 0.7299 - f1-score: 0.8283 - val_loss: 0.1770 - val_iou_score: 0.7186 - val_f1-score: 0.8212 - 105s/epoch - 676ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 107s - loss: 0.1658 - iou_score: 0.7354 - f1-score: 0.8332 - val_loss: 0.2011 - val_iou_score: 0.6917 - val_f1-score: 0.7989 - 107s/epoch - 685ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 105s - loss: 0.1688 - iou_score: 0.7314 - f1-score: 0.8306 - val_loss: 0.1816 - val_iou_score: 0.7146 - val_f1-score: 0.8174 - 105s/epoch - 676ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 106s - loss: 0.1627 - iou_score: 0.7394 - f1-score: 0.8364 - val_loss: 0.1712 - val_iou_score: 0.7289 - val_f1-score: 0.8295 - 106s/epoch - 678ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 107s - loss: 0.1583 - iou_score: 0.7457 - f1-score: 0.8408 - val_loss: 0.1707 - val_iou_score: 0.7291 - val_f1-score: 0.8290 - 107s/epoch - 684ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 106s - loss: 0.1574 - iou_score: 0.7466 - f1-score: 0.8419 - val_loss: 0.1742 - val_iou_score: 0.7253 - val_f1-score: 0.8263 - 106s/epoch - 679ms/step\n",
      "2023/09/25 22:01:03 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 22:01:37 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpjc2ptzbp/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 22:01:37 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 22:01:37 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 22:01:37 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 75\n",
      "Created version '75' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 22:02:10.399937: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 22:02:10.808088: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 22:02:10.808127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 22:02:10.808132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 22:02:12 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 22:02:12 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f30af9edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f30af9edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f30af9edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f30af9edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 138s - loss: 0.3152 - iou_score: 0.5620 - f1-score: 0.6833 - val_loss: 0.2826 - val_iou_score: 0.5925 - val_f1-score: 0.7157 - 138s/epoch - 882ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 106s - loss: 0.2423 - iou_score: 0.6404 - f1-score: 0.7572 - val_loss: 0.2399 - val_iou_score: 0.6453 - val_f1-score: 0.7585 - 106s/epoch - 677ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 106s - loss: 0.2217 - iou_score: 0.6653 - f1-score: 0.7778 - val_loss: 0.2115 - val_iou_score: 0.6796 - val_f1-score: 0.7888 - 106s/epoch - 680ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 106s - loss: 0.2060 - iou_score: 0.6854 - f1-score: 0.7939 - val_loss: 0.2026 - val_iou_score: 0.6878 - val_f1-score: 0.7946 - 106s/epoch - 678ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 106s - loss: 0.1997 - iou_score: 0.6916 - f1-score: 0.7992 - val_loss: 0.1932 - val_iou_score: 0.6989 - val_f1-score: 0.8053 - 106s/epoch - 678ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 106s - loss: 0.1951 - iou_score: 0.6968 - f1-score: 0.8032 - val_loss: 0.1887 - val_iou_score: 0.7074 - val_f1-score: 0.8106 - 106s/epoch - 680ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 106s - loss: 0.1919 - iou_score: 0.7024 - f1-score: 0.8078 - val_loss: 0.1855 - val_iou_score: 0.7094 - val_f1-score: 0.8141 - 106s/epoch - 678ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 106s - loss: 0.1901 - iou_score: 0.7013 - f1-score: 0.8071 - val_loss: 0.1784 - val_iou_score: 0.7202 - val_f1-score: 0.8224 - 106s/epoch - 679ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 107s - loss: 0.1847 - iou_score: 0.7102 - f1-score: 0.8142 - val_loss: 0.1816 - val_iou_score: 0.7172 - val_f1-score: 0.8184 - 107s/epoch - 686ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 107s - loss: 0.1823 - iou_score: 0.7132 - f1-score: 0.8161 - val_loss: 0.1841 - val_iou_score: 0.7114 - val_f1-score: 0.8141 - 107s/epoch - 689ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 106s - loss: 0.1791 - iou_score: 0.7179 - f1-score: 0.8198 - val_loss: 0.1862 - val_iou_score: 0.7116 - val_f1-score: 0.8139 - 106s/epoch - 680ms/step\n",
      "2023/09/25 22:23:03 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 22:23:37 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp6dqmtza1/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 22:23:37 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 22:23:37 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 22:23:37 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 76\n",
      "Created version '76' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 22:24:10.057085: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 22:24:10.463699: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 22:24:10.463737: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 22:24:10.463743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 22:24:12 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 22:24:12 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5fd8695d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5fd8695d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5fd8695d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5fd8695d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 135s - loss: 0.3057 - iou_score: 0.5733 - f1-score: 0.6929 - val_loss: 0.2738 - val_iou_score: 0.6017 - val_f1-score: 0.7246 - 135s/epoch - 867ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 105s - loss: 0.2280 - iou_score: 0.6578 - f1-score: 0.7715 - val_loss: 0.2436 - val_iou_score: 0.6443 - val_f1-score: 0.7551 - 105s/epoch - 676ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 105s - loss: 0.2071 - iou_score: 0.6840 - f1-score: 0.7925 - val_loss: 0.2192 - val_iou_score: 0.6723 - val_f1-score: 0.7807 - 105s/epoch - 673ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 106s - loss: 0.1964 - iou_score: 0.6964 - f1-score: 0.8023 - val_loss: 0.1938 - val_iou_score: 0.6982 - val_f1-score: 0.8035 - 106s/epoch - 679ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 106s - loss: 0.1880 - iou_score: 0.7066 - f1-score: 0.8111 - val_loss: 0.1895 - val_iou_score: 0.7041 - val_f1-score: 0.8089 - 106s/epoch - 680ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 106s - loss: 0.1836 - iou_score: 0.7121 - f1-score: 0.8148 - val_loss: 0.1914 - val_iou_score: 0.7015 - val_f1-score: 0.8075 - 106s/epoch - 678ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 106s - loss: 0.1784 - iou_score: 0.7188 - f1-score: 0.8201 - val_loss: 0.1870 - val_iou_score: 0.7083 - val_f1-score: 0.8125 - 106s/epoch - 681ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 105s - loss: 0.1729 - iou_score: 0.7262 - f1-score: 0.8259 - val_loss: 0.1789 - val_iou_score: 0.7216 - val_f1-score: 0.8219 - 105s/epoch - 674ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 105s - loss: 0.1677 - iou_score: 0.7336 - f1-score: 0.8319 - val_loss: 0.1808 - val_iou_score: 0.7172 - val_f1-score: 0.8192 - 105s/epoch - 674ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 107s - loss: 0.1688 - iou_score: 0.7295 - f1-score: 0.8282 - val_loss: 0.1767 - val_iou_score: 0.7198 - val_f1-score: 0.8212 - 107s/epoch - 684ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 105s - loss: 0.1656 - iou_score: 0.7357 - f1-score: 0.8335 - val_loss: 0.2241 - val_iou_score: 0.6746 - val_f1-score: 0.7763 - 105s/epoch - 675ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 105s - loss: 0.1664 - iou_score: 0.7341 - f1-score: 0.8323 - val_loss: 0.1737 - val_iou_score: 0.7247 - val_f1-score: 0.8262 - 105s/epoch - 676ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 105s - loss: 0.1654 - iou_score: 0.7354 - f1-score: 0.8336 - val_loss: 0.1760 - val_iou_score: 0.7224 - val_f1-score: 0.8247 - 105s/epoch - 676ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 105s - loss: 0.1598 - iou_score: 0.7425 - f1-score: 0.8381 - val_loss: 0.1701 - val_iou_score: 0.7291 - val_f1-score: 0.8293 - 105s/epoch - 675ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 106s - loss: 0.1572 - iou_score: 0.7477 - f1-score: 0.8427 - val_loss: 0.1683 - val_iou_score: 0.7329 - val_f1-score: 0.8325 - 106s/epoch - 681ms/step\n",
      "2023/09/25 22:51:23 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 22:51:56 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp_c49qagw/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 22:51:57 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 22:51:57 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 22:51:57 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 77\n",
      "Created version '77' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 22:52:29.750420: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 22:52:30.153507: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 22:52:30.153545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 22:52:30.153550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 22:52:31 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 22:52:31 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fa92da75d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fa92da75d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fa92da75d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fa92da75d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 137s - loss: 0.3196 - iou_score: 0.5581 - f1-score: 0.6788 - val_loss: 0.2988 - val_iou_score: 0.5741 - val_f1-score: 0.7004 - 137s/epoch - 876ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 104s - loss: 0.2452 - iou_score: 0.6374 - f1-score: 0.7550 - val_loss: 0.2594 - val_iou_score: 0.6284 - val_f1-score: 0.7389 - 104s/epoch - 668ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 105s - loss: 0.2240 - iou_score: 0.6623 - f1-score: 0.7759 - val_loss: 0.2168 - val_iou_score: 0.6709 - val_f1-score: 0.7832 - 105s/epoch - 675ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 106s - loss: 0.2089 - iou_score: 0.6800 - f1-score: 0.7897 - val_loss: 0.2035 - val_iou_score: 0.6874 - val_f1-score: 0.7935 - 106s/epoch - 678ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 106s - loss: 0.2012 - iou_score: 0.6897 - f1-score: 0.7979 - val_loss: 0.1919 - val_iou_score: 0.7012 - val_f1-score: 0.8064 - 106s/epoch - 678ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 106s - loss: 0.1995 - iou_score: 0.6913 - f1-score: 0.7989 - val_loss: 0.1959 - val_iou_score: 0.6958 - val_f1-score: 0.8038 - 106s/epoch - 677ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 105s - loss: 0.1943 - iou_score: 0.6994 - f1-score: 0.8055 - val_loss: 0.1873 - val_iou_score: 0.7086 - val_f1-score: 0.8123 - 105s/epoch - 674ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 107s - loss: 0.1888 - iou_score: 0.7059 - f1-score: 0.8110 - val_loss: 0.1824 - val_iou_score: 0.7147 - val_f1-score: 0.8183 - 107s/epoch - 683ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 106s - loss: 0.1871 - iou_score: 0.7083 - f1-score: 0.8127 - val_loss: 0.1977 - val_iou_score: 0.6991 - val_f1-score: 0.8024 - 106s/epoch - 680ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 107s - loss: 0.1873 - iou_score: 0.7067 - f1-score: 0.8112 - val_loss: 0.1780 - val_iou_score: 0.7184 - val_f1-score: 0.8203 - 107s/epoch - 687ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 106s - loss: 0.1836 - iou_score: 0.7110 - f1-score: 0.8145 - val_loss: 0.2328 - val_iou_score: 0.6455 - val_f1-score: 0.7675 - 106s/epoch - 676ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 106s - loss: 0.1870 - iou_score: 0.7068 - f1-score: 0.8122 - val_loss: 0.1799 - val_iou_score: 0.7164 - val_f1-score: 0.8198 - 106s/epoch - 679ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 106s - loss: 0.1775 - iou_score: 0.7176 - f1-score: 0.8197 - val_loss: 0.1734 - val_iou_score: 0.7267 - val_f1-score: 0.8273 - 106s/epoch - 682ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 108s - loss: 0.1768 - iou_score: 0.7204 - f1-score: 0.8223 - val_loss: 0.1741 - val_iou_score: 0.7242 - val_f1-score: 0.8256 - 108s/epoch - 691ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 106s - loss: 0.1728 - iou_score: 0.7253 - f1-score: 0.8265 - val_loss: 0.1745 - val_iou_score: 0.7234 - val_f1-score: 0.8260 - 106s/epoch - 680ms/step\n",
      "2023/09/25 23:19:48 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 23:20:21 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpzy6lbevd/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 23:20:21 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 23:20:21 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 23:20:21 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 78\n",
      "Created version '78' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 23:20:54.642650: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 23:20:55.064155: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 23:20:55.064194: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 23:20:55.064201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 23:20:56 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 23:20:56 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fa2a5889d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fa2a5889d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fa2a5889d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fa2a5889d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 142s - loss: 0.3050 - iou_score: 0.5744 - f1-score: 0.6938 - val_loss: 0.3247 - val_iou_score: 0.5484 - val_f1-score: 0.6727 - 142s/epoch - 912ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 112s - loss: 0.2354 - iou_score: 0.6496 - f1-score: 0.7649 - val_loss: 0.2835 - val_iou_score: 0.5943 - val_f1-score: 0.7149 - 112s/epoch - 716ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 113s - loss: 0.2125 - iou_score: 0.6762 - f1-score: 0.7866 - val_loss: 0.2352 - val_iou_score: 0.6553 - val_f1-score: 0.7652 - 113s/epoch - 724ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 112s - loss: 0.1982 - iou_score: 0.6949 - f1-score: 0.8011 - val_loss: 0.2053 - val_iou_score: 0.6849 - val_f1-score: 0.7914 - 112s/epoch - 721ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 114s - loss: 0.1914 - iou_score: 0.7024 - f1-score: 0.8073 - val_loss: 0.2080 - val_iou_score: 0.6829 - val_f1-score: 0.7908 - 114s/epoch - 728ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 114s - loss: 0.1851 - iou_score: 0.7107 - f1-score: 0.8135 - val_loss: 0.1904 - val_iou_score: 0.7043 - val_f1-score: 0.8096 - 114s/epoch - 729ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 114s - loss: 0.1808 - iou_score: 0.7169 - f1-score: 0.8188 - val_loss: 0.1832 - val_iou_score: 0.7130 - val_f1-score: 0.8164 - 114s/epoch - 729ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 114s - loss: 0.1748 - iou_score: 0.7247 - f1-score: 0.8253 - val_loss: 0.1822 - val_iou_score: 0.7168 - val_f1-score: 0.8183 - 114s/epoch - 730ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 113s - loss: 0.1722 - iou_score: 0.7271 - f1-score: 0.8269 - val_loss: 0.1765 - val_iou_score: 0.7231 - val_f1-score: 0.8234 - 113s/epoch - 726ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 114s - loss: 0.1696 - iou_score: 0.7305 - f1-score: 0.8290 - val_loss: 0.1825 - val_iou_score: 0.7110 - val_f1-score: 0.8158 - 114s/epoch - 729ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 114s - loss: 0.1671 - iou_score: 0.7328 - f1-score: 0.8310 - val_loss: 0.1753 - val_iou_score: 0.7246 - val_f1-score: 0.8248 - 114s/epoch - 732ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 113s - loss: 0.1653 - iou_score: 0.7359 - f1-score: 0.8335 - val_loss: 0.1720 - val_iou_score: 0.7273 - val_f1-score: 0.8276 - 113s/epoch - 725ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 115s - loss: 0.1615 - iou_score: 0.7402 - f1-score: 0.8367 - val_loss: 0.1711 - val_iou_score: 0.7309 - val_f1-score: 0.8298 - 115s/epoch - 735ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 112s - loss: 0.1611 - iou_score: 0.7409 - f1-score: 0.8370 - val_loss: 0.1710 - val_iou_score: 0.7299 - val_f1-score: 0.8287 - 112s/epoch - 718ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 115s - loss: 0.1600 - iou_score: 0.7436 - f1-score: 0.8400 - val_loss: 0.1673 - val_iou_score: 0.7353 - val_f1-score: 0.8335 - 115s/epoch - 736ms/step\n",
      "2023/09/25 23:50:32 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/25 23:51:05 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpzz2q4g2s/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/25 23:51:05 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 23:51:05 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/25 23:51:05 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 79\n",
      "Created version '79' of model 'fpn'.\n",
      "job end\n",
      "2023-09-25 23:51:38.444947: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 23:51:38.841118: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 23:51:38.841153: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 23:51:38.841158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/25 23:51:40 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/25 23:51:40 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7ff9a61d9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7ff9a61d9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7ff9a61d9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7ff9a61d9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 141s - loss: 0.3195 - iou_score: 0.5591 - f1-score: 0.6795 - val_loss: 0.3155 - val_iou_score: 0.5563 - val_f1-score: 0.6833 - 141s/epoch - 906ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 111s - loss: 0.2476 - iou_score: 0.6347 - f1-score: 0.7528 - val_loss: 0.2703 - val_iou_score: 0.6137 - val_f1-score: 0.7283 - 111s/epoch - 711ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 111s - loss: 0.2279 - iou_score: 0.6571 - f1-score: 0.7719 - val_loss: 0.2250 - val_iou_score: 0.6646 - val_f1-score: 0.7752 - 111s/epoch - 710ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 112s - loss: 0.2115 - iou_score: 0.6770 - f1-score: 0.7878 - val_loss: 0.2144 - val_iou_score: 0.6762 - val_f1-score: 0.7819 - 112s/epoch - 718ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 112s - loss: 0.2035 - iou_score: 0.6867 - f1-score: 0.7957 - val_loss: 0.2292 - val_iou_score: 0.6601 - val_f1-score: 0.7694 - 112s/epoch - 717ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 111s - loss: 0.2050 - iou_score: 0.6848 - f1-score: 0.7934 - val_loss: 0.1957 - val_iou_score: 0.6985 - val_f1-score: 0.8038 - 111s/epoch - 711ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 112s - loss: 0.1958 - iou_score: 0.6967 - f1-score: 0.8030 - val_loss: 0.1849 - val_iou_score: 0.7118 - val_f1-score: 0.8149 - 112s/epoch - 720ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 111s - loss: 0.1929 - iou_score: 0.7001 - f1-score: 0.8058 - val_loss: 0.2014 - val_iou_score: 0.6943 - val_f1-score: 0.7990 - 111s/epoch - 709ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 112s - loss: 0.1935 - iou_score: 0.6987 - f1-score: 0.8054 - val_loss: 0.1883 - val_iou_score: 0.7067 - val_f1-score: 0.8114 - 112s/epoch - 720ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 112s - loss: 0.1871 - iou_score: 0.7071 - f1-score: 0.8115 - val_loss: 0.1798 - val_iou_score: 0.7167 - val_f1-score: 0.8185 - 112s/epoch - 716ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 112s - loss: 0.1830 - iou_score: 0.7110 - f1-score: 0.8139 - val_loss: 0.1865 - val_iou_score: 0.7114 - val_f1-score: 0.8137 - 112s/epoch - 717ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 117s - loss: 0.1810 - iou_score: 0.7152 - f1-score: 0.8181 - val_loss: 0.1763 - val_iou_score: 0.7215 - val_f1-score: 0.8229 - 117s/epoch - 747ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 114s - loss: 0.1759 - iou_score: 0.7217 - f1-score: 0.8233 - val_loss: 0.1751 - val_iou_score: 0.7241 - val_f1-score: 0.8256 - 114s/epoch - 734ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 114s - loss: 0.1782 - iou_score: 0.7186 - f1-score: 0.8199 - val_loss: 0.1735 - val_iou_score: 0.7263 - val_f1-score: 0.8259 - 114s/epoch - 732ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 116s - loss: 0.1782 - iou_score: 0.7191 - f1-score: 0.8216 - val_loss: 0.1725 - val_iou_score: 0.7277 - val_f1-score: 0.8282 - 116s/epoch - 742ms/step\n",
      "2023/09/26 00:20:37 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/26 00:21:10 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpwugdi746/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/26 00:21:10 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 00:21:10 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/26 00:21:10 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 80\n",
      "Created version '80' of model 'fpn'.\n",
      "job end\n",
      "2023-09-26 00:21:43.685905: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 00:21:44.099756: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 00:21:44.099794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 00:21:44.099799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/26 00:21:45 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 00:21:45 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f603e3ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f603e3ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f603e3ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f603e3ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 144s - loss: 0.3076 - iou_score: 0.5710 - f1-score: 0.6901 - val_loss: 0.2945 - val_iou_score: 0.5779 - val_f1-score: 0.7040 - 144s/epoch - 926ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 112s - loss: 0.2335 - iou_score: 0.6517 - f1-score: 0.7668 - val_loss: 0.2608 - val_iou_score: 0.6267 - val_f1-score: 0.7377 - 112s/epoch - 719ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 111s - loss: 0.2124 - iou_score: 0.6772 - f1-score: 0.7874 - val_loss: 0.2175 - val_iou_score: 0.6747 - val_f1-score: 0.7829 - 111s/epoch - 710ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 111s - loss: 0.1985 - iou_score: 0.6939 - f1-score: 0.8006 - val_loss: 0.2172 - val_iou_score: 0.6748 - val_f1-score: 0.7797 - 111s/epoch - 711ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 110s - loss: 0.1908 - iou_score: 0.7032 - f1-score: 0.8082 - val_loss: 0.1947 - val_iou_score: 0.6973 - val_f1-score: 0.8035 - 110s/epoch - 708ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 111s - loss: 0.1874 - iou_score: 0.7060 - f1-score: 0.8103 - val_loss: 0.1925 - val_iou_score: 0.7009 - val_f1-score: 0.8073 - 111s/epoch - 710ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.1850 - iou_score: 0.7114 - f1-score: 0.8144 - val_loss: 0.1851 - val_iou_score: 0.7115 - val_f1-score: 0.8143 - 111s/epoch - 714ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 112s - loss: 0.1793 - iou_score: 0.7187 - f1-score: 0.8206 - val_loss: 0.1896 - val_iou_score: 0.7082 - val_f1-score: 0.8110 - 112s/epoch - 717ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 112s - loss: 0.1743 - iou_score: 0.7246 - f1-score: 0.8253 - val_loss: 0.1807 - val_iou_score: 0.7167 - val_f1-score: 0.8194 - 112s/epoch - 715ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 112s - loss: 0.1723 - iou_score: 0.7267 - f1-score: 0.8264 - val_loss: 0.1751 - val_iou_score: 0.7226 - val_f1-score: 0.8232 - 112s/epoch - 718ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 111s - loss: 0.1688 - iou_score: 0.7310 - f1-score: 0.8301 - val_loss: 0.1717 - val_iou_score: 0.7294 - val_f1-score: 0.8284 - 111s/epoch - 711ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 113s - loss: 0.1649 - iou_score: 0.7363 - f1-score: 0.8341 - val_loss: 0.1711 - val_iou_score: 0.7282 - val_f1-score: 0.8286 - 113s/epoch - 722ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 112s - loss: 0.1643 - iou_score: 0.7373 - f1-score: 0.8347 - val_loss: 0.1755 - val_iou_score: 0.7258 - val_f1-score: 0.8254 - 112s/epoch - 720ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 106s - loss: 0.1657 - iou_score: 0.7349 - f1-score: 0.8333 - val_loss: 0.1756 - val_iou_score: 0.7223 - val_f1-score: 0.8241 - 106s/epoch - 681ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 111s - loss: 0.1624 - iou_score: 0.7396 - f1-score: 0.8364 - val_loss: 0.1698 - val_iou_score: 0.7315 - val_f1-score: 0.8308 - 111s/epoch - 715ms/step\n",
      "2023/09/26 00:50:23 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/26 00:50:56 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpr8v636cb/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/26 00:50:57 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 00:50:57 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/26 00:50:57 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 81\n",
      "Created version '81' of model 'fpn'.\n",
      "job end\n",
      "2023-09-26 00:51:29.825164: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 00:51:30.230392: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 00:51:30.230430: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 00:51:30.230435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/26 00:51:31 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 00:51:31 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f63b43d9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f63b43d9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f63b43d9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f63b43d9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 142s - loss: 0.3225 - iou_score: 0.5537 - f1-score: 0.6754 - val_loss: 0.3117 - val_iou_score: 0.5563 - val_f1-score: 0.6866 - 142s/epoch - 907ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 111s - loss: 0.2512 - iou_score: 0.6299 - f1-score: 0.7491 - val_loss: 0.2647 - val_iou_score: 0.6211 - val_f1-score: 0.7335 - 111s/epoch - 712ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 111s - loss: 0.2291 - iou_score: 0.6560 - f1-score: 0.7705 - val_loss: 0.2111 - val_iou_score: 0.6804 - val_f1-score: 0.7890 - 111s/epoch - 710ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 113s - loss: 0.2138 - iou_score: 0.6751 - f1-score: 0.7860 - val_loss: 0.2019 - val_iou_score: 0.6870 - val_f1-score: 0.7947 - 113s/epoch - 725ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 114s - loss: 0.2077 - iou_score: 0.6819 - f1-score: 0.7916 - val_loss: 0.2114 - val_iou_score: 0.6776 - val_f1-score: 0.7872 - 114s/epoch - 728ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 114s - loss: 0.2027 - iou_score: 0.6870 - f1-score: 0.7954 - val_loss: 0.2011 - val_iou_score: 0.6902 - val_f1-score: 0.7985 - 114s/epoch - 732ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 114s - loss: 0.1962 - iou_score: 0.6960 - f1-score: 0.8028 - val_loss: 0.1862 - val_iou_score: 0.7097 - val_f1-score: 0.8130 - 114s/epoch - 732ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 114s - loss: 0.1917 - iou_score: 0.7024 - f1-score: 0.8081 - val_loss: 0.1877 - val_iou_score: 0.7091 - val_f1-score: 0.8129 - 114s/epoch - 729ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 114s - loss: 0.1968 - iou_score: 0.6938 - f1-score: 0.8020 - val_loss: 0.1882 - val_iou_score: 0.7086 - val_f1-score: 0.8120 - 114s/epoch - 728ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 114s - loss: 0.1909 - iou_score: 0.7006 - f1-score: 0.8067 - val_loss: 0.1788 - val_iou_score: 0.7164 - val_f1-score: 0.8189 - 114s/epoch - 730ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 114s - loss: 0.1844 - iou_score: 0.7100 - f1-score: 0.8143 - val_loss: 0.1756 - val_iou_score: 0.7242 - val_f1-score: 0.8245 - 114s/epoch - 730ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 114s - loss: 0.1825 - iou_score: 0.7139 - f1-score: 0.8168 - val_loss: 0.1809 - val_iou_score: 0.7163 - val_f1-score: 0.8188 - 114s/epoch - 733ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 114s - loss: 0.1832 - iou_score: 0.7113 - f1-score: 0.8156 - val_loss: 0.1856 - val_iou_score: 0.7105 - val_f1-score: 0.8153 - 114s/epoch - 731ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 113s - loss: 0.1828 - iou_score: 0.7118 - f1-score: 0.8154 - val_loss: 0.1790 - val_iou_score: 0.7170 - val_f1-score: 0.8204 - 113s/epoch - 727ms/step\n",
      "2023/09/26 01:18:44 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/26 01:19:17 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp4uc0aa6q/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/26 01:19:17 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 01:19:17 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/26 01:19:17 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 82\n",
      "Created version '82' of model 'fpn'.\n",
      "job end\n",
      "2023-09-26 01:19:50.597637: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 01:19:51.002695: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 01:19:51.002734: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 01:19:51.002739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/26 01:19:52 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 01:19:52 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f64e59edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f64e59edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f64e59edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f64e59edd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 139s - loss: 0.3089 - iou_score: 0.5709 - f1-score: 0.6895 - val_loss: 0.3010 - val_iou_score: 0.5770 - val_f1-score: 0.6981 - 139s/epoch - 889ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 106s - loss: 0.2388 - iou_score: 0.6463 - f1-score: 0.7611 - val_loss: 0.2699 - val_iou_score: 0.6146 - val_f1-score: 0.7284 - 106s/epoch - 679ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 106s - loss: 0.2172 - iou_score: 0.6712 - f1-score: 0.7823 - val_loss: 0.2278 - val_iou_score: 0.6604 - val_f1-score: 0.7726 - 106s/epoch - 678ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 106s - loss: 0.2070 - iou_score: 0.6843 - f1-score: 0.7928 - val_loss: 0.2053 - val_iou_score: 0.6861 - val_f1-score: 0.7918 - 106s/epoch - 682ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 106s - loss: 0.1960 - iou_score: 0.6970 - f1-score: 0.8032 - val_loss: 0.1994 - val_iou_score: 0.6914 - val_f1-score: 0.7988 - 106s/epoch - 682ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 106s - loss: 0.1945 - iou_score: 0.6986 - f1-score: 0.8040 - val_loss: 0.2019 - val_iou_score: 0.6889 - val_f1-score: 0.7980 - 106s/epoch - 682ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 107s - loss: 0.1849 - iou_score: 0.7120 - f1-score: 0.8148 - val_loss: 0.1883 - val_iou_score: 0.7075 - val_f1-score: 0.8112 - 107s/epoch - 687ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 108s - loss: 0.1818 - iou_score: 0.7151 - f1-score: 0.8175 - val_loss: 0.1888 - val_iou_score: 0.7100 - val_f1-score: 0.8119 - 108s/epoch - 690ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 107s - loss: 0.1779 - iou_score: 0.7204 - f1-score: 0.8217 - val_loss: 0.1874 - val_iou_score: 0.7109 - val_f1-score: 0.8126 - 107s/epoch - 688ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 107s - loss: 0.1772 - iou_score: 0.7195 - f1-score: 0.8205 - val_loss: 0.1775 - val_iou_score: 0.7186 - val_f1-score: 0.8203 - 107s/epoch - 688ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 107s - loss: 0.1716 - iou_score: 0.7272 - f1-score: 0.8268 - val_loss: 0.1951 - val_iou_score: 0.6985 - val_f1-score: 0.8049 - 107s/epoch - 686ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 108s - loss: 0.1727 - iou_score: 0.7266 - f1-score: 0.8266 - val_loss: 0.1804 - val_iou_score: 0.7170 - val_f1-score: 0.8190 - 108s/epoch - 694ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 108s - loss: 0.1690 - iou_score: 0.7311 - f1-score: 0.8301 - val_loss: 0.1758 - val_iou_score: 0.7240 - val_f1-score: 0.8248 - 108s/epoch - 693ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 107s - loss: 0.1662 - iou_score: 0.7344 - f1-score: 0.8320 - val_loss: 0.1779 - val_iou_score: 0.7208 - val_f1-score: 0.8218 - 107s/epoch - 688ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 107s - loss: 0.1642 - iou_score: 0.7382 - f1-score: 0.8357 - val_loss: 0.1861 - val_iou_score: 0.7087 - val_f1-score: 0.8146 - 107s/epoch - 685ms/step\n",
      "2023/09/26 01:47:25 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/26 01:47:59 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpsdwmv2pb/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/26 01:47:59 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 01:47:59 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/26 01:47:59 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 83\n",
      "Created version '83' of model 'fpn'.\n",
      "job end\n",
      "2023-09-26 01:48:32.673208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 01:48:33.082491: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 01:48:33.082532: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 01:48:33.082538: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/26 01:48:34 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 01:48:34 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f8c7c7ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f8c7c7ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f8c7c7ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f8c7c7ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 138s - loss: 0.3274 - iou_score: 0.5491 - f1-score: 0.6706 - val_loss: 0.2835 - val_iou_score: 0.5901 - val_f1-score: 0.7147 - 138s/epoch - 885ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 105s - loss: 0.2537 - iou_score: 0.6288 - f1-score: 0.7466 - val_loss: 0.2555 - val_iou_score: 0.6333 - val_f1-score: 0.7431 - 105s/epoch - 675ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 107s - loss: 0.2348 - iou_score: 0.6494 - f1-score: 0.7649 - val_loss: 0.2307 - val_iou_score: 0.6565 - val_f1-score: 0.7691 - 107s/epoch - 688ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 107s - loss: 0.2200 - iou_score: 0.6675 - f1-score: 0.7797 - val_loss: 0.2050 - val_iou_score: 0.6850 - val_f1-score: 0.7921 - 107s/epoch - 683ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 108s - loss: 0.2136 - iou_score: 0.6743 - f1-score: 0.7857 - val_loss: 0.2077 - val_iou_score: 0.6816 - val_f1-score: 0.7904 - 108s/epoch - 690ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 108s - loss: 0.2086 - iou_score: 0.6799 - f1-score: 0.7895 - val_loss: 0.1967 - val_iou_score: 0.6982 - val_f1-score: 0.8032 - 108s/epoch - 690ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 107s - loss: 0.2031 - iou_score: 0.6887 - f1-score: 0.7967 - val_loss: 0.1904 - val_iou_score: 0.7047 - val_f1-score: 0.8096 - 107s/epoch - 685ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 108s - loss: 0.1980 - iou_score: 0.6948 - f1-score: 0.8020 - val_loss: 0.1873 - val_iou_score: 0.7107 - val_f1-score: 0.8136 - 108s/epoch - 693ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 107s - loss: 0.1914 - iou_score: 0.7022 - f1-score: 0.8081 - val_loss: 0.1861 - val_iou_score: 0.7108 - val_f1-score: 0.8137 - 107s/epoch - 689ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 106s - loss: 0.1912 - iou_score: 0.7020 - f1-score: 0.8073 - val_loss: 0.1778 - val_iou_score: 0.7187 - val_f1-score: 0.8201 - 106s/epoch - 682ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 108s - loss: 0.1868 - iou_score: 0.7079 - f1-score: 0.8122 - val_loss: 0.1901 - val_iou_score: 0.7046 - val_f1-score: 0.8100 - 108s/epoch - 691ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 108s - loss: 0.1863 - iou_score: 0.7080 - f1-score: 0.8125 - val_loss: 0.1791 - val_iou_score: 0.7176 - val_f1-score: 0.8204 - 108s/epoch - 694ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 108s - loss: 0.1824 - iou_score: 0.7127 - f1-score: 0.8163 - val_loss: 0.1791 - val_iou_score: 0.7196 - val_f1-score: 0.8218 - 108s/epoch - 692ms/step\n",
      "2023/09/26 02:12:36 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/26 02:13:09 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpljjwgdqr/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/26 02:13:10 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 02:13:10 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/26 02:13:10 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 84\n",
      "Created version '84' of model 'fpn'.\n",
      "job end\n",
      "2023-09-26 02:13:43.061680: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 02:13:43.465924: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 02:13:43.465961: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 02:13:43.465967: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/26 02:13:45 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 02:13:45 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fb6493e5d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fb6493e5d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fb6493e5d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fb6493e5d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 139s - loss: 0.3119 - iou_score: 0.5664 - f1-score: 0.6862 - val_loss: 0.2976 - val_iou_score: 0.5741 - val_f1-score: 0.7013 - 139s/epoch - 893ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 106s - loss: 0.2424 - iou_score: 0.6405 - f1-score: 0.7567 - val_loss: 0.2520 - val_iou_score: 0.6332 - val_f1-score: 0.7463 - 106s/epoch - 681ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 107s - loss: 0.2211 - iou_score: 0.6664 - f1-score: 0.7788 - val_loss: 0.2216 - val_iou_score: 0.6694 - val_f1-score: 0.7785 - 107s/epoch - 688ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 107s - loss: 0.2067 - iou_score: 0.6836 - f1-score: 0.7922 - val_loss: 0.2114 - val_iou_score: 0.6779 - val_f1-score: 0.7859 - 107s/epoch - 684ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 107s - loss: 0.1980 - iou_score: 0.6945 - f1-score: 0.8014 - val_loss: 0.1949 - val_iou_score: 0.6986 - val_f1-score: 0.8037 - 107s/epoch - 683ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 106s - loss: 0.1917 - iou_score: 0.7016 - f1-score: 0.8064 - val_loss: 0.1883 - val_iou_score: 0.7080 - val_f1-score: 0.8114 - 106s/epoch - 682ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 107s - loss: 0.1875 - iou_score: 0.7087 - f1-score: 0.8120 - val_loss: 0.1853 - val_iou_score: 0.7103 - val_f1-score: 0.8148 - 107s/epoch - 689ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 108s - loss: 0.1826 - iou_score: 0.7145 - f1-score: 0.8173 - val_loss: 0.1826 - val_iou_score: 0.7153 - val_f1-score: 0.8175 - 108s/epoch - 690ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 107s - loss: 0.1836 - iou_score: 0.7129 - f1-score: 0.8158 - val_loss: 0.1860 - val_iou_score: 0.7111 - val_f1-score: 0.8137 - 107s/epoch - 688ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 107s - loss: 0.1813 - iou_score: 0.7148 - f1-score: 0.8171 - val_loss: 0.1803 - val_iou_score: 0.7160 - val_f1-score: 0.8180 - 107s/epoch - 689ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 107s - loss: 0.1752 - iou_score: 0.7224 - f1-score: 0.8232 - val_loss: 0.1891 - val_iou_score: 0.7066 - val_f1-score: 0.8108 - 107s/epoch - 688ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 109s - loss: 0.1735 - iou_score: 0.7253 - f1-score: 0.8256 - val_loss: 0.1749 - val_iou_score: 0.7226 - val_f1-score: 0.8243 - 109s/epoch - 696ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 108s - loss: 0.1699 - iou_score: 0.7297 - f1-score: 0.8291 - val_loss: 0.1776 - val_iou_score: 0.7218 - val_f1-score: 0.8232 - 108s/epoch - 692ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 107s - loss: 0.1704 - iou_score: 0.7292 - f1-score: 0.8286 - val_loss: 0.1802 - val_iou_score: 0.7174 - val_f1-score: 0.8198 - 107s/epoch - 686ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 107s - loss: 0.1674 - iou_score: 0.7319 - f1-score: 0.8309 - val_loss: 0.1768 - val_iou_score: 0.7229 - val_f1-score: 0.8240 - 107s/epoch - 688ms/step\n",
      "2023/09/26 02:41:22 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/26 02:41:56 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpwwe2w9fe/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/26 02:41:56 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 02:41:56 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/26 02:41:56 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 85\n",
      "Created version '85' of model 'fpn'.\n",
      "job end\n",
      "2023-09-26 02:42:29.421370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 02:42:29.831358: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 02:42:29.831395: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 02:42:29.831401: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/26 02:42:31 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 02:42:31 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5bb1bf9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5bb1bf9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5bb1bf9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5bb1bf9d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 138s - loss: 0.3268 - iou_score: 0.5490 - f1-score: 0.6716 - val_loss: 0.2952 - val_iou_score: 0.5764 - val_f1-score: 0.7039 - 138s/epoch - 882ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 106s - loss: 0.2547 - iou_score: 0.6263 - f1-score: 0.7455 - val_loss: 0.2432 - val_iou_score: 0.6402 - val_f1-score: 0.7556 - 106s/epoch - 679ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 106s - loss: 0.2402 - iou_score: 0.6422 - f1-score: 0.7591 - val_loss: 0.2357 - val_iou_score: 0.6561 - val_f1-score: 0.7647 - 106s/epoch - 681ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 106s - loss: 0.2292 - iou_score: 0.6560 - f1-score: 0.7705 - val_loss: 0.2074 - val_iou_score: 0.6811 - val_f1-score: 0.7897 - 106s/epoch - 677ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 106s - loss: 0.2150 - iou_score: 0.6719 - f1-score: 0.7839 - val_loss: 0.1976 - val_iou_score: 0.6939 - val_f1-score: 0.8005 - 106s/epoch - 680ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 107s - loss: 0.2093 - iou_score: 0.6785 - f1-score: 0.7889 - val_loss: 0.1973 - val_iou_score: 0.6941 - val_f1-score: 0.8017 - 107s/epoch - 683ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 106s - loss: 0.2069 - iou_score: 0.6821 - f1-score: 0.7921 - val_loss: 0.1895 - val_iou_score: 0.7054 - val_f1-score: 0.8100 - 106s/epoch - 680ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 107s - loss: 0.2035 - iou_score: 0.6864 - f1-score: 0.7954 - val_loss: 0.1937 - val_iou_score: 0.7026 - val_f1-score: 0.8066 - 107s/epoch - 684ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 107s - loss: 0.1944 - iou_score: 0.6984 - f1-score: 0.8049 - val_loss: 0.1836 - val_iou_score: 0.7138 - val_f1-score: 0.8162 - 107s/epoch - 686ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 107s - loss: 0.1953 - iou_score: 0.6959 - f1-score: 0.8029 - val_loss: 0.1868 - val_iou_score: 0.7053 - val_f1-score: 0.8108 - 107s/epoch - 684ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 107s - loss: 0.1915 - iou_score: 0.7021 - f1-score: 0.8074 - val_loss: 0.1960 - val_iou_score: 0.6994 - val_f1-score: 0.8038 - 107s/epoch - 686ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 107s - loss: 0.1887 - iou_score: 0.7050 - f1-score: 0.8103 - val_loss: 0.1791 - val_iou_score: 0.7175 - val_f1-score: 0.8204 - 107s/epoch - 684ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 107s - loss: 0.1872 - iou_score: 0.7074 - f1-score: 0.8119 - val_loss: 0.1862 - val_iou_score: 0.7098 - val_f1-score: 0.8144 - 107s/epoch - 684ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 108s - loss: 0.1882 - iou_score: 0.7050 - f1-score: 0.8100 - val_loss: 0.1850 - val_iou_score: 0.7107 - val_f1-score: 0.8143 - 108s/epoch - 693ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 107s - loss: 0.1827 - iou_score: 0.7132 - f1-score: 0.8172 - val_loss: 0.1788 - val_iou_score: 0.7196 - val_f1-score: 0.8218 - 107s/epoch - 684ms/step\n",
      "2023/09/26 03:09:58 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/26 03:10:31 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmplpexqdyz/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/26 03:10:31 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 03:10:31 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/26 03:10:31 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 86\n",
      "Created version '86' of model 'fpn'.\n",
      "job end\n",
      "2023-09-26 03:11:04.649840: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 03:11:05.057937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 03:11:05.057975: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 03:11:05.057981: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/26 03:11:06 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 03:11:06 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fde751ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fde751ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fde751ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fde751ddd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 143s - loss: 0.3148 - iou_score: 0.5635 - f1-score: 0.6835 - val_loss: 0.3009 - val_iou_score: 0.5672 - val_f1-score: 0.6979 - 143s/epoch - 919ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 111s - loss: 0.2458 - iou_score: 0.6371 - f1-score: 0.7541 - val_loss: 0.2791 - val_iou_score: 0.5954 - val_f1-score: 0.7183 - 111s/epoch - 711ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 110s - loss: 0.2244 - iou_score: 0.6618 - f1-score: 0.7752 - val_loss: 0.2238 - val_iou_score: 0.6667 - val_f1-score: 0.7764 - 110s/epoch - 707ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 113s - loss: 0.2100 - iou_score: 0.6803 - f1-score: 0.7897 - val_loss: 0.2196 - val_iou_score: 0.6730 - val_f1-score: 0.7777 - 113s/epoch - 723ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 112s - loss: 0.2042 - iou_score: 0.6860 - f1-score: 0.7949 - val_loss: 0.2047 - val_iou_score: 0.6843 - val_f1-score: 0.7940 - 112s/epoch - 718ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 112s - loss: 0.1973 - iou_score: 0.6951 - f1-score: 0.8009 - val_loss: 0.1921 - val_iou_score: 0.7026 - val_f1-score: 0.8078 - 112s/epoch - 720ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 113s - loss: 0.1911 - iou_score: 0.7032 - f1-score: 0.8079 - val_loss: 0.1936 - val_iou_score: 0.6997 - val_f1-score: 0.8057 - 113s/epoch - 724ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 111s - loss: 0.1861 - iou_score: 0.7098 - f1-score: 0.8137 - val_loss: 0.1875 - val_iou_score: 0.7095 - val_f1-score: 0.8129 - 111s/epoch - 710ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 111s - loss: 0.1802 - iou_score: 0.7177 - f1-score: 0.8195 - val_loss: 0.1880 - val_iou_score: 0.7085 - val_f1-score: 0.8117 - 111s/epoch - 714ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 113s - loss: 0.1822 - iou_score: 0.7141 - f1-score: 0.8165 - val_loss: 0.1801 - val_iou_score: 0.7156 - val_f1-score: 0.8183 - 113s/epoch - 724ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 111s - loss: 0.1766 - iou_score: 0.7214 - f1-score: 0.8222 - val_loss: 0.1828 - val_iou_score: 0.7166 - val_f1-score: 0.8174 - 111s/epoch - 713ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 111s - loss: 0.1744 - iou_score: 0.7246 - f1-score: 0.8249 - val_loss: 0.1796 - val_iou_score: 0.7171 - val_f1-score: 0.8199 - 111s/epoch - 709ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 111s - loss: 0.1773 - iou_score: 0.7195 - f1-score: 0.8215 - val_loss: 0.1813 - val_iou_score: 0.7167 - val_f1-score: 0.8194 - 111s/epoch - 714ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 111s - loss: 0.1714 - iou_score: 0.7275 - f1-score: 0.8270 - val_loss: 0.1818 - val_iou_score: 0.7147 - val_f1-score: 0.8175 - 111s/epoch - 713ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 112s - loss: 0.1681 - iou_score: 0.7331 - f1-score: 0.8317 - val_loss: 0.1741 - val_iou_score: 0.7263 - val_f1-score: 0.8267 - 112s/epoch - 719ms/step\n",
      "2023/09/26 03:39:50 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/26 03:40:24 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp99y29pjx/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/26 03:40:24 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 03:40:24 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/26 03:40:24 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 87\n",
      "Created version '87' of model 'fpn'.\n",
      "job end\n",
      "2023-09-26 03:40:57.310962: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 03:40:57.717528: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 03:40:57.717567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 03:40:57.717573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/26 03:40:59 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 03:40:59 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f0e25d99d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f0e25d99d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f0e25d99d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f0e25d99d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 141s - loss: 0.3297 - iou_score: 0.5465 - f1-score: 0.6689 - val_loss: 0.3201 - val_iou_score: 0.5553 - val_f1-score: 0.6784 - 141s/epoch - 905ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 111s - loss: 0.2577 - iou_score: 0.6229 - f1-score: 0.7424 - val_loss: 0.2665 - val_iou_score: 0.6192 - val_f1-score: 0.7319 - 111s/epoch - 709ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 112s - loss: 0.2395 - iou_score: 0.6432 - f1-score: 0.7602 - val_loss: 0.2278 - val_iou_score: 0.6608 - val_f1-score: 0.7726 - 112s/epoch - 716ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 111s - loss: 0.2288 - iou_score: 0.6557 - f1-score: 0.7704 - val_loss: 0.2074 - val_iou_score: 0.6809 - val_f1-score: 0.7890 - 111s/epoch - 712ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 110s - loss: 0.2193 - iou_score: 0.6669 - f1-score: 0.7800 - val_loss: 0.2081 - val_iou_score: 0.6802 - val_f1-score: 0.7907 - 110s/epoch - 708ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 112s - loss: 0.2141 - iou_score: 0.6732 - f1-score: 0.7843 - val_loss: 0.2043 - val_iou_score: 0.6884 - val_f1-score: 0.7953 - 112s/epoch - 719ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.2074 - iou_score: 0.6808 - f1-score: 0.7906 - val_loss: 0.1899 - val_iou_score: 0.7046 - val_f1-score: 0.8100 - 111s/epoch - 713ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 112s - loss: 0.2025 - iou_score: 0.6886 - f1-score: 0.7968 - val_loss: 0.1885 - val_iou_score: 0.7083 - val_f1-score: 0.8122 - 112s/epoch - 720ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 112s - loss: 0.1988 - iou_score: 0.6921 - f1-score: 0.7998 - val_loss: 0.1996 - val_iou_score: 0.6928 - val_f1-score: 0.7999 - 112s/epoch - 716ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 111s - loss: 0.1984 - iou_score: 0.6928 - f1-score: 0.8002 - val_loss: 0.1804 - val_iou_score: 0.7146 - val_f1-score: 0.8175 - 111s/epoch - 714ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 112s - loss: 0.1942 - iou_score: 0.6992 - f1-score: 0.8050 - val_loss: 0.1949 - val_iou_score: 0.7016 - val_f1-score: 0.8056 - 112s/epoch - 719ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 111s - loss: 0.1896 - iou_score: 0.7037 - f1-score: 0.8094 - val_loss: 0.1819 - val_iou_score: 0.7138 - val_f1-score: 0.8177 - 111s/epoch - 714ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 112s - loss: 0.1911 - iou_score: 0.7013 - f1-score: 0.8075 - val_loss: 0.1770 - val_iou_score: 0.7227 - val_f1-score: 0.8237 - 112s/epoch - 715ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 111s - loss: 0.1900 - iou_score: 0.7030 - f1-score: 0.8087 - val_loss: 0.1824 - val_iou_score: 0.7154 - val_f1-score: 0.8176 - 111s/epoch - 713ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 112s - loss: 0.1868 - iou_score: 0.7068 - f1-score: 0.8118 - val_loss: 0.1814 - val_iou_score: 0.7162 - val_f1-score: 0.8190 - 112s/epoch - 718ms/step\n",
      "2023/09/26 04:10:09 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/26 04:10:44 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp8cunmfo0/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/26 04:10:44 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 04:10:44 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/26 04:10:44 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 88\n",
      "Created version '88' of model 'fpn'.\n",
      "job end\n",
      "2023-09-26 04:11:17.420793: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 04:11:17.828285: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 04:11:17.828323: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 04:11:17.828329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/26 04:11:19 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 04:11:19 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5395a75d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5395a75d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5395a75d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5395a75d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 142s - loss: 0.3169 - iou_score: 0.5614 - f1-score: 0.6816 - val_loss: 0.2882 - val_iou_score: 0.5842 - val_f1-score: 0.7103 - 142s/epoch - 908ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 110s - loss: 0.2467 - iou_score: 0.6365 - f1-score: 0.7535 - val_loss: 0.2750 - val_iou_score: 0.6036 - val_f1-score: 0.7229 - 110s/epoch - 706ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 111s - loss: 0.2296 - iou_score: 0.6555 - f1-score: 0.7703 - val_loss: 0.2270 - val_iou_score: 0.6601 - val_f1-score: 0.7732 - 111s/epoch - 709ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 111s - loss: 0.2127 - iou_score: 0.6770 - f1-score: 0.7873 - val_loss: 0.2100 - val_iou_score: 0.6810 - val_f1-score: 0.7870 - 111s/epoch - 714ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 112s - loss: 0.2033 - iou_score: 0.6872 - f1-score: 0.7959 - val_loss: 0.2009 - val_iou_score: 0.6907 - val_f1-score: 0.7976 - 112s/epoch - 717ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 110s - loss: 0.2003 - iou_score: 0.6904 - f1-score: 0.7979 - val_loss: 0.2007 - val_iou_score: 0.6929 - val_f1-score: 0.7990 - 110s/epoch - 706ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 110s - loss: 0.1936 - iou_score: 0.6986 - f1-score: 0.8046 - val_loss: 0.1987 - val_iou_score: 0.6935 - val_f1-score: 0.8010 - 110s/epoch - 706ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 111s - loss: 0.1906 - iou_score: 0.7038 - f1-score: 0.8088 - val_loss: 0.1847 - val_iou_score: 0.7136 - val_f1-score: 0.8161 - 111s/epoch - 714ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 111s - loss: 0.1824 - iou_score: 0.7146 - f1-score: 0.8170 - val_loss: 0.1852 - val_iou_score: 0.7121 - val_f1-score: 0.8148 - 111s/epoch - 711ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 112s - loss: 0.1836 - iou_score: 0.7112 - f1-score: 0.8147 - val_loss: 0.1838 - val_iou_score: 0.7106 - val_f1-score: 0.8143 - 112s/epoch - 715ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 111s - loss: 0.1804 - iou_score: 0.7165 - f1-score: 0.8187 - val_loss: 0.1840 - val_iou_score: 0.7133 - val_f1-score: 0.8162 - 111s/epoch - 713ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 112s - loss: 0.1768 - iou_score: 0.7209 - f1-score: 0.8223 - val_loss: 0.1803 - val_iou_score: 0.7165 - val_f1-score: 0.8194 - 112s/epoch - 717ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 110s - loss: 0.1750 - iou_score: 0.7226 - f1-score: 0.8235 - val_loss: 0.1789 - val_iou_score: 0.7220 - val_f1-score: 0.8218 - 110s/epoch - 708ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 113s - loss: 0.1744 - iou_score: 0.7238 - f1-score: 0.8245 - val_loss: 0.1803 - val_iou_score: 0.7169 - val_f1-score: 0.8196 - 113s/epoch - 727ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 112s - loss: 0.1716 - iou_score: 0.7285 - f1-score: 0.8285 - val_loss: 0.1799 - val_iou_score: 0.7183 - val_f1-score: 0.8203 - 112s/epoch - 717ms/step\n",
      "2023/09/26 04:40:26 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/26 04:40:59 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpw7tl4t2c/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/26 04:40:59 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 04:40:59 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/26 04:40:59 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 89\n",
      "Created version '89' of model 'fpn'.\n",
      "job end\n",
      "2023-09-26 04:41:32.416519: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 04:41:32.815595: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 04:41:32.815635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-26 04:41:32.815640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/26 04:41:34 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 04:41:34 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7facbaa79d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7facbaa79d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7facbaa79d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7facbaa79d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 143s - loss: 0.3284 - iou_score: 0.5478 - f1-score: 0.6694 - val_loss: 0.3034 - val_iou_score: 0.5673 - val_f1-score: 0.6954 - 143s/epoch - 914ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 111s - loss: 0.2607 - iou_score: 0.6201 - f1-score: 0.7397 - val_loss: 0.2817 - val_iou_score: 0.6070 - val_f1-score: 0.7165 - 111s/epoch - 714ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 111s - loss: 0.2400 - iou_score: 0.6437 - f1-score: 0.7598 - val_loss: 0.2267 - val_iou_score: 0.6647 - val_f1-score: 0.7736 - 111s/epoch - 714ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 111s - loss: 0.2265 - iou_score: 0.6596 - f1-score: 0.7735 - val_loss: 0.2139 - val_iou_score: 0.6747 - val_f1-score: 0.7829 - 111s/epoch - 709ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 111s - loss: 0.2179 - iou_score: 0.6690 - f1-score: 0.7815 - val_loss: 0.2060 - val_iou_score: 0.6817 - val_f1-score: 0.7926 - 111s/epoch - 714ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 112s - loss: 0.2146 - iou_score: 0.6724 - f1-score: 0.7837 - val_loss: 0.1959 - val_iou_score: 0.6979 - val_f1-score: 0.8040 - 112s/epoch - 717ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 112s - loss: 0.2079 - iou_score: 0.6822 - f1-score: 0.7913 - val_loss: 0.1921 - val_iou_score: 0.7027 - val_f1-score: 0.8078 - 112s/epoch - 717ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 111s - loss: 0.2048 - iou_score: 0.6852 - f1-score: 0.7947 - val_loss: 0.1917 - val_iou_score: 0.7050 - val_f1-score: 0.8093 - 111s/epoch - 713ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 112s - loss: 0.1977 - iou_score: 0.6943 - f1-score: 0.8018 - val_loss: 0.1896 - val_iou_score: 0.7066 - val_f1-score: 0.8101 - 112s/epoch - 718ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 112s - loss: 0.2009 - iou_score: 0.6895 - f1-score: 0.7978 - val_loss: 0.1841 - val_iou_score: 0.7107 - val_f1-score: 0.8142 - 112s/epoch - 717ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 113s - loss: 0.1935 - iou_score: 0.6985 - f1-score: 0.8053 - val_loss: 0.1882 - val_iou_score: 0.7076 - val_f1-score: 0.8119 - 113s/epoch - 722ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 112s - loss: 0.1938 - iou_score: 0.6989 - f1-score: 0.8056 - val_loss: 0.1789 - val_iou_score: 0.7191 - val_f1-score: 0.8207 - 112s/epoch - 720ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 114s - loss: 0.1887 - iou_score: 0.7049 - f1-score: 0.8103 - val_loss: 0.1869 - val_iou_score: 0.7095 - val_f1-score: 0.8140 - 114s/epoch - 728ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 112s - loss: 0.1872 - iou_score: 0.7068 - f1-score: 0.8111 - val_loss: 0.1850 - val_iou_score: 0.7120 - val_f1-score: 0.8147 - 112s/epoch - 718ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 113s - loss: 0.1849 - iou_score: 0.7099 - f1-score: 0.8143 - val_loss: 0.1802 - val_iou_score: 0.7188 - val_f1-score: 0.8205 - 113s/epoch - 723ms/step\n",
      "2023/09/26 05:10:50 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/26 05:11:24 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpl1d2lor4/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/26 05:11:25 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/26 05:11:25 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/26 05:11:25 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 90\n",
      "Created version '90' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!bash src/modeling/pretrained-models_aug.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling + best aug combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-27 10:24:24.871599: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-27 10:24:25.313652: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-27 10:24:25.313689: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-27 10:24:25.313695: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/27 10:24:27 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/27 10:24:27 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ab6429cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ab6429cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ab6429cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ab6429cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 141s - loss: 0.3063 - iou_score: 0.5736 - f1-score: 0.6926 - val_loss: 0.3307 - val_iou_score: 0.5352 - val_f1-score: 0.6683 - 141s/epoch - 904ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 110s - loss: 0.2338 - iou_score: 0.6510 - f1-score: 0.7662 - val_loss: 0.2786 - val_iou_score: 0.6113 - val_f1-score: 0.7201 - 110s/epoch - 704ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 110s - loss: 0.2107 - iou_score: 0.6786 - f1-score: 0.7887 - val_loss: 0.2395 - val_iou_score: 0.6460 - val_f1-score: 0.7608 - 110s/epoch - 704ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 110s - loss: 0.2009 - iou_score: 0.6918 - f1-score: 0.7988 - val_loss: 0.2119 - val_iou_score: 0.6784 - val_f1-score: 0.7850 - 110s/epoch - 707ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 110s - loss: 0.1886 - iou_score: 0.7058 - f1-score: 0.8103 - val_loss: 0.1960 - val_iou_score: 0.6942 - val_f1-score: 0.8023 - 110s/epoch - 705ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 110s - loss: 0.1833 - iou_score: 0.7122 - f1-score: 0.8149 - val_loss: 0.1902 - val_iou_score: 0.7050 - val_f1-score: 0.8097 - 110s/epoch - 702ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.1857 - iou_score: 0.7104 - f1-score: 0.8135 - val_loss: 0.1856 - val_iou_score: 0.7105 - val_f1-score: 0.8141 - 111s/epoch - 712ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 110s - loss: 0.1784 - iou_score: 0.7191 - f1-score: 0.8205 - val_loss: 0.1846 - val_iou_score: 0.7118 - val_f1-score: 0.8163 - 110s/epoch - 708ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 109s - loss: 0.1739 - iou_score: 0.7253 - f1-score: 0.8257 - val_loss: 0.1792 - val_iou_score: 0.7190 - val_f1-score: 0.8209 - 109s/epoch - 697ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 109s - loss: 0.1718 - iou_score: 0.7270 - f1-score: 0.8267 - val_loss: 0.1780 - val_iou_score: 0.7160 - val_f1-score: 0.8199 - 109s/epoch - 701ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 111s - loss: 0.1718 - iou_score: 0.7269 - f1-score: 0.8263 - val_loss: 0.1751 - val_iou_score: 0.7242 - val_f1-score: 0.8249 - 111s/epoch - 710ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 110s - loss: 0.1676 - iou_score: 0.7327 - f1-score: 0.8316 - val_loss: 0.1710 - val_iou_score: 0.7289 - val_f1-score: 0.8290 - 110s/epoch - 707ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 111s - loss: 0.1636 - iou_score: 0.7373 - f1-score: 0.8347 - val_loss: 0.1693 - val_iou_score: 0.7325 - val_f1-score: 0.8313 - 111s/epoch - 712ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 109s - loss: 0.1642 - iou_score: 0.7375 - f1-score: 0.8347 - val_loss: 0.1764 - val_iou_score: 0.7211 - val_f1-score: 0.8230 - 109s/epoch - 701ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 111s - loss: 0.1634 - iou_score: 0.7379 - f1-score: 0.8353 - val_loss: 0.1670 - val_iou_score: 0.7356 - val_f1-score: 0.8337 - 111s/epoch - 712ms/step\n",
      "2023/09/27 10:52:45 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/27 10:53:19 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmprgtaa5tb/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/27 10:53:19 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/27 10:53:19 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/27 10:53:19 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 95\n",
      "Created version '95' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py generator.auglist.geo=rdcrop \\\n",
    "                    generator.auglist.ker=gnoise \\\n",
    "                    generator.auglist.clim=0.2 \\\n",
    "                    generator.auglist.blim=0.2 \\\n",
    "                    generator.oversampling=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-27 14:54:27.130400: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-27 14:54:27.556583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-27 14:54:27.556619: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-27 14:54:27.556625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/27 14:54:29 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/27 14:54:29 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fd4b7962170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fd4b7962170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fd4b7962170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fd4b7962170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 151s - loss: 0.3026 - iou_score: 0.5771 - f1-score: 0.6959 - val_loss: 0.3287 - val_iou_score: 0.5451 - val_f1-score: 0.6705 - 151s/epoch - 968ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 119s - loss: 0.2324 - iou_score: 0.6533 - f1-score: 0.7679 - val_loss: 0.2945 - val_iou_score: 0.5913 - val_f1-score: 0.7046 - 119s/epoch - 765ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 120s - loss: 0.2127 - iou_score: 0.6764 - f1-score: 0.7869 - val_loss: 0.2334 - val_iou_score: 0.6557 - val_f1-score: 0.7670 - 120s/epoch - 767ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 120s - loss: 0.2006 - iou_score: 0.6923 - f1-score: 0.7990 - val_loss: 0.2048 - val_iou_score: 0.6859 - val_f1-score: 0.7921 - 120s/epoch - 772ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 120s - loss: 0.1881 - iou_score: 0.7065 - f1-score: 0.8106 - val_loss: 0.1978 - val_iou_score: 0.6946 - val_f1-score: 0.8009 - 120s/epoch - 769ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 110s - loss: 0.1829 - iou_score: 0.7123 - f1-score: 0.8147 - val_loss: 0.1854 - val_iou_score: 0.7099 - val_f1-score: 0.8140 - 110s/epoch - 702ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 112s - loss: 0.1809 - iou_score: 0.7154 - f1-score: 0.8179 - val_loss: 0.1829 - val_iou_score: 0.7149 - val_f1-score: 0.8169 - 112s/epoch - 717ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 112s - loss: 0.1754 - iou_score: 0.7242 - f1-score: 0.8246 - val_loss: 0.1865 - val_iou_score: 0.7119 - val_f1-score: 0.8143 - 112s/epoch - 718ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 111s - loss: 0.1726 - iou_score: 0.7265 - f1-score: 0.8262 - val_loss: 0.1808 - val_iou_score: 0.7177 - val_f1-score: 0.8194 - 111s/epoch - 712ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 112s - loss: 0.1690 - iou_score: 0.7299 - f1-score: 0.8281 - val_loss: 0.1765 - val_iou_score: 0.7198 - val_f1-score: 0.8216 - 112s/epoch - 720ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 111s - loss: 0.1695 - iou_score: 0.7297 - f1-score: 0.8288 - val_loss: 0.1752 - val_iou_score: 0.7242 - val_f1-score: 0.8249 - 111s/epoch - 710ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 111s - loss: 0.1660 - iou_score: 0.7348 - f1-score: 0.8328 - val_loss: 0.1715 - val_iou_score: 0.7276 - val_f1-score: 0.8281 - 111s/epoch - 714ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 111s - loss: 0.1626 - iou_score: 0.7392 - f1-score: 0.8365 - val_loss: 0.1697 - val_iou_score: 0.7316 - val_f1-score: 0.8309 - 111s/epoch - 711ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 112s - loss: 0.1637 - iou_score: 0.7376 - f1-score: 0.8347 - val_loss: 0.1709 - val_iou_score: 0.7292 - val_f1-score: 0.8289 - 112s/epoch - 719ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 110s - loss: 0.1658 - iou_score: 0.7346 - f1-score: 0.8331 - val_loss: 0.1713 - val_iou_score: 0.7298 - val_f1-score: 0.8295 - 110s/epoch - 706ms/step\n",
      "2023/09/27 15:23:49 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/27 15:24:22 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpc8z2vznc/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/27 15:24:23 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/27 15:24:23 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/27 15:24:23 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 106\n",
      "Created version '106' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py generator.auglist.geo=rdcrop \\\n",
    "                    generator.auglist.ker=gnoise \\\n",
    "                    generator.auglist.clim=0.08 \\\n",
    "                    generator.auglist.blim=0.2 \\\n",
    "                    generator.oversampling=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-27 18:34:47.986766: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-27 18:34:48.426047: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-27 18:34:48.426088: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-27 18:34:48.426094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "\u001b[32m[I 2023-09-27 18:34:50,270]\u001b[0m A new study created in memory with name: no-name-21636968-51ac-40ca-96be-0314f2249f56\u001b[0m\n",
      "[2023-09-27 18:34:50,270][HYDRA] Study name: no-name-21636968-51ac-40ca-96be-0314f2249f56\n",
      "[2023-09-27 18:34:50,270][HYDRA] Storage: None\n",
      "[2023-09-27 18:34:50,270][HYDRA] Sampler: TPESampler\n",
      "[2023-09-27 18:34:50,270][HYDRA] Directions: ['maximize', 'maximize']\n",
      "[2023-09-27 18:34:50,272][HYDRA] Launching 1 jobs locally\n",
      "[2023-09-27 18:34:50,272][HYDRA] \t#0 : generator.auglist.ker=mblur\n",
      "2023/09/27 18:34:50 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/27 18:34:50 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f3d0504a320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f3d0504a320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f3d0504a320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f3d0504a320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 - 37s - loss: 0.9018 - iou_score: 0.0528 - f1-score: 0.0982 - val_loss: 0.9628 - val_iou_score: 0.0214 - val_f1-score: 0.0372 - 37s/epoch - 37s/step\n",
      "aug_list\n",
      "cfg\n",
      "current_graph\n",
      "early_stopping\n",
      "graph_def\n",
      "loss\n",
      "mosaic\n",
      "oversampling\n",
      "params\n",
      "run\n",
      "scores\n",
      "start\n",
      "time_spent\n",
      "x_train\n",
      "x_valid\n",
      "y_train\n",
      "y_valid\n",
      "job end\n",
      "[2023-09-27 18:35:36,019][HYDRA] Launching 1 jobs locally\n",
      "[2023-09-27 18:35:36,020][HYDRA] \t#1 : generator.auglist.ker=gnoise\n",
      "1/1 - 35s - loss: 0.9010 - iou_score: 0.0533 - f1-score: 0.0990 - val_loss: 0.9636 - val_iou_score: 0.0210 - val_f1-score: 0.0364 - 35s/epoch - 35s/step\n",
      "aug_list\n",
      "cfg\n",
      "current_graph\n",
      "early_stopping\n",
      "graph_def\n",
      "loss\n",
      "mosaic\n",
      "oversampling\n",
      "params\n",
      "run\n",
      "scores\n",
      "start\n",
      "time_spent\n",
      "x_train\n",
      "x_valid\n",
      "y_train\n",
      "y_valid\n",
      "job end\n",
      "[2023-09-27 18:36:19,440][HYDRA] Number of Pareto solutions: 1\n",
      "[2023-09-27 18:36:19,442][HYDRA]     Values: [0.02144545316696167, 0.037236619740724564], Params: {'generator.auglist.ker': 'mblur'}\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-27 23:56:46.961880: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-27 23:56:47.394846: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-27 23:56:47.394884: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-27 23:56:47.394890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/27 23:56:49 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/27 23:56:49 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f34f7d9b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f34f7d9b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f34f7d9b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f34f7d9b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 141s - loss: 0.3258 - iou_score: 0.5461 - f1-score: 0.6728 - val_loss: 0.3056 - val_iou_score: 0.5638 - val_f1-score: 0.6924 - 141s/epoch - 903ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 107s - loss: 0.2536 - iou_score: 0.6232 - f1-score: 0.7453 - val_loss: 0.2645 - val_iou_score: 0.6224 - val_f1-score: 0.7335 - 107s/epoch - 689ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 108s - loss: 0.2309 - iou_score: 0.6510 - f1-score: 0.7685 - val_loss: 0.2379 - val_iou_score: 0.6492 - val_f1-score: 0.7621 - 108s/epoch - 690ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 107s - loss: 0.2243 - iou_score: 0.6584 - f1-score: 0.7747 - val_loss: 0.2260 - val_iou_score: 0.6587 - val_f1-score: 0.7713 - 107s/epoch - 688ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 108s - loss: 0.2101 - iou_score: 0.6760 - f1-score: 0.7887 - val_loss: 0.2221 - val_iou_score: 0.6691 - val_f1-score: 0.7761 - 108s/epoch - 695ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 107s - loss: 0.2027 - iou_score: 0.6845 - f1-score: 0.7950 - val_loss: 0.2180 - val_iou_score: 0.6684 - val_f1-score: 0.7814 - 107s/epoch - 686ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 104s - loss: 0.1987 - iou_score: 0.6902 - f1-score: 0.8001 - val_loss: 0.2113 - val_iou_score: 0.6824 - val_f1-score: 0.7888 - 104s/epoch - 666ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 105s - loss: 0.1919 - iou_score: 0.6987 - f1-score: 0.8073 - val_loss: 0.1998 - val_iou_score: 0.6962 - val_f1-score: 0.8003 - 105s/epoch - 671ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 105s - loss: 0.1885 - iou_score: 0.7029 - f1-score: 0.8104 - val_loss: 0.1911 - val_iou_score: 0.7064 - val_f1-score: 0.8085 - 105s/epoch - 671ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 105s - loss: 0.1858 - iou_score: 0.7055 - f1-score: 0.8119 - val_loss: 0.2073 - val_iou_score: 0.6826 - val_f1-score: 0.7911 - 105s/epoch - 673ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 104s - loss: 0.1896 - iou_score: 0.7022 - f1-score: 0.8091 - val_loss: 0.1967 - val_iou_score: 0.6986 - val_f1-score: 0.8032 - 104s/epoch - 667ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 105s - loss: 0.1838 - iou_score: 0.7089 - f1-score: 0.8154 - val_loss: 0.1890 - val_iou_score: 0.7065 - val_f1-score: 0.8109 - 105s/epoch - 672ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 106s - loss: 0.1796 - iou_score: 0.7147 - f1-score: 0.8194 - val_loss: 0.1831 - val_iou_score: 0.7156 - val_f1-score: 0.8175 - 106s/epoch - 681ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 105s - loss: 0.1876 - iou_score: 0.7052 - f1-score: 0.8115 - val_loss: 0.1887 - val_iou_score: 0.7081 - val_f1-score: 0.8113 - 105s/epoch - 672ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 104s - loss: 0.1801 - iou_score: 0.7133 - f1-score: 0.8183 - val_loss: 0.1801 - val_iou_score: 0.7190 - val_f1-score: 0.8204 - 104s/epoch - 666ms/step\n",
      "2023/09/28 00:24:06 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 00:24:39 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpnrj01e8b/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 00:24:39 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 00:24:39 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 00:24:39 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 124\n",
      "Created version '124' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 00:25:12.899858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 00:25:13.299173: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 00:25:13.299211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 00:25:13.299217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 00:25:14 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 00:25:14 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fa3b05ef520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fa3b05ef520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fa3b05ef520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fa3b05ef520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 133s - loss: 0.3345 - iou_score: 0.5334 - f1-score: 0.6646 - val_loss: 0.3242 - val_iou_score: 0.5489 - val_f1-score: 0.6743 - 133s/epoch - 850ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 103s - loss: 0.2612 - iou_score: 0.6125 - f1-score: 0.7388 - val_loss: 0.3005 - val_iou_score: 0.5907 - val_f1-score: 0.6989 - 103s/epoch - 662ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 103s - loss: 0.2374 - iou_score: 0.6410 - f1-score: 0.7626 - val_loss: 0.2498 - val_iou_score: 0.6391 - val_f1-score: 0.7506 - 103s/epoch - 661ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 104s - loss: 0.2228 - iou_score: 0.6576 - f1-score: 0.7764 - val_loss: 0.2273 - val_iou_score: 0.6599 - val_f1-score: 0.7691 - 104s/epoch - 668ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 104s - loss: 0.2134 - iou_score: 0.6689 - f1-score: 0.7858 - val_loss: 0.2184 - val_iou_score: 0.6729 - val_f1-score: 0.7798 - 104s/epoch - 664ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 104s - loss: 0.2078 - iou_score: 0.6761 - f1-score: 0.7905 - val_loss: 0.2140 - val_iou_score: 0.6759 - val_f1-score: 0.7849 - 104s/epoch - 665ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 103s - loss: 0.2040 - iou_score: 0.6816 - f1-score: 0.7952 - val_loss: 0.2073 - val_iou_score: 0.6849 - val_f1-score: 0.7929 - 103s/epoch - 662ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 103s - loss: 0.1978 - iou_score: 0.6897 - f1-score: 0.8016 - val_loss: 0.2080 - val_iou_score: 0.6867 - val_f1-score: 0.7927 - 103s/epoch - 663ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 103s - loss: 0.1972 - iou_score: 0.6899 - f1-score: 0.8014 - val_loss: 0.2082 - val_iou_score: 0.6864 - val_f1-score: 0.7912 - 103s/epoch - 659ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 104s - loss: 0.1925 - iou_score: 0.6955 - f1-score: 0.8057 - val_loss: 0.1965 - val_iou_score: 0.6965 - val_f1-score: 0.8019 - 104s/epoch - 669ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 105s - loss: 0.1883 - iou_score: 0.7006 - f1-score: 0.8097 - val_loss: 0.2021 - val_iou_score: 0.6931 - val_f1-score: 0.7979 - 105s/epoch - 672ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 104s - loss: 0.1862 - iou_score: 0.7041 - f1-score: 0.8127 - val_loss: 0.1912 - val_iou_score: 0.7061 - val_f1-score: 0.8081 - 104s/epoch - 669ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 105s - loss: 0.1827 - iou_score: 0.7082 - f1-score: 0.8163 - val_loss: 0.1925 - val_iou_score: 0.7060 - val_f1-score: 0.8084 - 105s/epoch - 670ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 104s - loss: 0.1831 - iou_score: 0.7085 - f1-score: 0.8161 - val_loss: 0.2153 - val_iou_score: 0.6812 - val_f1-score: 0.7839 - 104s/epoch - 666ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 105s - loss: 0.1803 - iou_score: 0.7117 - f1-score: 0.8193 - val_loss: 0.1974 - val_iou_score: 0.7010 - val_f1-score: 0.8032 - 105s/epoch - 673ms/step\n",
      "2023/09/28 00:51:57 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 00:52:31 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpcr53vrdn/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 00:52:31 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 00:52:31 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 00:52:31 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 125\n",
      "Created version '125' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 00:53:04.448419: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 00:53:04.846639: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 00:53:04.846676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 00:53:04.846681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 00:53:06 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 00:53:06 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f403e9af520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f403e9af520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f403e9af520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f403e9af520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 137s - loss: 0.3239 - iou_score: 0.5483 - f1-score: 0.6747 - val_loss: 0.3226 - val_iou_score: 0.5460 - val_f1-score: 0.6765 - 137s/epoch - 877ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 105s - loss: 0.2568 - iou_score: 0.6205 - f1-score: 0.7431 - val_loss: 0.2934 - val_iou_score: 0.5994 - val_f1-score: 0.7056 - 105s/epoch - 670ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 105s - loss: 0.2303 - iou_score: 0.6518 - f1-score: 0.7690 - val_loss: 0.2436 - val_iou_score: 0.6394 - val_f1-score: 0.7565 - 105s/epoch - 674ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 105s - loss: 0.2187 - iou_score: 0.6670 - f1-score: 0.7811 - val_loss: 0.2118 - val_iou_score: 0.6765 - val_f1-score: 0.7850 - 105s/epoch - 672ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 105s - loss: 0.2064 - iou_score: 0.6801 - f1-score: 0.7928 - val_loss: 0.2266 - val_iou_score: 0.6691 - val_f1-score: 0.7720 - 105s/epoch - 673ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 105s - loss: 0.2007 - iou_score: 0.6867 - f1-score: 0.7971 - val_loss: 0.2026 - val_iou_score: 0.6893 - val_f1-score: 0.7968 - 105s/epoch - 672ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 105s - loss: 0.2001 - iou_score: 0.6890 - f1-score: 0.7986 - val_loss: 0.2012 - val_iou_score: 0.6944 - val_f1-score: 0.7984 - 105s/epoch - 675ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 105s - loss: 0.1930 - iou_score: 0.6986 - f1-score: 0.8066 - val_loss: 0.1927 - val_iou_score: 0.7056 - val_f1-score: 0.8079 - 105s/epoch - 675ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 106s - loss: 0.1898 - iou_score: 0.7015 - f1-score: 0.8091 - val_loss: 0.1970 - val_iou_score: 0.6971 - val_f1-score: 0.8026 - 106s/epoch - 677ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 105s - loss: 0.1879 - iou_score: 0.7036 - f1-score: 0.8103 - val_loss: 0.2003 - val_iou_score: 0.6943 - val_f1-score: 0.7986 - 105s/epoch - 675ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 105s - loss: 0.1831 - iou_score: 0.7093 - f1-score: 0.8151 - val_loss: 0.1876 - val_iou_score: 0.7103 - val_f1-score: 0.8126 - 105s/epoch - 671ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 106s - loss: 0.1788 - iou_score: 0.7161 - f1-score: 0.8206 - val_loss: 0.1811 - val_iou_score: 0.7174 - val_f1-score: 0.8188 - 106s/epoch - 679ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 106s - loss: 0.1775 - iou_score: 0.7162 - f1-score: 0.8204 - val_loss: 0.1909 - val_iou_score: 0.7042 - val_f1-score: 0.8100 - 106s/epoch - 677ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 107s - loss: 0.1771 - iou_score: 0.7172 - f1-score: 0.8210 - val_loss: 0.1881 - val_iou_score: 0.7071 - val_f1-score: 0.8114 - 107s/epoch - 684ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 105s - loss: 0.1778 - iou_score: 0.7159 - f1-score: 0.8208 - val_loss: 0.1811 - val_iou_score: 0.7186 - val_f1-score: 0.8194 - 105s/epoch - 672ms/step\n",
      "2023/09/28 01:20:13 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 01:20:45 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpk6og8642/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 01:20:45 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 01:20:45 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 01:20:45 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 126\n",
      "Created version '126' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 01:21:18.569979: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 01:21:18.960511: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 01:21:18.960549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 01:21:18.960555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 01:21:20 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 01:21:20 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fe2085bb520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fe2085bb520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fe2085bb520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fe2085bb520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 135s - loss: 0.3366 - iou_score: 0.5312 - f1-score: 0.6624 - val_loss: 0.3467 - val_iou_score: 0.5299 - val_f1-score: 0.6520 - 135s/epoch - 863ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 103s - loss: 0.2640 - iou_score: 0.6098 - f1-score: 0.7363 - val_loss: 0.3142 - val_iou_score: 0.5789 - val_f1-score: 0.6854 - 103s/epoch - 663ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 104s - loss: 0.2397 - iou_score: 0.6370 - f1-score: 0.7596 - val_loss: 0.2891 - val_iou_score: 0.5881 - val_f1-score: 0.7121 - 104s/epoch - 665ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 103s - loss: 0.2311 - iou_score: 0.6479 - f1-score: 0.7683 - val_loss: 0.2221 - val_iou_score: 0.6655 - val_f1-score: 0.7748 - 103s/epoch - 658ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 104s - loss: 0.2169 - iou_score: 0.6645 - f1-score: 0.7822 - val_loss: 0.2182 - val_iou_score: 0.6727 - val_f1-score: 0.7802 - 104s/epoch - 668ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 104s - loss: 0.2091 - iou_score: 0.6735 - f1-score: 0.7886 - val_loss: 0.2075 - val_iou_score: 0.6845 - val_f1-score: 0.7921 - 104s/epoch - 669ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 104s - loss: 0.2025 - iou_score: 0.6832 - f1-score: 0.7963 - val_loss: 0.2057 - val_iou_score: 0.6870 - val_f1-score: 0.7942 - 104s/epoch - 667ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 104s - loss: 0.1981 - iou_score: 0.6885 - f1-score: 0.8007 - val_loss: 0.1995 - val_iou_score: 0.6980 - val_f1-score: 0.8010 - 104s/epoch - 666ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 105s - loss: 0.1928 - iou_score: 0.6963 - f1-score: 0.8072 - val_loss: 0.2005 - val_iou_score: 0.6956 - val_f1-score: 0.7991 - 105s/epoch - 670ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 104s - loss: 0.1941 - iou_score: 0.6923 - f1-score: 0.8031 - val_loss: 0.1947 - val_iou_score: 0.6980 - val_f1-score: 0.8036 - 104s/epoch - 667ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 104s - loss: 0.1872 - iou_score: 0.7018 - f1-score: 0.8112 - val_loss: 0.1948 - val_iou_score: 0.7014 - val_f1-score: 0.8044 - 104s/epoch - 668ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 103s - loss: 0.1892 - iou_score: 0.6994 - f1-score: 0.8093 - val_loss: 0.1939 - val_iou_score: 0.7020 - val_f1-score: 0.8057 - 103s/epoch - 663ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 103s - loss: 0.1843 - iou_score: 0.7063 - f1-score: 0.8147 - val_loss: 0.1914 - val_iou_score: 0.7061 - val_f1-score: 0.8094 - 103s/epoch - 662ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 105s - loss: 0.1830 - iou_score: 0.7074 - f1-score: 0.8150 - val_loss: 0.1961 - val_iou_score: 0.7002 - val_f1-score: 0.8031 - 105s/epoch - 671ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 104s - loss: 0.1851 - iou_score: 0.7040 - f1-score: 0.8124 - val_loss: 0.1953 - val_iou_score: 0.7040 - val_f1-score: 0.8054 - 104s/epoch - 667ms/step\n",
      "2023/09/28 01:48:43 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 01:49:16 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpo_8vp241/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 01:49:16 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 01:49:16 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 01:49:16 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 127\n",
      "Created version '127' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 01:49:49.660720: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 01:49:50.052290: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 01:49:50.052328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 01:49:50.052333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 01:49:51 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 01:49:51 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f50de5c7520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f50de5c7520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f50de5c7520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f50de5c7520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 135s - loss: 0.3286 - iou_score: 0.5436 - f1-score: 0.6702 - val_loss: 0.3273 - val_iou_score: 0.5472 - val_f1-score: 0.6715 - 135s/epoch - 866ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 104s - loss: 0.2571 - iou_score: 0.6202 - f1-score: 0.7430 - val_loss: 0.2835 - val_iou_score: 0.6043 - val_f1-score: 0.7152 - 104s/epoch - 665ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 104s - loss: 0.2337 - iou_score: 0.6472 - f1-score: 0.7657 - val_loss: 0.2434 - val_iou_score: 0.6417 - val_f1-score: 0.7569 - 104s/epoch - 665ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 104s - loss: 0.2227 - iou_score: 0.6602 - f1-score: 0.7761 - val_loss: 0.2134 - val_iou_score: 0.6752 - val_f1-score: 0.7837 - 104s/epoch - 666ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 104s - loss: 0.2106 - iou_score: 0.6748 - f1-score: 0.7881 - val_loss: 0.2145 - val_iou_score: 0.6757 - val_f1-score: 0.7834 - 104s/epoch - 669ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 105s - loss: 0.2063 - iou_score: 0.6810 - f1-score: 0.7924 - val_loss: 0.2096 - val_iou_score: 0.6801 - val_f1-score: 0.7895 - 105s/epoch - 670ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 103s - loss: 0.1982 - iou_score: 0.6898 - f1-score: 0.8003 - val_loss: 0.1967 - val_iou_score: 0.6997 - val_f1-score: 0.8029 - 103s/epoch - 661ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 106s - loss: 0.1941 - iou_score: 0.6967 - f1-score: 0.8055 - val_loss: 0.1934 - val_iou_score: 0.7038 - val_f1-score: 0.8069 - 106s/epoch - 677ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 104s - loss: 0.1900 - iou_score: 0.7019 - f1-score: 0.8097 - val_loss: 0.1910 - val_iou_score: 0.7059 - val_f1-score: 0.8085 - 104s/epoch - 669ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 104s - loss: 0.1903 - iou_score: 0.6999 - f1-score: 0.8076 - val_loss: 0.1936 - val_iou_score: 0.7008 - val_f1-score: 0.8048 - 104s/epoch - 667ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 105s - loss: 0.1842 - iou_score: 0.7086 - f1-score: 0.8143 - val_loss: 0.1860 - val_iou_score: 0.7130 - val_f1-score: 0.8137 - 105s/epoch - 674ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 105s - loss: 0.1785 - iou_score: 0.7159 - f1-score: 0.8204 - val_loss: 0.1808 - val_iou_score: 0.7183 - val_f1-score: 0.8191 - 105s/epoch - 672ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 105s - loss: 0.1782 - iou_score: 0.7164 - f1-score: 0.8209 - val_loss: 0.1872 - val_iou_score: 0.7095 - val_f1-score: 0.8135 - 105s/epoch - 673ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 105s - loss: 0.1819 - iou_score: 0.7121 - f1-score: 0.8171 - val_loss: 0.1868 - val_iou_score: 0.7114 - val_f1-score: 0.8135 - 105s/epoch - 675ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 105s - loss: 0.1775 - iou_score: 0.7153 - f1-score: 0.8198 - val_loss: 0.1825 - val_iou_score: 0.7163 - val_f1-score: 0.8182 - 105s/epoch - 675ms/step\n",
      "2023/09/28 02:16:44 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 02:17:18 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpr0lp28_x/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 02:17:18 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 02:17:18 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 02:17:18 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 128\n",
      "Created version '128' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 02:17:51.474643: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 02:17:51.873667: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 02:17:51.873703: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 02:17:51.873709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 02:17:53 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 02:17:53 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fa04a9af520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fa04a9af520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fa04a9af520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fa04a9af520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 134s - loss: 0.3359 - iou_score: 0.5308 - f1-score: 0.6627 - val_loss: 0.3678 - val_iou_score: 0.5103 - val_f1-score: 0.6310 - 134s/epoch - 859ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 104s - loss: 0.2657 - iou_score: 0.6066 - f1-score: 0.7336 - val_loss: 0.2948 - val_iou_score: 0.5898 - val_f1-score: 0.7042 - 104s/epoch - 667ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 103s - loss: 0.2416 - iou_score: 0.6352 - f1-score: 0.7578 - val_loss: 0.2531 - val_iou_score: 0.6397 - val_f1-score: 0.7473 - 103s/epoch - 661ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 105s - loss: 0.2260 - iou_score: 0.6544 - f1-score: 0.7738 - val_loss: 0.2336 - val_iou_score: 0.6514 - val_f1-score: 0.7633 - 105s/epoch - 671ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 104s - loss: 0.2165 - iou_score: 0.6655 - f1-score: 0.7827 - val_loss: 0.2097 - val_iou_score: 0.6809 - val_f1-score: 0.7886 - 104s/epoch - 665ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 104s - loss: 0.2097 - iou_score: 0.6730 - f1-score: 0.7879 - val_loss: 0.2117 - val_iou_score: 0.6821 - val_f1-score: 0.7877 - 104s/epoch - 666ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 103s - loss: 0.2040 - iou_score: 0.6818 - f1-score: 0.7957 - val_loss: 0.2064 - val_iou_score: 0.6855 - val_f1-score: 0.7935 - 103s/epoch - 661ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 104s - loss: 0.2008 - iou_score: 0.6858 - f1-score: 0.7988 - val_loss: 0.2057 - val_iou_score: 0.6916 - val_f1-score: 0.7947 - 104s/epoch - 665ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 105s - loss: 0.1945 - iou_score: 0.6931 - f1-score: 0.8053 - val_loss: 0.1997 - val_iou_score: 0.6963 - val_f1-score: 0.7997 - 105s/epoch - 671ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 105s - loss: 0.1965 - iou_score: 0.6898 - f1-score: 0.8013 - val_loss: 0.1962 - val_iou_score: 0.6964 - val_f1-score: 0.8022 - 105s/epoch - 671ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 105s - loss: 0.1881 - iou_score: 0.7013 - f1-score: 0.8104 - val_loss: 0.1952 - val_iou_score: 0.7023 - val_f1-score: 0.8048 - 105s/epoch - 673ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 105s - loss: 0.1871 - iou_score: 0.7028 - f1-score: 0.8118 - val_loss: 0.1970 - val_iou_score: 0.6966 - val_f1-score: 0.8021 - 105s/epoch - 672ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 105s - loss: 0.1859 - iou_score: 0.7043 - f1-score: 0.8131 - val_loss: 0.1993 - val_iou_score: 0.6987 - val_f1-score: 0.8013 - 105s/epoch - 675ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 104s - loss: 0.1846 - iou_score: 0.7058 - f1-score: 0.8138 - val_loss: 0.2512 - val_iou_score: 0.6351 - val_f1-score: 0.7483 - 104s/epoch - 665ms/step\n",
      "2023/09/28 02:42:57 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 02:43:31 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp_j6zxav_/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 02:43:31 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 02:43:31 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 02:43:31 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 129\n",
      "Created version '129' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 02:44:04.473798: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 02:44:04.870103: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 02:44:04.870139: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 02:44:04.870144: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 02:44:06 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 02:44:06 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f961bf7f520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f961bf7f520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f961bf7f520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f961bf7f520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 135s - loss: 0.3225 - iou_score: 0.5492 - f1-score: 0.6763 - val_loss: 0.3900 - val_iou_score: 0.4807 - val_f1-score: 0.6093 - 135s/epoch - 867ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 105s - loss: 0.2519 - iou_score: 0.6259 - f1-score: 0.7482 - val_loss: 0.2872 - val_iou_score: 0.6012 - val_f1-score: 0.7115 - 105s/epoch - 672ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 103s - loss: 0.2263 - iou_score: 0.6570 - f1-score: 0.7734 - val_loss: 0.2458 - val_iou_score: 0.6399 - val_f1-score: 0.7546 - 103s/epoch - 663ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 104s - loss: 0.2175 - iou_score: 0.6671 - f1-score: 0.7815 - val_loss: 0.2216 - val_iou_score: 0.6657 - val_f1-score: 0.7752 - 104s/epoch - 669ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 104s - loss: 0.2077 - iou_score: 0.6789 - f1-score: 0.7911 - val_loss: 0.2210 - val_iou_score: 0.6714 - val_f1-score: 0.7772 - 104s/epoch - 665ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 105s - loss: 0.2020 - iou_score: 0.6851 - f1-score: 0.7954 - val_loss: 0.2043 - val_iou_score: 0.6872 - val_f1-score: 0.7945 - 105s/epoch - 670ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 105s - loss: 0.1999 - iou_score: 0.6881 - f1-score: 0.7992 - val_loss: 0.2081 - val_iou_score: 0.6838 - val_f1-score: 0.7912 - 105s/epoch - 671ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 105s - loss: 0.1936 - iou_score: 0.6966 - f1-score: 0.8053 - val_loss: 0.1900 - val_iou_score: 0.7082 - val_f1-score: 0.8108 - 105s/epoch - 673ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 105s - loss: 0.1864 - iou_score: 0.7056 - f1-score: 0.8126 - val_loss: 0.1904 - val_iou_score: 0.7073 - val_f1-score: 0.8096 - 105s/epoch - 676ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 105s - loss: 0.1891 - iou_score: 0.7020 - f1-score: 0.8094 - val_loss: 0.1895 - val_iou_score: 0.7060 - val_f1-score: 0.8089 - 105s/epoch - 670ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 105s - loss: 0.1872 - iou_score: 0.7051 - f1-score: 0.8113 - val_loss: 0.1881 - val_iou_score: 0.7104 - val_f1-score: 0.8119 - 105s/epoch - 673ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 105s - loss: 0.1815 - iou_score: 0.7121 - f1-score: 0.8176 - val_loss: 0.1846 - val_iou_score: 0.7126 - val_f1-score: 0.8151 - 105s/epoch - 671ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 106s - loss: 0.1808 - iou_score: 0.7130 - f1-score: 0.8182 - val_loss: 0.1803 - val_iou_score: 0.7182 - val_f1-score: 0.8203 - 106s/epoch - 679ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 105s - loss: 0.1849 - iou_score: 0.7077 - f1-score: 0.8138 - val_loss: 0.1885 - val_iou_score: 0.7098 - val_f1-score: 0.8107 - 105s/epoch - 676ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 106s - loss: 0.1755 - iou_score: 0.7203 - f1-score: 0.8241 - val_loss: 0.1864 - val_iou_score: 0.7115 - val_f1-score: 0.8140 - 106s/epoch - 677ms/step\n",
      "2023/09/28 03:11:05 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 03:11:38 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpg43l4isr/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 03:11:38 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 03:11:38 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 03:11:38 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 130\n",
      "Created version '130' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 03:12:11.204590: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 03:12:11.601068: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 03:12:11.601111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 03:12:11.601118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 03:12:13 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 03:12:13 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fde53fa7520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fde53fa7520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fde53fa7520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fde53fa7520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 135s - loss: 0.3358 - iou_score: 0.5303 - f1-score: 0.6622 - val_loss: 0.3386 - val_iou_score: 0.5398 - val_f1-score: 0.6601 - 135s/epoch - 867ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 101s - loss: 0.2568 - iou_score: 0.6173 - f1-score: 0.7426 - val_loss: 0.2919 - val_iou_score: 0.5978 - val_f1-score: 0.7071 - 101s/epoch - 648ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 104s - loss: 0.2407 - iou_score: 0.6367 - f1-score: 0.7589 - val_loss: 0.2544 - val_iou_score: 0.6371 - val_f1-score: 0.7459 - 104s/epoch - 664ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 103s - loss: 0.2257 - iou_score: 0.6549 - f1-score: 0.7743 - val_loss: 0.2225 - val_iou_score: 0.6641 - val_f1-score: 0.7745 - 103s/epoch - 658ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 103s - loss: 0.2167 - iou_score: 0.6650 - f1-score: 0.7825 - val_loss: 0.2108 - val_iou_score: 0.6811 - val_f1-score: 0.7876 - 103s/epoch - 659ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 103s - loss: 0.2068 - iou_score: 0.6764 - f1-score: 0.7910 - val_loss: 0.2042 - val_iou_score: 0.6892 - val_f1-score: 0.7952 - 103s/epoch - 663ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 104s - loss: 0.2024 - iou_score: 0.6831 - f1-score: 0.7966 - val_loss: 0.2042 - val_iou_score: 0.6899 - val_f1-score: 0.7956 - 104s/epoch - 664ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 103s - loss: 0.1979 - iou_score: 0.6883 - f1-score: 0.8007 - val_loss: 0.2027 - val_iou_score: 0.6944 - val_f1-score: 0.7979 - 103s/epoch - 660ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 103s - loss: 0.1943 - iou_score: 0.6944 - f1-score: 0.8054 - val_loss: 0.2031 - val_iou_score: 0.6937 - val_f1-score: 0.7965 - 103s/epoch - 662ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 104s - loss: 0.1934 - iou_score: 0.6931 - f1-score: 0.8037 - val_loss: 0.2025 - val_iou_score: 0.6888 - val_f1-score: 0.7958 - 104s/epoch - 667ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 104s - loss: 0.1894 - iou_score: 0.6986 - f1-score: 0.8083 - val_loss: 0.1918 - val_iou_score: 0.7066 - val_f1-score: 0.8082 - 104s/epoch - 664ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 103s - loss: 0.1886 - iou_score: 0.7008 - f1-score: 0.8102 - val_loss: 0.1932 - val_iou_score: 0.7029 - val_f1-score: 0.8065 - 103s/epoch - 660ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 104s - loss: 0.1839 - iou_score: 0.7058 - f1-score: 0.8146 - val_loss: 0.1922 - val_iou_score: 0.7045 - val_f1-score: 0.8088 - 104s/epoch - 666ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 104s - loss: 0.1851 - iou_score: 0.7049 - f1-score: 0.8132 - val_loss: 0.2082 - val_iou_score: 0.6833 - val_f1-score: 0.7911 - 104s/epoch - 664ms/step\n",
      "2023/09/28 03:37:05 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 03:37:38 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp9xvh4wpo/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 03:37:39 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 03:37:39 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 03:37:39 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 131\n",
      "Created version '131' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 03:38:12.081609: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 03:38:12.483813: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 03:38:12.483853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 03:38:12.483859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 03:38:14 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 03:38:14 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9183f97520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9183f97520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9183f97520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9183f97520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 140s - loss: 0.3294 - iou_score: 0.5407 - f1-score: 0.6678 - val_loss: 0.3260 - val_iou_score: 0.5463 - val_f1-score: 0.6732 - 140s/epoch - 899ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 110s - loss: 0.2609 - iou_score: 0.6157 - f1-score: 0.7386 - val_loss: 0.2625 - val_iou_score: 0.6197 - val_f1-score: 0.7361 - 110s/epoch - 702ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 110s - loss: 0.2378 - iou_score: 0.6426 - f1-score: 0.7622 - val_loss: 0.2470 - val_iou_score: 0.6436 - val_f1-score: 0.7531 - 110s/epoch - 708ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 111s - loss: 0.2276 - iou_score: 0.6545 - f1-score: 0.7716 - val_loss: 0.2203 - val_iou_score: 0.6657 - val_f1-score: 0.7763 - 111s/epoch - 711ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 112s - loss: 0.2147 - iou_score: 0.6702 - f1-score: 0.7845 - val_loss: 0.2044 - val_iou_score: 0.6886 - val_f1-score: 0.7939 - 112s/epoch - 716ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 111s - loss: 0.2063 - iou_score: 0.6796 - f1-score: 0.7916 - val_loss: 0.2055 - val_iou_score: 0.6877 - val_f1-score: 0.7938 - 111s/epoch - 711ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.2022 - iou_score: 0.6865 - f1-score: 0.7970 - val_loss: 0.2036 - val_iou_score: 0.6881 - val_f1-score: 0.7962 - 111s/epoch - 710ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 112s - loss: 0.2036 - iou_score: 0.6832 - f1-score: 0.7942 - val_loss: 0.1908 - val_iou_score: 0.7065 - val_f1-score: 0.8097 - 112s/epoch - 719ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 111s - loss: 0.1947 - iou_score: 0.6956 - f1-score: 0.8050 - val_loss: 0.1946 - val_iou_score: 0.7021 - val_f1-score: 0.8054 - 111s/epoch - 710ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 112s - loss: 0.1919 - iou_score: 0.6973 - f1-score: 0.8054 - val_loss: 0.1943 - val_iou_score: 0.6995 - val_f1-score: 0.8042 - 112s/epoch - 716ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 111s - loss: 0.1864 - iou_score: 0.7060 - f1-score: 0.8122 - val_loss: 0.1882 - val_iou_score: 0.7102 - val_f1-score: 0.8118 - 111s/epoch - 711ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 111s - loss: 0.1854 - iou_score: 0.7074 - f1-score: 0.8141 - val_loss: 0.1894 - val_iou_score: 0.7052 - val_f1-score: 0.8103 - 111s/epoch - 711ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 112s - loss: 0.1841 - iou_score: 0.7094 - f1-score: 0.8151 - val_loss: 0.1819 - val_iou_score: 0.7184 - val_f1-score: 0.8189 - 112s/epoch - 718ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 112s - loss: 0.1833 - iou_score: 0.7100 - f1-score: 0.8146 - val_loss: 0.1902 - val_iou_score: 0.7084 - val_f1-score: 0.8090 - 112s/epoch - 717ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 111s - loss: 0.1812 - iou_score: 0.7121 - f1-score: 0.8174 - val_loss: 0.1981 - val_iou_score: 0.6967 - val_f1-score: 0.8020 - 111s/epoch - 711ms/step\n",
      "2023/09/28 04:06:47 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 04:07:20 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpyqz12ayt/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 04:07:20 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 04:07:20 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 04:07:20 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 132\n",
      "Created version '132' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 04:07:53.541103: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 04:07:53.942864: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 04:07:53.942902: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 04:07:53.942907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 04:07:55 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 04:07:55 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f3d41963520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f3d41963520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f3d41963520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f3d41963520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 138s - loss: 0.3345 - iou_score: 0.5330 - f1-score: 0.6644 - val_loss: 0.3134 - val_iou_score: 0.5602 - val_f1-score: 0.6847 - 138s/epoch - 884ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 108s - loss: 0.2625 - iou_score: 0.6101 - f1-score: 0.7368 - val_loss: 0.2782 - val_iou_score: 0.6131 - val_f1-score: 0.7207 - 108s/epoch - 690ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 109s - loss: 0.2430 - iou_score: 0.6326 - f1-score: 0.7562 - val_loss: 0.2380 - val_iou_score: 0.6515 - val_f1-score: 0.7620 - 109s/epoch - 697ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 107s - loss: 0.2303 - iou_score: 0.6496 - f1-score: 0.7695 - val_loss: 0.2267 - val_iou_score: 0.6596 - val_f1-score: 0.7700 - 107s/epoch - 687ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 108s - loss: 0.2211 - iou_score: 0.6595 - f1-score: 0.7783 - val_loss: 0.2192 - val_iou_score: 0.6706 - val_f1-score: 0.7794 - 108s/epoch - 693ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 108s - loss: 0.2140 - iou_score: 0.6689 - f1-score: 0.7843 - val_loss: 0.2150 - val_iou_score: 0.6777 - val_f1-score: 0.7845 - 108s/epoch - 692ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 108s - loss: 0.2066 - iou_score: 0.6775 - f1-score: 0.7922 - val_loss: 0.2091 - val_iou_score: 0.6848 - val_f1-score: 0.7907 - 108s/epoch - 692ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 109s - loss: 0.2060 - iou_score: 0.6782 - f1-score: 0.7928 - val_loss: 0.2068 - val_iou_score: 0.6871 - val_f1-score: 0.7937 - 109s/epoch - 699ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 108s - loss: 0.2025 - iou_score: 0.6834 - f1-score: 0.7964 - val_loss: 0.2048 - val_iou_score: 0.6907 - val_f1-score: 0.7954 - 108s/epoch - 690ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 108s - loss: 0.2036 - iou_score: 0.6806 - f1-score: 0.7945 - val_loss: 0.2104 - val_iou_score: 0.6774 - val_f1-score: 0.7881 - 108s/epoch - 691ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 106s - loss: 0.1993 - iou_score: 0.6866 - f1-score: 0.7990 - val_loss: 0.1962 - val_iou_score: 0.7015 - val_f1-score: 0.8042 - 106s/epoch - 681ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 108s - loss: 0.1905 - iou_score: 0.6990 - f1-score: 0.8088 - val_loss: 0.1954 - val_iou_score: 0.7014 - val_f1-score: 0.8045 - 108s/epoch - 689ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 109s - loss: 0.1882 - iou_score: 0.7016 - f1-score: 0.8107 - val_loss: 0.2099 - val_iou_score: 0.6793 - val_f1-score: 0.7908 - 109s/epoch - 696ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 109s - loss: 0.1887 - iou_score: 0.7013 - f1-score: 0.8105 - val_loss: 0.2009 - val_iou_score: 0.6937 - val_f1-score: 0.7989 - 109s/epoch - 700ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 108s - loss: 0.1853 - iou_score: 0.7034 - f1-score: 0.8123 - val_loss: 0.1998 - val_iou_score: 0.6950 - val_f1-score: 0.8006 - 108s/epoch - 692ms/step\n",
      "2023/09/28 04:35:42 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 04:36:15 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpri3hh3ee/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 04:36:15 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 04:36:15 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 04:36:15 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 133\n",
      "Created version '133' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 04:36:48.424342: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 04:36:48.818448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 04:36:48.818488: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 04:36:48.818492: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 04:36:50 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 04:36:50 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f3f283c3520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f3f283c3520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f3f283c3520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f3f283c3520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 139s - loss: 0.3200 - iou_score: 0.5506 - f1-score: 0.6773 - val_loss: 0.3133 - val_iou_score: 0.5610 - val_f1-score: 0.6856 - 139s/epoch - 892ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 105s - loss: 0.2520 - iou_score: 0.6266 - f1-score: 0.7476 - val_loss: 0.2525 - val_iou_score: 0.6318 - val_f1-score: 0.7463 - 105s/epoch - 673ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 107s - loss: 0.2333 - iou_score: 0.6485 - f1-score: 0.7662 - val_loss: 0.2547 - val_iou_score: 0.6345 - val_f1-score: 0.7455 - 107s/epoch - 684ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 107s - loss: 0.2214 - iou_score: 0.6625 - f1-score: 0.7775 - val_loss: 0.2152 - val_iou_score: 0.6743 - val_f1-score: 0.7817 - 107s/epoch - 685ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 106s - loss: 0.2106 - iou_score: 0.6750 - f1-score: 0.7883 - val_loss: 0.2029 - val_iou_score: 0.6890 - val_f1-score: 0.7957 - 106s/epoch - 678ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 107s - loss: 0.2059 - iou_score: 0.6807 - f1-score: 0.7925 - val_loss: 0.2040 - val_iou_score: 0.6888 - val_f1-score: 0.7950 - 107s/epoch - 686ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 107s - loss: 0.2019 - iou_score: 0.6861 - f1-score: 0.7970 - val_loss: 0.1962 - val_iou_score: 0.6977 - val_f1-score: 0.8034 - 107s/epoch - 685ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 106s - loss: 0.1973 - iou_score: 0.6927 - f1-score: 0.8016 - val_loss: 0.1911 - val_iou_score: 0.7070 - val_f1-score: 0.8096 - 106s/epoch - 680ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 106s - loss: 0.1914 - iou_score: 0.7004 - f1-score: 0.8084 - val_loss: 0.2017 - val_iou_score: 0.6963 - val_f1-score: 0.7985 - 106s/epoch - 677ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 107s - loss: 0.1888 - iou_score: 0.7018 - f1-score: 0.8089 - val_loss: 0.1881 - val_iou_score: 0.7072 - val_f1-score: 0.8101 - 107s/epoch - 684ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 107s - loss: 0.1898 - iou_score: 0.7013 - f1-score: 0.8086 - val_loss: 0.1967 - val_iou_score: 0.6992 - val_f1-score: 0.8032 - 107s/epoch - 688ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 108s - loss: 0.1876 - iou_score: 0.7047 - f1-score: 0.8116 - val_loss: 0.1868 - val_iou_score: 0.7090 - val_f1-score: 0.8127 - 108s/epoch - 689ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 107s - loss: 0.1866 - iou_score: 0.7044 - f1-score: 0.8113 - val_loss: 0.1825 - val_iou_score: 0.7165 - val_f1-score: 0.8183 - 107s/epoch - 687ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 107s - loss: 0.1802 - iou_score: 0.7139 - f1-score: 0.8181 - val_loss: 0.2203 - val_iou_score: 0.6745 - val_f1-score: 0.7799 - 107s/epoch - 687ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 107s - loss: 0.1817 - iou_score: 0.7107 - f1-score: 0.8161 - val_loss: 0.1817 - val_iou_score: 0.7164 - val_f1-score: 0.8187 - 107s/epoch - 686ms/step\n",
      "2023/09/28 05:04:19 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 05:04:52 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpef3v1f58/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 05:04:52 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 05:04:52 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 05:04:52 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 134\n",
      "Created version '134' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 05:05:25.182787: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 05:05:25.583599: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 05:05:25.583641: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 05:05:25.583647: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 05:05:27 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 05:05:27 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f236098f520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f236098f520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f236098f520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f236098f520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 140s - loss: 0.3366 - iou_score: 0.5315 - f1-score: 0.6622 - val_loss: 0.3383 - val_iou_score: 0.5395 - val_f1-score: 0.6607 - 140s/epoch - 895ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 110s - loss: 0.2656 - iou_score: 0.6072 - f1-score: 0.7344 - val_loss: 0.2930 - val_iou_score: 0.5934 - val_f1-score: 0.7059 - 110s/epoch - 702ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 111s - loss: 0.2473 - iou_score: 0.6293 - f1-score: 0.7525 - val_loss: 0.2445 - val_iou_score: 0.6422 - val_f1-score: 0.7558 - 111s/epoch - 709ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 111s - loss: 0.2293 - iou_score: 0.6511 - f1-score: 0.7704 - val_loss: 0.2352 - val_iou_score: 0.6538 - val_f1-score: 0.7610 - 111s/epoch - 709ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 110s - loss: 0.2211 - iou_score: 0.6595 - f1-score: 0.7780 - val_loss: 0.2161 - val_iou_score: 0.6723 - val_f1-score: 0.7820 - 110s/epoch - 706ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 110s - loss: 0.2127 - iou_score: 0.6699 - f1-score: 0.7853 - val_loss: 0.2136 - val_iou_score: 0.6785 - val_f1-score: 0.7859 - 110s/epoch - 708ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.2063 - iou_score: 0.6787 - f1-score: 0.7930 - val_loss: 0.2033 - val_iou_score: 0.6907 - val_f1-score: 0.7968 - 111s/epoch - 709ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 111s - loss: 0.2010 - iou_score: 0.6844 - f1-score: 0.7974 - val_loss: 0.2091 - val_iou_score: 0.6848 - val_f1-score: 0.7914 - 111s/epoch - 712ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 109s - loss: 0.2000 - iou_score: 0.6856 - f1-score: 0.7988 - val_loss: 0.2029 - val_iou_score: 0.6920 - val_f1-score: 0.7968 - 109s/epoch - 701ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 112s - loss: 0.1981 - iou_score: 0.6883 - f1-score: 0.7998 - val_loss: 0.2025 - val_iou_score: 0.6915 - val_f1-score: 0.7963 - 112s/epoch - 715ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 111s - loss: 0.1963 - iou_score: 0.6912 - f1-score: 0.8025 - val_loss: 0.1960 - val_iou_score: 0.7016 - val_f1-score: 0.8039 - 111s/epoch - 711ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 111s - loss: 0.1921 - iou_score: 0.6966 - f1-score: 0.8070 - val_loss: 0.1924 - val_iou_score: 0.7054 - val_f1-score: 0.8076 - 111s/epoch - 714ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 111s - loss: 0.1867 - iou_score: 0.7024 - f1-score: 0.8115 - val_loss: 0.1912 - val_iou_score: 0.7071 - val_f1-score: 0.8097 - 111s/epoch - 711ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 111s - loss: 0.1902 - iou_score: 0.6991 - f1-score: 0.8090 - val_loss: 0.2145 - val_iou_score: 0.6771 - val_f1-score: 0.7851 - 111s/epoch - 708ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 111s - loss: 0.1874 - iou_score: 0.7024 - f1-score: 0.8118 - val_loss: 0.1865 - val_iou_score: 0.7127 - val_f1-score: 0.8144 - 111s/epoch - 714ms/step\n",
      "2023/09/28 05:34:24 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 05:34:57 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp5ix9oi3z/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 05:34:57 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 05:34:57 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 05:34:57 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 135\n",
      "Created version '135' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 05:35:30.699700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 05:35:31.091951: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 05:35:31.091985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 05:35:31.091991: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 05:35:32 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 05:35:32 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fc66796b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fc66796b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fc66796b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fc66796b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 141s - loss: 0.3332 - iou_score: 0.5378 - f1-score: 0.6642 - val_loss: 0.3714 - val_iou_score: 0.4980 - val_f1-score: 0.6280 - 141s/epoch - 905ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 111s - loss: 0.2620 - iou_score: 0.6154 - f1-score: 0.7381 - val_loss: 0.2756 - val_iou_score: 0.6048 - val_f1-score: 0.7228 - 111s/epoch - 710ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 111s - loss: 0.2400 - iou_score: 0.6397 - f1-score: 0.7597 - val_loss: 0.2568 - val_iou_score: 0.6280 - val_f1-score: 0.7433 - 111s/epoch - 714ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 111s - loss: 0.2295 - iou_score: 0.6522 - f1-score: 0.7702 - val_loss: 0.2261 - val_iou_score: 0.6583 - val_f1-score: 0.7711 - 111s/epoch - 710ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 112s - loss: 0.2148 - iou_score: 0.6699 - f1-score: 0.7841 - val_loss: 0.2095 - val_iou_score: 0.6811 - val_f1-score: 0.7890 - 112s/epoch - 719ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 113s - loss: 0.2080 - iou_score: 0.6779 - f1-score: 0.7900 - val_loss: 0.2050 - val_iou_score: 0.6879 - val_f1-score: 0.7945 - 113s/epoch - 723ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.2025 - iou_score: 0.6864 - f1-score: 0.7971 - val_loss: 0.1958 - val_iou_score: 0.6982 - val_f1-score: 0.8037 - 111s/epoch - 713ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 111s - loss: 0.1943 - iou_score: 0.6953 - f1-score: 0.8045 - val_loss: 0.1919 - val_iou_score: 0.7047 - val_f1-score: 0.8084 - 111s/epoch - 714ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 113s - loss: 0.1941 - iou_score: 0.6966 - f1-score: 0.8050 - val_loss: 0.1903 - val_iou_score: 0.7066 - val_f1-score: 0.8098 - 113s/epoch - 725ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 112s - loss: 0.1951 - iou_score: 0.6941 - f1-score: 0.8026 - val_loss: 0.1935 - val_iou_score: 0.6992 - val_f1-score: 0.8046 - 112s/epoch - 718ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 114s - loss: 0.1875 - iou_score: 0.7046 - f1-score: 0.8111 - val_loss: 0.1861 - val_iou_score: 0.7123 - val_f1-score: 0.8140 - 114s/epoch - 729ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 113s - loss: 0.1851 - iou_score: 0.7076 - f1-score: 0.8139 - val_loss: 0.1927 - val_iou_score: 0.7008 - val_f1-score: 0.8070 - 113s/epoch - 725ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 113s - loss: 0.1866 - iou_score: 0.7059 - f1-score: 0.8126 - val_loss: 0.1904 - val_iou_score: 0.7078 - val_f1-score: 0.8107 - 113s/epoch - 727ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 113s - loss: 0.1820 - iou_score: 0.7109 - f1-score: 0.8159 - val_loss: 0.1864 - val_iou_score: 0.7113 - val_f1-score: 0.8133 - 113s/epoch - 722ms/step\n",
      "2023/09/28 06:02:30 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 06:03:02 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp9jsl_rhu/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 06:03:02 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 06:03:02 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 06:03:02 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 136\n",
      "Created version '136' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 06:03:35.959477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 06:03:36.359159: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 06:03:36.359196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 06:03:36.359201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 06:03:38 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 06:03:38 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fcbd39df520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fcbd39df520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fcbd39df520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fcbd39df520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 141s - loss: 0.3349 - iou_score: 0.5323 - f1-score: 0.6640 - val_loss: 0.3338 - val_iou_score: 0.5362 - val_f1-score: 0.6656 - 141s/epoch - 904ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 107s - loss: 0.2653 - iou_score: 0.6062 - f1-score: 0.7340 - val_loss: 0.2804 - val_iou_score: 0.6044 - val_f1-score: 0.7184 - 107s/epoch - 685ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 108s - loss: 0.2483 - iou_score: 0.6270 - f1-score: 0.7507 - val_loss: 0.2400 - val_iou_score: 0.6485 - val_f1-score: 0.7605 - 108s/epoch - 690ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 107s - loss: 0.2321 - iou_score: 0.6466 - f1-score: 0.7672 - val_loss: 0.2176 - val_iou_score: 0.6719 - val_f1-score: 0.7794 - 107s/epoch - 688ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 107s - loss: 0.2194 - iou_score: 0.6615 - f1-score: 0.7794 - val_loss: 0.2108 - val_iou_score: 0.6804 - val_f1-score: 0.7877 - 107s/epoch - 686ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 107s - loss: 0.2154 - iou_score: 0.6664 - f1-score: 0.7825 - val_loss: 0.2075 - val_iou_score: 0.6852 - val_f1-score: 0.7911 - 107s/epoch - 684ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 108s - loss: 0.2084 - iou_score: 0.6771 - f1-score: 0.7913 - val_loss: 0.2060 - val_iou_score: 0.6891 - val_f1-score: 0.7938 - 108s/epoch - 692ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 106s - loss: 0.2036 - iou_score: 0.6804 - f1-score: 0.7948 - val_loss: 0.2005 - val_iou_score: 0.6965 - val_f1-score: 0.8003 - 106s/epoch - 682ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 110s - loss: 0.2007 - iou_score: 0.6865 - f1-score: 0.7991 - val_loss: 0.2039 - val_iou_score: 0.6897 - val_f1-score: 0.7958 - 110s/epoch - 705ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 109s - loss: 0.1976 - iou_score: 0.6877 - f1-score: 0.7996 - val_loss: 0.1986 - val_iou_score: 0.6959 - val_f1-score: 0.7996 - 109s/epoch - 698ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 109s - loss: 0.1943 - iou_score: 0.6933 - f1-score: 0.8045 - val_loss: 0.1955 - val_iou_score: 0.7000 - val_f1-score: 0.8045 - 109s/epoch - 701ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 109s - loss: 0.1924 - iou_score: 0.6964 - f1-score: 0.8070 - val_loss: 0.1975 - val_iou_score: 0.6980 - val_f1-score: 0.8022 - 109s/epoch - 696ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 108s - loss: 0.1895 - iou_score: 0.6991 - f1-score: 0.8090 - val_loss: 0.2107 - val_iou_score: 0.6816 - val_f1-score: 0.7904 - 108s/epoch - 693ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 108s - loss: 0.1889 - iou_score: 0.6994 - f1-score: 0.8092 - val_loss: 0.1987 - val_iou_score: 0.6977 - val_f1-score: 0.8007 - 108s/epoch - 692ms/step\n",
      "2023/09/28 06:30:13 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 06:30:46 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpgx6t_hde/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 06:30:46 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 06:30:46 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 06:30:46 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 137\n",
      "Created version '137' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 06:31:19.843609: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 06:31:20.238181: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 06:31:20.238220: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 06:31:20.238226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 06:31:21 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 06:31:21 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7ff405d3b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7ff405d3b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7ff405d3b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7ff405d3b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 141s - loss: 0.3301 - iou_score: 0.5413 - f1-score: 0.6669 - val_loss: 0.3420 - val_iou_score: 0.5365 - val_f1-score: 0.6569 - 141s/epoch - 901ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 110s - loss: 0.2552 - iou_score: 0.6220 - f1-score: 0.7439 - val_loss: 0.2749 - val_iou_score: 0.6139 - val_f1-score: 0.7241 - 110s/epoch - 703ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 111s - loss: 0.2316 - iou_score: 0.6498 - f1-score: 0.7675 - val_loss: 0.2369 - val_iou_score: 0.6542 - val_f1-score: 0.7635 - 111s/epoch - 711ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 110s - loss: 0.2242 - iou_score: 0.6592 - f1-score: 0.7753 - val_loss: 0.2200 - val_iou_score: 0.6657 - val_f1-score: 0.7767 - 110s/epoch - 708ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 112s - loss: 0.2152 - iou_score: 0.6695 - f1-score: 0.7835 - val_loss: 0.1986 - val_iou_score: 0.6949 - val_f1-score: 0.7998 - 112s/epoch - 717ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 110s - loss: 0.2069 - iou_score: 0.6792 - f1-score: 0.7904 - val_loss: 0.2202 - val_iou_score: 0.6713 - val_f1-score: 0.7789 - 110s/epoch - 706ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 112s - loss: 0.2024 - iou_score: 0.6860 - f1-score: 0.7968 - val_loss: 0.1945 - val_iou_score: 0.7005 - val_f1-score: 0.8052 - 112s/epoch - 720ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 112s - loss: 0.1992 - iou_score: 0.6883 - f1-score: 0.7990 - val_loss: 0.1923 - val_iou_score: 0.7041 - val_f1-score: 0.8080 - 112s/epoch - 716ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 111s - loss: 0.1920 - iou_score: 0.6990 - f1-score: 0.8075 - val_loss: 0.1934 - val_iou_score: 0.7035 - val_f1-score: 0.8066 - 111s/epoch - 712ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 112s - loss: 0.1905 - iou_score: 0.6993 - f1-score: 0.8067 - val_loss: 0.1871 - val_iou_score: 0.7082 - val_f1-score: 0.8112 - 112s/epoch - 716ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 111s - loss: 0.1880 - iou_score: 0.7032 - f1-score: 0.8102 - val_loss: 0.1916 - val_iou_score: 0.7049 - val_f1-score: 0.8087 - 111s/epoch - 713ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 111s - loss: 0.1888 - iou_score: 0.7035 - f1-score: 0.8108 - val_loss: 0.1919 - val_iou_score: 0.7036 - val_f1-score: 0.8073 - 111s/epoch - 713ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 111s - loss: 0.1825 - iou_score: 0.7094 - f1-score: 0.8153 - val_loss: 0.1830 - val_iou_score: 0.7160 - val_f1-score: 0.8175 - 111s/epoch - 711ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 111s - loss: 0.1817 - iou_score: 0.7118 - f1-score: 0.8173 - val_loss: 0.1862 - val_iou_score: 0.7111 - val_f1-score: 0.8135 - 111s/epoch - 713ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 110s - loss: 0.1816 - iou_score: 0.7126 - f1-score: 0.8177 - val_loss: 0.1969 - val_iou_score: 0.7011 - val_f1-score: 0.8040 - 110s/epoch - 704ms/step\n",
      "2023/09/28 06:59:54 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 07:00:27 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp_cey5d9k/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 07:00:27 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 07:00:27 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 07:00:27 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 138\n",
      "Created version '138' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 07:01:00.783515: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 07:01:01.187564: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 07:01:01.187603: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 07:01:01.187609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 07:01:02 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 07:01:02 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9fd85cf520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9fd85cf520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9fd85cf520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9fd85cf520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 139s - loss: 0.3394 - iou_score: 0.5277 - f1-score: 0.6596 - val_loss: 0.3317 - val_iou_score: 0.5436 - val_f1-score: 0.6673 - 139s/epoch - 890ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 110s - loss: 0.2656 - iou_score: 0.6076 - f1-score: 0.7344 - val_loss: 0.2803 - val_iou_score: 0.6060 - val_f1-score: 0.7184 - 110s/epoch - 702ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 110s - loss: 0.2443 - iou_score: 0.6323 - f1-score: 0.7552 - val_loss: 0.2382 - val_iou_score: 0.6488 - val_f1-score: 0.7619 - 110s/epoch - 705ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 110s - loss: 0.2323 - iou_score: 0.6465 - f1-score: 0.7672 - val_loss: 0.2237 - val_iou_score: 0.6651 - val_f1-score: 0.7726 - 110s/epoch - 702ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 110s - loss: 0.2219 - iou_score: 0.6589 - f1-score: 0.7774 - val_loss: 0.2167 - val_iou_score: 0.6736 - val_f1-score: 0.7818 - 110s/epoch - 705ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 110s - loss: 0.2147 - iou_score: 0.6668 - f1-score: 0.7833 - val_loss: 0.2138 - val_iou_score: 0.6775 - val_f1-score: 0.7860 - 110s/epoch - 704ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.2088 - iou_score: 0.6758 - f1-score: 0.7908 - val_loss: 0.2020 - val_iou_score: 0.6923 - val_f1-score: 0.7976 - 111s/epoch - 711ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 109s - loss: 0.2046 - iou_score: 0.6807 - f1-score: 0.7947 - val_loss: 0.2029 - val_iou_score: 0.6928 - val_f1-score: 0.7976 - 109s/epoch - 701ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 110s - loss: 0.1979 - iou_score: 0.6889 - f1-score: 0.8012 - val_loss: 0.2105 - val_iou_score: 0.6838 - val_f1-score: 0.7890 - 110s/epoch - 707ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 111s - loss: 0.1976 - iou_score: 0.6887 - f1-score: 0.8006 - val_loss: 0.1987 - val_iou_score: 0.6928 - val_f1-score: 0.7996 - 111s/epoch - 711ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 110s - loss: 0.1916 - iou_score: 0.6961 - f1-score: 0.8065 - val_loss: 0.1941 - val_iou_score: 0.7040 - val_f1-score: 0.8062 - 110s/epoch - 703ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 110s - loss: 0.1919 - iou_score: 0.6971 - f1-score: 0.8074 - val_loss: 0.1927 - val_iou_score: 0.7031 - val_f1-score: 0.8070 - 110s/epoch - 707ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 110s - loss: 0.1926 - iou_score: 0.6961 - f1-score: 0.8064 - val_loss: 0.1970 - val_iou_score: 0.6996 - val_f1-score: 0.8041 - 110s/epoch - 708ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 110s - loss: 0.1897 - iou_score: 0.6990 - f1-score: 0.8091 - val_loss: 0.2068 - val_iou_score: 0.6822 - val_f1-score: 0.7926 - 110s/epoch - 705ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 111s - loss: 0.1865 - iou_score: 0.7028 - f1-score: 0.8117 - val_loss: 0.1993 - val_iou_score: 0.6965 - val_f1-score: 0.8016 - 111s/epoch - 711ms/step\n",
      "2023/09/28 07:29:21 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 07:29:53 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpfv80bunz/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 07:29:53 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 07:29:53 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 07:29:53 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 139\n",
      "Created version '139' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!bash src/modeling/pretrained-models_aug_oversampling.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-28 11:20:41.720139: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 11:20:42.389545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 11:20:42.389590: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 11:20:42.389595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 11:20:44 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 11:20:44 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f06f339b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f06f339b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f06f339b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f06f339b520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 140s - loss: 0.3041 - iou_score: 0.5763 - f1-score: 0.6947 - val_loss: 0.2895 - val_iou_score: 0.5850 - val_f1-score: 0.7094 - 140s/epoch - 899ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 111s - loss: 0.2326 - iou_score: 0.6530 - f1-score: 0.7671 - val_loss: 0.2592 - val_iou_score: 0.6205 - val_f1-score: 0.7395 - 111s/epoch - 709ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 108s - loss: 0.2096 - iou_score: 0.6808 - f1-score: 0.7903 - val_loss: 0.2107 - val_iou_score: 0.6810 - val_f1-score: 0.7895 - 108s/epoch - 691ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 111s - loss: 0.1957 - iou_score: 0.6986 - f1-score: 0.8041 - val_loss: 0.1959 - val_iou_score: 0.6962 - val_f1-score: 0.8010 - 111s/epoch - 713ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 111s - loss: 0.1883 - iou_score: 0.7065 - f1-score: 0.8108 - val_loss: 0.1906 - val_iou_score: 0.7040 - val_f1-score: 0.8078 - 111s/epoch - 710ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 112s - loss: 0.1840 - iou_score: 0.7114 - f1-score: 0.8142 - val_loss: 0.1929 - val_iou_score: 0.6997 - val_f1-score: 0.8068 - 112s/epoch - 715ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.1807 - iou_score: 0.7160 - f1-score: 0.8179 - val_loss: 0.1798 - val_iou_score: 0.7190 - val_f1-score: 0.8200 - 111s/epoch - 714ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 111s - loss: 0.1748 - iou_score: 0.7252 - f1-score: 0.8251 - val_loss: 0.1826 - val_iou_score: 0.7161 - val_f1-score: 0.8181 - 111s/epoch - 709ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 113s - loss: 0.1716 - iou_score: 0.7275 - f1-score: 0.8274 - val_loss: 0.1805 - val_iou_score: 0.7184 - val_f1-score: 0.8196 - 113s/epoch - 723ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 109s - loss: 0.1700 - iou_score: 0.7292 - f1-score: 0.8280 - val_loss: 0.1744 - val_iou_score: 0.7230 - val_f1-score: 0.8240 - 109s/epoch - 698ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 114s - loss: 0.1670 - iou_score: 0.7339 - f1-score: 0.8318 - val_loss: 0.1720 - val_iou_score: 0.7282 - val_f1-score: 0.8280 - 114s/epoch - 728ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 112s - loss: 0.1642 - iou_score: 0.7377 - f1-score: 0.8350 - val_loss: 0.1717 - val_iou_score: 0.7278 - val_f1-score: 0.8279 - 112s/epoch - 716ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 110s - loss: 0.1640 - iou_score: 0.7369 - f1-score: 0.8345 - val_loss: 0.1787 - val_iou_score: 0.7201 - val_f1-score: 0.8222 - 110s/epoch - 702ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 112s - loss: 0.1653 - iou_score: 0.7355 - f1-score: 0.8337 - val_loss: 0.1742 - val_iou_score: 0.7252 - val_f1-score: 0.8255 - 112s/epoch - 716ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 112s - loss: 0.1612 - iou_score: 0.7410 - f1-score: 0.8376 - val_loss: 0.1731 - val_iou_score: 0.7274 - val_f1-score: 0.8275 - 112s/epoch - 718ms/step\n",
      "2023/09/28 11:49:16 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 11:49:51 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmps747_q83/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 11:49:51 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 11:49:51 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 11:49:51 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 140\n",
      "Created version '140' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py generator.auglist.geo=rdcrop \\\n",
    "                    generator.auglist.ker=gnoise \\\n",
    "                    generator.auglist.clim=0.14 \\\n",
    "                    generator.auglist.blim=0.2 \\\n",
    "                    generator.mosaic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-28 18:34:12.198622: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 18:34:12.639524: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 18:34:12.639569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 18:34:12.639576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 18:34:14 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 18:34:14 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5cdc9c75b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5cdc9c75b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5cdc9c75b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5cdc9c75b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 150s - loss: 0.3010 - iou_score: 0.5631 - f1-score: 0.6980 - val_loss: 0.3266 - val_iou_score: 0.5547 - val_f1-score: 0.6724 - 150s/epoch - 960ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 118s - loss: 0.2323 - iou_score: 0.6395 - f1-score: 0.7670 - val_loss: 0.2901 - val_iou_score: 0.6011 - val_f1-score: 0.7085 - 118s/epoch - 755ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 116s - loss: 0.2051 - iou_score: 0.6737 - f1-score: 0.7939 - val_loss: 0.2472 - val_iou_score: 0.6476 - val_f1-score: 0.7531 - 116s/epoch - 746ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 115s - loss: 0.1915 - iou_score: 0.6914 - f1-score: 0.8076 - val_loss: 0.2116 - val_iou_score: 0.6805 - val_f1-score: 0.7854 - 115s/epoch - 739ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 119s - loss: 0.1818 - iou_score: 0.7041 - f1-score: 0.8171 - val_loss: 0.2094 - val_iou_score: 0.6846 - val_f1-score: 0.7893 - 119s/epoch - 760ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 111s - loss: 0.1769 - iou_score: 0.7103 - f1-score: 0.8213 - val_loss: 0.1980 - val_iou_score: 0.6982 - val_f1-score: 0.8013 - 111s/epoch - 713ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 109s - loss: 0.1700 - iou_score: 0.7207 - f1-score: 0.8288 - val_loss: 0.1956 - val_iou_score: 0.7008 - val_f1-score: 0.8043 - 109s/epoch - 700ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 111s - loss: 0.1688 - iou_score: 0.7226 - f1-score: 0.8306 - val_loss: 0.1999 - val_iou_score: 0.6990 - val_f1-score: 0.8010 - 111s/epoch - 711ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 110s - loss: 0.1647 - iou_score: 0.7279 - f1-score: 0.8343 - val_loss: 0.1919 - val_iou_score: 0.7070 - val_f1-score: 0.8076 - 110s/epoch - 703ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 110s - loss: 0.1642 - iou_score: 0.7279 - f1-score: 0.8343 - val_loss: 0.1952 - val_iou_score: 0.7008 - val_f1-score: 0.8026 - 110s/epoch - 707ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 115s - loss: 0.1602 - iou_score: 0.7336 - f1-score: 0.8379 - val_loss: 0.1881 - val_iou_score: 0.7116 - val_f1-score: 0.8117 - 115s/epoch - 739ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 113s - loss: 0.1561 - iou_score: 0.7400 - f1-score: 0.8433 - val_loss: 0.1846 - val_iou_score: 0.7156 - val_f1-score: 0.8153 - 113s/epoch - 723ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 113s - loss: 0.1554 - iou_score: 0.7402 - f1-score: 0.8432 - val_loss: 0.1949 - val_iou_score: 0.7024 - val_f1-score: 0.8061 - 113s/epoch - 721ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 113s - loss: 0.1554 - iou_score: 0.7402 - f1-score: 0.8429 - val_loss: 0.1814 - val_iou_score: 0.7191 - val_f1-score: 0.8184 - 113s/epoch - 722ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 113s - loss: 0.1517 - iou_score: 0.7466 - f1-score: 0.8480 - val_loss: 0.1876 - val_iou_score: 0.7086 - val_f1-score: 0.8127 - 113s/epoch - 726ms/step\n",
      "2023/09/28 19:03:27 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 19:04:01 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpqql1ez5p/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 19:04:01 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 19:04:01 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 19:04:01 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 142\n",
      "Created version '142' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py generator.auglist.geo=rdcrop \\\n",
    "                    generator.auglist.ker=gnoise \\\n",
    "                    generator.auglist.clim=0.14 \\\n",
    "                    generator.auglist.blim=0.2 \\\n",
    "                    generator.oversampling=True \\\n",
    "                    generator.oversampling_n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-28 23:28:47.564311: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 23:28:48.233878: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 23:28:48.233926: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 23:28:48.233932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 23:28:50 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 23:28:50 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fa02519f490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fa02519f490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fa02519f490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fa02519f490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 150s - loss: 0.2966 - iou_score: 0.5740 - f1-score: 0.7020 - val_loss: 0.3249 - val_iou_score: 0.5455 - val_f1-score: 0.6730 - 150s/epoch - 961ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 112s - loss: 0.2297 - iou_score: 0.6487 - f1-score: 0.7695 - val_loss: 0.2575 - val_iou_score: 0.6275 - val_f1-score: 0.7406 - 112s/epoch - 717ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 113s - loss: 0.2041 - iou_score: 0.6811 - f1-score: 0.7956 - val_loss: 0.2382 - val_iou_score: 0.6501 - val_f1-score: 0.7624 - 113s/epoch - 723ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 112s - loss: 0.1904 - iou_score: 0.6990 - f1-score: 0.8093 - val_loss: 0.2128 - val_iou_score: 0.6771 - val_f1-score: 0.7840 - 112s/epoch - 716ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 112s - loss: 0.1866 - iou_score: 0.7031 - f1-score: 0.8128 - val_loss: 0.1986 - val_iou_score: 0.6938 - val_f1-score: 0.7996 - 112s/epoch - 718ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 112s - loss: 0.1764 - iou_score: 0.7157 - f1-score: 0.8218 - val_loss: 0.1944 - val_iou_score: 0.7013 - val_f1-score: 0.8053 - 112s/epoch - 718ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.1744 - iou_score: 0.7191 - f1-score: 0.8246 - val_loss: 0.1917 - val_iou_score: 0.7039 - val_f1-score: 0.8081 - 111s/epoch - 709ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 110s - loss: 0.1697 - iou_score: 0.7258 - f1-score: 0.8298 - val_loss: 0.1878 - val_iou_score: 0.7112 - val_f1-score: 0.8120 - 110s/epoch - 702ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 110s - loss: 0.1674 - iou_score: 0.7285 - f1-score: 0.8316 - val_loss: 0.1913 - val_iou_score: 0.7074 - val_f1-score: 0.8089 - 110s/epoch - 707ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 109s - loss: 0.1641 - iou_score: 0.7311 - f1-score: 0.8334 - val_loss: 0.1805 - val_iou_score: 0.7156 - val_f1-score: 0.8176 - 109s/epoch - 700ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 110s - loss: 0.1620 - iou_score: 0.7344 - f1-score: 0.8358 - val_loss: 0.1869 - val_iou_score: 0.7109 - val_f1-score: 0.8134 - 110s/epoch - 705ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 111s - loss: 0.1633 - iou_score: 0.7336 - f1-score: 0.8360 - val_loss: 0.1881 - val_iou_score: 0.7085 - val_f1-score: 0.8114 - 111s/epoch - 713ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 110s - loss: 0.1593 - iou_score: 0.7388 - f1-score: 0.8390 - val_loss: 0.1780 - val_iou_score: 0.7230 - val_f1-score: 0.8228 - 110s/epoch - 707ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 110s - loss: 0.1556 - iou_score: 0.7437 - f1-score: 0.8426 - val_loss: 0.1752 - val_iou_score: 0.7257 - val_f1-score: 0.8245 - 110s/epoch - 708ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 111s - loss: 0.1539 - iou_score: 0.7471 - f1-score: 0.8459 - val_loss: 0.1718 - val_iou_score: 0.7302 - val_f1-score: 0.8288 - 111s/epoch - 709ms/step\n",
      "2023/09/28 23:57:29 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/28 23:58:03 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpn2z36g8g/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/28 23:58:03 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 23:58:03 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/28 23:58:03 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 143\n",
      "Created version '143' of model 'fpn'.\n",
      "job end\n",
      "2023-09-28 23:58:36.282458: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 23:58:36.681747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 23:58:36.681785: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-28 23:58:36.681791: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/28 23:58:38 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/28 23:58:38 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7ff7fc5cb490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7ff7fc5cb490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7ff7fc5cb490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7ff7fc5cb490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 136s - loss: 0.2952 - iou_score: 0.5730 - f1-score: 0.7025 - val_loss: 0.3291 - val_iou_score: 0.5416 - val_f1-score: 0.6702 - 136s/epoch - 873ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 108s - loss: 0.2248 - iou_score: 0.6532 - f1-score: 0.7752 - val_loss: 0.2680 - val_iou_score: 0.6169 - val_f1-score: 0.7317 - 108s/epoch - 691ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 107s - loss: 0.2057 - iou_score: 0.6770 - f1-score: 0.7940 - val_loss: 0.2304 - val_iou_score: 0.6593 - val_f1-score: 0.7698 - 107s/epoch - 683ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 109s - loss: 0.1935 - iou_score: 0.6917 - f1-score: 0.8052 - val_loss: 0.2160 - val_iou_score: 0.6733 - val_f1-score: 0.7812 - 109s/epoch - 699ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 106s - loss: 0.1800 - iou_score: 0.7100 - f1-score: 0.8193 - val_loss: 0.2048 - val_iou_score: 0.6898 - val_f1-score: 0.7934 - 106s/epoch - 683ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 108s - loss: 0.1753 - iou_score: 0.7151 - f1-score: 0.8223 - val_loss: 0.1993 - val_iou_score: 0.6951 - val_f1-score: 0.7998 - 108s/epoch - 694ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 107s - loss: 0.1686 - iou_score: 0.7251 - f1-score: 0.8301 - val_loss: 0.2052 - val_iou_score: 0.6884 - val_f1-score: 0.7941 - 107s/epoch - 688ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 108s - loss: 0.1670 - iou_score: 0.7275 - f1-score: 0.8319 - val_loss: 0.2064 - val_iou_score: 0.6905 - val_f1-score: 0.7941 - 108s/epoch - 694ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 108s - loss: 0.1624 - iou_score: 0.7345 - f1-score: 0.8374 - val_loss: 0.1915 - val_iou_score: 0.7053 - val_f1-score: 0.8083 - 108s/epoch - 690ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 111s - loss: 0.1646 - iou_score: 0.7293 - f1-score: 0.8329 - val_loss: 0.1907 - val_iou_score: 0.7046 - val_f1-score: 0.8070 - 111s/epoch - 711ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 107s - loss: 0.1609 - iou_score: 0.7355 - f1-score: 0.8379 - val_loss: 0.1991 - val_iou_score: 0.6988 - val_f1-score: 0.8010 - 107s/epoch - 686ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 108s - loss: 0.1563 - iou_score: 0.7422 - f1-score: 0.8429 - val_loss: 0.1818 - val_iou_score: 0.7171 - val_f1-score: 0.8181 - 108s/epoch - 692ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 108s - loss: 0.1552 - iou_score: 0.7438 - f1-score: 0.8439 - val_loss: 0.1894 - val_iou_score: 0.7071 - val_f1-score: 0.8112 - 108s/epoch - 695ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 107s - loss: 0.1544 - iou_score: 0.7446 - f1-score: 0.8443 - val_loss: 0.1914 - val_iou_score: 0.7038 - val_f1-score: 0.8085 - 107s/epoch - 684ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 107s - loss: 0.1540 - iou_score: 0.7448 - f1-score: 0.8447 - val_loss: 0.1782 - val_iou_score: 0.7222 - val_f1-score: 0.8221 - 107s/epoch - 685ms/step\n",
      "2023/09/29 00:26:20 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/29 00:26:53 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpjtxd149v/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/29 00:26:53 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 00:26:53 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/29 00:26:53 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 144\n",
      "Created version '144' of model 'fpn'.\n",
      "job end\n",
      "2023-09-29 00:27:26.507823: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 00:27:26.908756: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 00:27:26.908792: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 00:27:26.908798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/29 00:27:28 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 00:27:28 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f0afb9e3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f0afb9e3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f0afb9e3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f0afb9e3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 140s - loss: 0.2880 - iou_score: 0.5805 - f1-score: 0.7098 - val_loss: 0.3438 - val_iou_score: 0.5353 - val_f1-score: 0.6547 - 140s/epoch - 895ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 109s - loss: 0.2270 - iou_score: 0.6511 - f1-score: 0.7732 - val_loss: 0.2879 - val_iou_score: 0.5995 - val_f1-score: 0.7109 - 109s/epoch - 701ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 111s - loss: 0.2105 - iou_score: 0.6704 - f1-score: 0.7886 - val_loss: 0.2476 - val_iou_score: 0.6395 - val_f1-score: 0.7524 - 111s/epoch - 711ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 110s - loss: 0.1947 - iou_score: 0.6910 - f1-score: 0.8044 - val_loss: 0.2189 - val_iou_score: 0.6707 - val_f1-score: 0.7779 - 110s/epoch - 707ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 111s - loss: 0.1842 - iou_score: 0.7040 - f1-score: 0.8145 - val_loss: 0.2151 - val_iou_score: 0.6763 - val_f1-score: 0.7833 - 111s/epoch - 709ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 110s - loss: 0.1768 - iou_score: 0.7140 - f1-score: 0.8210 - val_loss: 0.2165 - val_iou_score: 0.6760 - val_f1-score: 0.7836 - 110s/epoch - 705ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.1729 - iou_score: 0.7196 - f1-score: 0.8261 - val_loss: 0.2140 - val_iou_score: 0.6796 - val_f1-score: 0.7853 - 111s/epoch - 713ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 111s - loss: 0.1698 - iou_score: 0.7242 - f1-score: 0.8297 - val_loss: 0.2047 - val_iou_score: 0.6918 - val_f1-score: 0.7960 - 111s/epoch - 711ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 111s - loss: 0.1682 - iou_score: 0.7270 - f1-score: 0.8314 - val_loss: 0.2040 - val_iou_score: 0.6941 - val_f1-score: 0.7958 - 111s/epoch - 711ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 110s - loss: 0.1632 - iou_score: 0.7311 - f1-score: 0.8343 - val_loss: 0.1904 - val_iou_score: 0.7037 - val_f1-score: 0.8081 - 110s/epoch - 707ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 111s - loss: 0.1641 - iou_score: 0.7316 - f1-score: 0.8347 - val_loss: 0.1910 - val_iou_score: 0.7070 - val_f1-score: 0.8090 - 111s/epoch - 709ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 112s - loss: 0.1584 - iou_score: 0.7399 - f1-score: 0.8408 - val_loss: 0.1845 - val_iou_score: 0.7136 - val_f1-score: 0.8152 - 112s/epoch - 716ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 111s - loss: 0.1535 - iou_score: 0.7461 - f1-score: 0.8458 - val_loss: 0.1903 - val_iou_score: 0.7067 - val_f1-score: 0.8103 - 111s/epoch - 712ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 111s - loss: 0.1565 - iou_score: 0.7420 - f1-score: 0.8424 - val_loss: 0.1878 - val_iou_score: 0.7112 - val_f1-score: 0.8118 - 111s/epoch - 711ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 111s - loss: 0.1541 - iou_score: 0.7449 - f1-score: 0.8448 - val_loss: 0.1909 - val_iou_score: 0.7098 - val_f1-score: 0.8099 - 111s/epoch - 715ms/step\n",
      "2023/09/29 00:55:55 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/29 00:56:29 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmprp40lbv2/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/29 00:56:29 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 00:56:29 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/29 00:56:29 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 145\n",
      "Created version '145' of model 'fpn'.\n",
      "job end\n",
      "2023-09-29 00:57:02.320360: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 00:57:02.712048: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 00:57:02.712085: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 00:57:02.712090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/29 00:57:04 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 00:57:04 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f1b85f83490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f1b85f83490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f1b85f83490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f1b85f83490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 141s - loss: 0.2966 - iou_score: 0.5695 - f1-score: 0.7019 - val_loss: 0.3190 - val_iou_score: 0.5529 - val_f1-score: 0.6800 - 141s/epoch - 902ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 111s - loss: 0.2282 - iou_score: 0.6470 - f1-score: 0.7713 - val_loss: 0.2879 - val_iou_score: 0.5925 - val_f1-score: 0.7102 - 111s/epoch - 709ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 111s - loss: 0.2073 - iou_score: 0.6729 - f1-score: 0.7923 - val_loss: 0.2356 - val_iou_score: 0.6529 - val_f1-score: 0.7646 - 111s/epoch - 709ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 111s - loss: 0.1912 - iou_score: 0.6941 - f1-score: 0.8081 - val_loss: 0.2168 - val_iou_score: 0.6755 - val_f1-score: 0.7800 - 111s/epoch - 709ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 111s - loss: 0.1816 - iou_score: 0.7060 - f1-score: 0.8173 - val_loss: 0.1995 - val_iou_score: 0.6959 - val_f1-score: 0.7988 - 111s/epoch - 712ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 111s - loss: 0.1778 - iou_score: 0.7109 - f1-score: 0.8206 - val_loss: 0.2107 - val_iou_score: 0.6841 - val_f1-score: 0.7894 - 111s/epoch - 714ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.1717 - iou_score: 0.7207 - f1-score: 0.8279 - val_loss: 0.1925 - val_iou_score: 0.7043 - val_f1-score: 0.8072 - 111s/epoch - 710ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 112s - loss: 0.1652 - iou_score: 0.7284 - f1-score: 0.8338 - val_loss: 0.1877 - val_iou_score: 0.7124 - val_f1-score: 0.8132 - 112s/epoch - 719ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 111s - loss: 0.1608 - iou_score: 0.7357 - f1-score: 0.8391 - val_loss: 0.2024 - val_iou_score: 0.6931 - val_f1-score: 0.7976 - 111s/epoch - 711ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 111s - loss: 0.1652 - iou_score: 0.7270 - f1-score: 0.8323 - val_loss: 0.1859 - val_iou_score: 0.7101 - val_f1-score: 0.8121 - 111s/epoch - 714ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 111s - loss: 0.1600 - iou_score: 0.7349 - f1-score: 0.8382 - val_loss: 0.1902 - val_iou_score: 0.7102 - val_f1-score: 0.8098 - 111s/epoch - 710ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 112s - loss: 0.1566 - iou_score: 0.7402 - f1-score: 0.8421 - val_loss: 0.1790 - val_iou_score: 0.7211 - val_f1-score: 0.8208 - 112s/epoch - 721ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 111s - loss: 0.1522 - iou_score: 0.7466 - f1-score: 0.8470 - val_loss: 0.1903 - val_iou_score: 0.7087 - val_f1-score: 0.8106 - 111s/epoch - 710ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 112s - loss: 0.1539 - iou_score: 0.7433 - f1-score: 0.8450 - val_loss: 0.1871 - val_iou_score: 0.7137 - val_f1-score: 0.8124 - 112s/epoch - 716ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 112s - loss: 0.1532 - iou_score: 0.7454 - f1-score: 0.8463 - val_loss: 0.1882 - val_iou_score: 0.7117 - val_f1-score: 0.8121 - 112s/epoch - 715ms/step\n",
      "2023/09/29 01:25:38 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/29 01:26:11 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpo2kg3n_c/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/29 01:26:12 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 01:26:12 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/29 01:26:12 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 146\n",
      "Created version '146' of model 'fpn'.\n",
      "job end\n",
      "2023-09-29 01:26:45.089938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 01:26:45.498724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 01:26:45.498765: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 01:26:45.498772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/29 01:26:47 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 01:26:47 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ef8363490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ef8363490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ef8363490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ef8363490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 140s - loss: 0.2909 - iou_score: 0.5731 - f1-score: 0.7072 - val_loss: 0.3316 - val_iou_score: 0.5484 - val_f1-score: 0.6679 - 140s/epoch - 900ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 110s - loss: 0.2232 - iou_score: 0.6515 - f1-score: 0.7764 - val_loss: 0.2931 - val_iou_score: 0.5938 - val_f1-score: 0.7061 - 110s/epoch - 706ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 110s - loss: 0.2031 - iou_score: 0.6765 - f1-score: 0.7964 - val_loss: 0.2316 - val_iou_score: 0.6600 - val_f1-score: 0.7683 - 110s/epoch - 702ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 110s - loss: 0.1906 - iou_score: 0.6925 - f1-score: 0.8082 - val_loss: 0.2199 - val_iou_score: 0.6708 - val_f1-score: 0.7770 - 110s/epoch - 703ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 111s - loss: 0.1757 - iou_score: 0.7123 - f1-score: 0.8231 - val_loss: 0.2151 - val_iou_score: 0.6773 - val_f1-score: 0.7832 - 111s/epoch - 710ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 108s - loss: 0.1697 - iou_score: 0.7203 - f1-score: 0.8289 - val_loss: 0.2024 - val_iou_score: 0.6950 - val_f1-score: 0.7974 - 108s/epoch - 690ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 110s - loss: 0.1665 - iou_score: 0.7268 - f1-score: 0.8331 - val_loss: 0.1979 - val_iou_score: 0.6997 - val_f1-score: 0.8015 - 110s/epoch - 705ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 109s - loss: 0.1645 - iou_score: 0.7279 - f1-score: 0.8344 - val_loss: 0.2026 - val_iou_score: 0.6957 - val_f1-score: 0.7982 - 109s/epoch - 701ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 109s - loss: 0.1586 - iou_score: 0.7365 - f1-score: 0.8406 - val_loss: 0.1922 - val_iou_score: 0.7055 - val_f1-score: 0.8078 - 109s/epoch - 702ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 111s - loss: 0.1565 - iou_score: 0.7389 - f1-score: 0.8416 - val_loss: 0.1897 - val_iou_score: 0.7067 - val_f1-score: 0.8088 - 111s/epoch - 712ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 110s - loss: 0.1565 - iou_score: 0.7382 - f1-score: 0.8411 - val_loss: 0.1918 - val_iou_score: 0.7063 - val_f1-score: 0.8081 - 110s/epoch - 705ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 110s - loss: 0.1530 - iou_score: 0.7442 - f1-score: 0.8460 - val_loss: 0.1910 - val_iou_score: 0.7067 - val_f1-score: 0.8085 - 110s/epoch - 705ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 111s - loss: 0.1485 - iou_score: 0.7502 - f1-score: 0.8501 - val_loss: 0.2122 - val_iou_score: 0.6858 - val_f1-score: 0.7887 - 111s/epoch - 710ms/step\n",
      "2023/09/29 01:51:23 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/29 01:51:56 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpw_1pebwj/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/29 01:51:56 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 01:51:56 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/29 01:51:56 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 147\n",
      "Created version '147' of model 'fpn'.\n",
      "job end\n",
      "2023-09-29 01:52:29.554651: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 01:52:29.953078: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 01:52:29.953127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 01:52:29.953133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/29 01:52:31 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 01:52:31 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f4da8d8b490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f4da8d8b490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f4da8d8b490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f4da8d8b490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 141s - loss: 0.2840 - iou_score: 0.5808 - f1-score: 0.7147 - val_loss: 0.3509 - val_iou_score: 0.5268 - val_f1-score: 0.6468 - 141s/epoch - 901ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 105s - loss: 0.2204 - iou_score: 0.6549 - f1-score: 0.7796 - val_loss: 0.2697 - val_iou_score: 0.6137 - val_f1-score: 0.7289 - 105s/epoch - 670ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 105s - loss: 0.2063 - iou_score: 0.6721 - f1-score: 0.7932 - val_loss: 0.2835 - val_iou_score: 0.5967 - val_f1-score: 0.7169 - 105s/epoch - 673ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 105s - loss: 0.1907 - iou_score: 0.6934 - f1-score: 0.8091 - val_loss: 0.2270 - val_iou_score: 0.6617 - val_f1-score: 0.7703 - 105s/epoch - 674ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 107s - loss: 0.1752 - iou_score: 0.7133 - f1-score: 0.8235 - val_loss: 0.2218 - val_iou_score: 0.6735 - val_f1-score: 0.7763 - 107s/epoch - 687ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 112s - loss: 0.1696 - iou_score: 0.7209 - f1-score: 0.8287 - val_loss: 0.2110 - val_iou_score: 0.6852 - val_f1-score: 0.7886 - 112s/epoch - 719ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 112s - loss: 0.1682 - iou_score: 0.7236 - f1-score: 0.8310 - val_loss: 0.2065 - val_iou_score: 0.6906 - val_f1-score: 0.7934 - 112s/epoch - 720ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 106s - loss: 0.1612 - iou_score: 0.7325 - f1-score: 0.8381 - val_loss: 0.1993 - val_iou_score: 0.6992 - val_f1-score: 0.8013 - 106s/epoch - 677ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 112s - loss: 0.1542 - iou_score: 0.7429 - f1-score: 0.8450 - val_loss: 0.2025 - val_iou_score: 0.6969 - val_f1-score: 0.7977 - 112s/epoch - 715ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 106s - loss: 0.1592 - iou_score: 0.7351 - f1-score: 0.8382 - val_loss: 0.2006 - val_iou_score: 0.6948 - val_f1-score: 0.7973 - 106s/epoch - 679ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 105s - loss: 0.1576 - iou_score: 0.7378 - f1-score: 0.8407 - val_loss: 0.1959 - val_iou_score: 0.7039 - val_f1-score: 0.8043 - 105s/epoch - 675ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 111s - loss: 0.1500 - iou_score: 0.7486 - f1-score: 0.8490 - val_loss: 0.1957 - val_iou_score: 0.7023 - val_f1-score: 0.8038 - 111s/epoch - 713ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 106s - loss: 0.1486 - iou_score: 0.7500 - f1-score: 0.8500 - val_loss: 0.2116 - val_iou_score: 0.6817 - val_f1-score: 0.7889 - 106s/epoch - 677ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 107s - loss: 0.1492 - iou_score: 0.7498 - f1-score: 0.8498 - val_loss: 0.2186 - val_iou_score: 0.6730 - val_f1-score: 0.7814 - 107s/epoch - 683ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 112s - loss: 0.1493 - iou_score: 0.7506 - f1-score: 0.8504 - val_loss: 0.1925 - val_iou_score: 0.7061 - val_f1-score: 0.8080 - 112s/epoch - 715ms/step\n",
      "2023/09/29 02:20:49 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/29 02:21:22 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp7dlorju3/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/29 02:21:22 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 02:21:22 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/29 02:21:22 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 148\n",
      "Created version '148' of model 'fpn'.\n",
      "job end\n",
      "2023-09-29 02:21:55.478439: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 02:21:55.868537: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 02:21:55.868575: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 02:21:55.868580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/29 02:21:57 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 02:21:57 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ca81d3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ca81d3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ca81d3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f0ca81d3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 137s - loss: 0.3016 - iou_score: 0.5603 - f1-score: 0.6965 - val_loss: 0.3259 - val_iou_score: 0.5492 - val_f1-score: 0.6721 - 137s/epoch - 879ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 106s - loss: 0.2323 - iou_score: 0.6394 - f1-score: 0.7666 - val_loss: 0.2723 - val_iou_score: 0.6153 - val_f1-score: 0.7263 - 106s/epoch - 682ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 107s - loss: 0.2051 - iou_score: 0.6734 - f1-score: 0.7940 - val_loss: 0.2390 - val_iou_score: 0.6569 - val_f1-score: 0.7614 - 107s/epoch - 683ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 107s - loss: 0.1938 - iou_score: 0.6894 - f1-score: 0.8056 - val_loss: 0.2144 - val_iou_score: 0.6773 - val_f1-score: 0.7824 - 107s/epoch - 685ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 106s - loss: 0.1811 - iou_score: 0.7055 - f1-score: 0.8182 - val_loss: 0.2049 - val_iou_score: 0.6887 - val_f1-score: 0.7931 - 106s/epoch - 679ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 108s - loss: 0.1763 - iou_score: 0.7112 - f1-score: 0.8220 - val_loss: 0.2072 - val_iou_score: 0.6892 - val_f1-score: 0.7921 - 108s/epoch - 691ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 107s - loss: 0.1719 - iou_score: 0.7178 - f1-score: 0.8268 - val_loss: 0.1943 - val_iou_score: 0.7016 - val_f1-score: 0.8051 - 107s/epoch - 686ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 106s - loss: 0.1671 - iou_score: 0.7249 - f1-score: 0.8320 - val_loss: 0.2064 - val_iou_score: 0.6911 - val_f1-score: 0.7941 - 106s/epoch - 680ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 106s - loss: 0.1659 - iou_score: 0.7263 - f1-score: 0.8335 - val_loss: 0.1964 - val_iou_score: 0.7026 - val_f1-score: 0.8035 - 106s/epoch - 681ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 107s - loss: 0.1631 - iou_score: 0.7294 - f1-score: 0.8350 - val_loss: 0.1920 - val_iou_score: 0.7045 - val_f1-score: 0.8059 - 107s/epoch - 687ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 106s - loss: 0.1623 - iou_score: 0.7302 - f1-score: 0.8358 - val_loss: 0.1884 - val_iou_score: 0.7121 - val_f1-score: 0.8117 - 106s/epoch - 679ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 107s - loss: 0.1590 - iou_score: 0.7361 - f1-score: 0.8405 - val_loss: 0.2052 - val_iou_score: 0.6895 - val_f1-score: 0.7935 - 107s/epoch - 684ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 107s - loss: 0.1584 - iou_score: 0.7373 - f1-score: 0.8412 - val_loss: 0.1948 - val_iou_score: 0.7028 - val_f1-score: 0.8061 - 107s/epoch - 683ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 107s - loss: 0.1530 - iou_score: 0.7439 - f1-score: 0.8460 - val_loss: 0.1832 - val_iou_score: 0.7171 - val_f1-score: 0.8164 - 107s/epoch - 686ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 107s - loss: 0.1527 - iou_score: 0.7455 - f1-score: 0.8471 - val_loss: 0.1809 - val_iou_score: 0.7197 - val_f1-score: 0.8197 - 107s/epoch - 688ms/step\n",
      "2023/09/29 02:49:25 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/29 02:49:58 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpwre3zs0m/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/29 02:49:58 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 02:49:58 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/29 02:49:58 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 149\n",
      "Created version '149' of model 'fpn'.\n",
      "job end\n",
      "2023-09-29 02:50:31.640034: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 02:50:32.038846: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 02:50:32.038884: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 02:50:32.038890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/29 02:50:33 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 02:50:33 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fd4177b3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fd4177b3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fd4177b3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fd4177b3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 139s - loss: 0.2961 - iou_score: 0.5643 - f1-score: 0.7024 - val_loss: 0.3435 - val_iou_score: 0.5258 - val_f1-score: 0.6547 - 139s/epoch - 891ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 108s - loss: 0.2250 - iou_score: 0.6454 - f1-score: 0.7731 - val_loss: 0.2998 - val_iou_score: 0.5787 - val_f1-score: 0.6981 - 108s/epoch - 695ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 109s - loss: 0.2051 - iou_score: 0.6718 - f1-score: 0.7940 - val_loss: 0.2431 - val_iou_score: 0.6482 - val_f1-score: 0.7569 - 109s/epoch - 697ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 108s - loss: 0.1891 - iou_score: 0.6939 - f1-score: 0.8106 - val_loss: 0.2262 - val_iou_score: 0.6624 - val_f1-score: 0.7704 - 108s/epoch - 692ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 110s - loss: 0.1765 - iou_score: 0.7101 - f1-score: 0.8227 - val_loss: 0.2241 - val_iou_score: 0.6713 - val_f1-score: 0.7742 - 110s/epoch - 702ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 109s - loss: 0.1704 - iou_score: 0.7175 - f1-score: 0.8276 - val_loss: 0.2083 - val_iou_score: 0.6880 - val_f1-score: 0.7914 - 109s/epoch - 699ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 108s - loss: 0.1644 - iou_score: 0.7278 - f1-score: 0.8351 - val_loss: 0.2021 - val_iou_score: 0.6951 - val_f1-score: 0.7975 - 108s/epoch - 695ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 111s - loss: 0.1593 - iou_score: 0.7341 - f1-score: 0.8402 - val_loss: 0.1971 - val_iou_score: 0.7030 - val_f1-score: 0.8033 - 111s/epoch - 712ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 109s - loss: 0.1581 - iou_score: 0.7358 - f1-score: 0.8409 - val_loss: 0.2048 - val_iou_score: 0.6960 - val_f1-score: 0.7950 - 109s/epoch - 700ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 109s - loss: 0.1596 - iou_score: 0.7324 - f1-score: 0.8375 - val_loss: 0.2041 - val_iou_score: 0.6881 - val_f1-score: 0.7937 - 109s/epoch - 699ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 109s - loss: 0.1569 - iou_score: 0.7375 - f1-score: 0.8413 - val_loss: 0.1987 - val_iou_score: 0.7007 - val_f1-score: 0.8019 - 109s/epoch - 701ms/step\n",
      "2023/09/29 03:11:20 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/29 03:11:53 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpsszidpst/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/29 03:11:53 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 03:11:53 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/29 03:11:53 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 150\n",
      "Created version '150' of model 'fpn'.\n",
      "job end\n",
      "2023-09-29 03:12:26.511185: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 03:12:26.907921: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 03:12:26.907958: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 03:12:26.907963: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/29 03:12:28 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 03:12:28 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f4be77a7490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f4be77a7490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f4be77a7490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f4be77a7490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 138s - loss: 0.2901 - iou_score: 0.5711 - f1-score: 0.7086 - val_loss: 0.3341 - val_iou_score: 0.5437 - val_f1-score: 0.6639 - 138s/epoch - 884ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 106s - loss: 0.2223 - iou_score: 0.6506 - f1-score: 0.7777 - val_loss: 0.2905 - val_iou_score: 0.5895 - val_f1-score: 0.7081 - 106s/epoch - 681ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 109s - loss: 0.2038 - iou_score: 0.6740 - f1-score: 0.7956 - val_loss: 0.2570 - val_iou_score: 0.6315 - val_f1-score: 0.7426 - 109s/epoch - 697ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 108s - loss: 0.1906 - iou_score: 0.6920 - f1-score: 0.8091 - val_loss: 0.2334 - val_iou_score: 0.6552 - val_f1-score: 0.7636 - 108s/epoch - 693ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 108s - loss: 0.1829 - iou_score: 0.7017 - f1-score: 0.8163 - val_loss: 0.2230 - val_iou_score: 0.6682 - val_f1-score: 0.7755 - 108s/epoch - 691ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 108s - loss: 0.1702 - iou_score: 0.7176 - f1-score: 0.8279 - val_loss: 0.2144 - val_iou_score: 0.6802 - val_f1-score: 0.7847 - 108s/epoch - 690ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 110s - loss: 0.1696 - iou_score: 0.7213 - f1-score: 0.8295 - val_loss: 0.2074 - val_iou_score: 0.6888 - val_f1-score: 0.7922 - 110s/epoch - 702ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 108s - loss: 0.1584 - iou_score: 0.7357 - f1-score: 0.8406 - val_loss: 0.2086 - val_iou_score: 0.6908 - val_f1-score: 0.7922 - 108s/epoch - 689ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 109s - loss: 0.1567 - iou_score: 0.7389 - f1-score: 0.8431 - val_loss: 0.2071 - val_iou_score: 0.6917 - val_f1-score: 0.7925 - 109s/epoch - 696ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 109s - loss: 0.1550 - iou_score: 0.7390 - f1-score: 0.8420 - val_loss: 0.2115 - val_iou_score: 0.6789 - val_f1-score: 0.7860 - 109s/epoch - 697ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 108s - loss: 0.1538 - iou_score: 0.7411 - f1-score: 0.8437 - val_loss: 0.2316 - val_iou_score: 0.6568 - val_f1-score: 0.7689 - 108s/epoch - 694ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 110s - loss: 0.1514 - iou_score: 0.7456 - f1-score: 0.8480 - val_loss: 0.1995 - val_iou_score: 0.6988 - val_f1-score: 0.8006 - 110s/epoch - 704ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 109s - loss: 0.1493 - iou_score: 0.7486 - f1-score: 0.8496 - val_loss: 0.2207 - val_iou_score: 0.6694 - val_f1-score: 0.7802 - 109s/epoch - 696ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 108s - loss: 0.1520 - iou_score: 0.7439 - f1-score: 0.8459 - val_loss: 0.2063 - val_iou_score: 0.6913 - val_f1-score: 0.7929 - 108s/epoch - 695ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 109s - loss: 0.1486 - iou_score: 0.7501 - f1-score: 0.8502 - val_loss: 0.1928 - val_iou_score: 0.7066 - val_f1-score: 0.8075 - 109s/epoch - 697ms/step\n",
      "2023/09/29 03:40:56 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/29 03:41:29 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpf57lqmh3/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/29 03:41:29 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 03:41:29 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/29 03:41:29 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 151\n",
      "Created version '151' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!bash src/modeling/pretrained-models_aug_oversampling_max.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 11:13:52.977023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 11:13:53.672584: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 11:13:53.672629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 11:13:53.672636: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/29 11:13:56 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 11:13:56 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f6510553490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f6510553490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f6510553490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f6510553490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 148s - loss: 0.2985 - iou_score: 0.5761 - f1-score: 0.6992 - val_loss: 0.3206 - val_iou_score: 0.5528 - val_f1-score: 0.6781 - 148s/epoch - 951ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 109s - loss: 0.2262 - iou_score: 0.6573 - f1-score: 0.7737 - val_loss: 0.2479 - val_iou_score: 0.6424 - val_f1-score: 0.7515 - 109s/epoch - 698ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 111s - loss: 0.2059 - iou_score: 0.6817 - f1-score: 0.7939 - val_loss: 0.2124 - val_iou_score: 0.6804 - val_f1-score: 0.7881 - 111s/epoch - 712ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 110s - loss: 0.1910 - iou_score: 0.7007 - f1-score: 0.8083 - val_loss: 0.2022 - val_iou_score: 0.6886 - val_f1-score: 0.7942 - 110s/epoch - 703ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 114s - loss: 0.1842 - iou_score: 0.7088 - f1-score: 0.8151 - val_loss: 0.2087 - val_iou_score: 0.6825 - val_f1-score: 0.7899 - 114s/epoch - 730ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 115s - loss: 0.1790 - iou_score: 0.7153 - f1-score: 0.8190 - val_loss: 0.1905 - val_iou_score: 0.7056 - val_f1-score: 0.8088 - 115s/epoch - 739ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 115s - loss: 0.1735 - iou_score: 0.7233 - f1-score: 0.8253 - val_loss: 0.2040 - val_iou_score: 0.6867 - val_f1-score: 0.7955 - 115s/epoch - 736ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 115s - loss: 0.1722 - iou_score: 0.7259 - f1-score: 0.8280 - val_loss: 0.1843 - val_iou_score: 0.7142 - val_f1-score: 0.8161 - 115s/epoch - 740ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 115s - loss: 0.1676 - iou_score: 0.7314 - f1-score: 0.8323 - val_loss: 0.1810 - val_iou_score: 0.7172 - val_f1-score: 0.8192 - 115s/epoch - 736ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 116s - loss: 0.1657 - iou_score: 0.7333 - f1-score: 0.8332 - val_loss: 0.1762 - val_iou_score: 0.7216 - val_f1-score: 0.8219 - 116s/epoch - 746ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 110s - loss: 0.1647 - iou_score: 0.7335 - f1-score: 0.8334 - val_loss: 0.1723 - val_iou_score: 0.7293 - val_f1-score: 0.8278 - 110s/epoch - 707ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 108s - loss: 0.1596 - iou_score: 0.7411 - f1-score: 0.8392 - val_loss: 0.1714 - val_iou_score: 0.7285 - val_f1-score: 0.8283 - 108s/epoch - 690ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 115s - loss: 0.1571 - iou_score: 0.7450 - f1-score: 0.8420 - val_loss: 0.1768 - val_iou_score: 0.7227 - val_f1-score: 0.8241 - 115s/epoch - 737ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 116s - loss: 0.1555 - iou_score: 0.7470 - f1-score: 0.8434 - val_loss: 0.1901 - val_iou_score: 0.7050 - val_f1-score: 0.8099 - 116s/epoch - 741ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 115s - loss: 0.1585 - iou_score: 0.7424 - f1-score: 0.8408 - val_loss: 0.1709 - val_iou_score: 0.7298 - val_f1-score: 0.8294 - 115s/epoch - 735ms/step\n",
      "2023/09/29 11:43:39 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/29 11:44:14 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp40ogpmaz/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/29 11:44:14 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 11:44:14 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/29 11:44:14 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 152\n",
      "Created version '152' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py generator.auglist.geo=rdcrop \\\n",
    "                    generator.auglist.ker=gnoise \\\n",
    "                    generator.auglist.clim=0.14 \\\n",
    "                    generator.auglist.blim=0.2 \\\n",
    "                    generator.oversampling=True \\\n",
    "                    generator.oversampling_n=1 \\\n",
    "                    generator.oversampling_max=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 17:00:14.709041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 17:00:15.148096: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 17:00:15.148133: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 17:00:15.148139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/29 17:00:17 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 17:00:17 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f80987bf400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f80987bf400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f80987bf400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f80987bf400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 149s - loss: 0.2816 - iou_score: 0.5844 - f1-score: 0.7166 - val_loss: 0.2950 - val_iou_score: 0.5833 - val_f1-score: 0.7026 - 149s/epoch - 955ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 115s - loss: 0.2115 - iou_score: 0.6671 - f1-score: 0.7881 - val_loss: 0.2763 - val_iou_score: 0.6028 - val_f1-score: 0.7215 - 115s/epoch - 740ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 117s - loss: 0.1874 - iou_score: 0.6977 - f1-score: 0.8117 - val_loss: 0.2342 - val_iou_score: 0.6577 - val_f1-score: 0.7661 - 117s/epoch - 752ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 117s - loss: 0.1793 - iou_score: 0.7089 - f1-score: 0.8202 - val_loss: 0.2201 - val_iou_score: 0.6713 - val_f1-score: 0.7768 - 117s/epoch - 748ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 117s - loss: 0.1726 - iou_score: 0.7177 - f1-score: 0.8262 - val_loss: 0.2063 - val_iou_score: 0.6844 - val_f1-score: 0.7923 - 117s/epoch - 752ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 109s - loss: 0.1620 - iou_score: 0.7303 - f1-score: 0.8348 - val_loss: 0.1969 - val_iou_score: 0.7011 - val_f1-score: 0.8030 - 109s/epoch - 702ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 110s - loss: 0.1594 - iou_score: 0.7368 - f1-score: 0.8403 - val_loss: 0.1969 - val_iou_score: 0.6973 - val_f1-score: 0.8031 - 110s/epoch - 705ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 109s - loss: 0.1569 - iou_score: 0.7398 - f1-score: 0.8427 - val_loss: 0.1997 - val_iou_score: 0.6975 - val_f1-score: 0.8000 - 109s/epoch - 696ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 109s - loss: 0.1561 - iou_score: 0.7419 - f1-score: 0.8440 - val_loss: 0.1947 - val_iou_score: 0.7018 - val_f1-score: 0.8052 - 109s/epoch - 700ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 110s - loss: 0.1548 - iou_score: 0.7407 - f1-score: 0.8423 - val_loss: 0.1918 - val_iou_score: 0.7037 - val_f1-score: 0.8061 - 110s/epoch - 707ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 110s - loss: 0.1554 - iou_score: 0.7405 - f1-score: 0.8429 - val_loss: 0.1875 - val_iou_score: 0.7109 - val_f1-score: 0.8124 - 110s/epoch - 704ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 110s - loss: 0.1478 - iou_score: 0.7521 - f1-score: 0.8512 - val_loss: 0.2399 - val_iou_score: 0.6568 - val_f1-score: 0.7597 - 110s/epoch - 705ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 110s - loss: 0.1469 - iou_score: 0.7531 - f1-score: 0.8515 - val_loss: 0.1910 - val_iou_score: 0.7078 - val_f1-score: 0.8097 - 110s/epoch - 703ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 110s - loss: 0.1455 - iou_score: 0.7556 - f1-score: 0.8536 - val_loss: 0.1854 - val_iou_score: 0.7132 - val_f1-score: 0.8140 - 110s/epoch - 704ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 111s - loss: 0.1417 - iou_score: 0.7616 - f1-score: 0.8581 - val_loss: 0.1914 - val_iou_score: 0.7069 - val_f1-score: 0.8092 - 111s/epoch - 710ms/step\n",
      "2023/09/29 17:29:08 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/29 17:29:43 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpl7n3hpb_/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/29 17:29:43 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 17:29:43 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/29 17:29:43 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 154\n",
      "Created version '154' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py generator.auglist.geo=rdcrop \\\n",
    "                    generator.auglist.ker=gnoise \\\n",
    "                    generator.auglist.clim=0.14 \\\n",
    "                    generator.auglist.blim=0.2 \\\n",
    "                    generator.oversampling=True \\\n",
    "                    generator.oversampling_n=3 \\\n",
    "                    generator.oversampling_max=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-02 13:14:13.894508: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-02 13:14:14.310186: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-02 13:14:14.310224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-02 13:14:14.310229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/10/02 13:14:16 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/10/02 13:14:16 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9b11bab5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9b11bab5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9b11bab5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9b11bab5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 151s - loss: 0.2872 - iou_score: 0.5942 - f1-score: 0.7115 - val_loss: 0.3019 - val_iou_score: 0.5668 - val_f1-score: 0.6964 - 151s/epoch - 969ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 118s - loss: 0.2213 - iou_score: 0.6665 - f1-score: 0.7787 - val_loss: 0.3033 - val_iou_score: 0.5799 - val_f1-score: 0.6951 - 118s/epoch - 756ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 116s - loss: 0.2050 - iou_score: 0.6854 - f1-score: 0.7943 - val_loss: 0.2242 - val_iou_score: 0.6670 - val_f1-score: 0.7759 - 116s/epoch - 746ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 117s - loss: 0.1928 - iou_score: 0.7014 - f1-score: 0.8065 - val_loss: 0.2167 - val_iou_score: 0.6702 - val_f1-score: 0.7796 - 117s/epoch - 750ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 117s - loss: 0.1877 - iou_score: 0.7062 - f1-score: 0.8110 - val_loss: 0.2035 - val_iou_score: 0.6858 - val_f1-score: 0.7948 - 117s/epoch - 748ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 111s - loss: 0.1834 - iou_score: 0.7121 - f1-score: 0.8148 - val_loss: 0.1948 - val_iou_score: 0.6972 - val_f1-score: 0.8046 - 111s/epoch - 710ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 107s - loss: 0.1787 - iou_score: 0.7178 - f1-score: 0.8191 - val_loss: 0.1880 - val_iou_score: 0.7079 - val_f1-score: 0.8111 - 107s/epoch - 686ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 108s - loss: 0.1707 - iou_score: 0.7278 - f1-score: 0.8270 - val_loss: 0.2004 - val_iou_score: 0.6938 - val_f1-score: 0.8003 - 108s/epoch - 693ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 109s - loss: 0.1681 - iou_score: 0.7330 - f1-score: 0.8315 - val_loss: 0.1816 - val_iou_score: 0.7161 - val_f1-score: 0.8182 - 109s/epoch - 698ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 107s - loss: 0.1695 - iou_score: 0.7302 - f1-score: 0.8291 - val_loss: 0.1813 - val_iou_score: 0.7154 - val_f1-score: 0.8171 - 107s/epoch - 688ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 109s - loss: 0.1684 - iou_score: 0.7312 - f1-score: 0.8301 - val_loss: 0.1827 - val_iou_score: 0.7157 - val_f1-score: 0.8176 - 109s/epoch - 701ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 112s - loss: 0.1630 - iou_score: 0.7390 - f1-score: 0.8363 - val_loss: 0.1812 - val_iou_score: 0.7164 - val_f1-score: 0.8186 - 112s/epoch - 720ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 110s - loss: 0.1657 - iou_score: 0.7349 - f1-score: 0.8328 - val_loss: 0.1883 - val_iou_score: 0.7059 - val_f1-score: 0.8124 - 110s/epoch - 707ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 112s - loss: 0.1700 - iou_score: 0.7290 - f1-score: 0.8287 - val_loss: 0.1871 - val_iou_score: 0.7072 - val_f1-score: 0.8125 - 112s/epoch - 715ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 110s - loss: 0.1637 - iou_score: 0.7388 - f1-score: 0.8362 - val_loss: 0.1811 - val_iou_score: 0.7172 - val_f1-score: 0.8196 - 110s/epoch - 708ms/step\n",
      "2023/10/02 13:43:37 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/10/02 13:44:12 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpr3m6a5qz/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/10/02 13:44:12 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/10/02 13:44:12 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/10/02 13:44:12 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 158\n",
      "Created version '158' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py generator.auglist.geo=upcrop \\\n",
    "                    generator.auglist.ker=gnoise \\\n",
    "                    generator.auglist.clim=0.14 \\\n",
    "                    generator.auglist.blim=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-29 20:06:47.135933: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 20:06:47.536196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 20:06:47.536233: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-29 20:06:47.536238: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/09/29 20:06:49 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 20:06:49 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f7e0efdf490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f7e0efdf490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f7e0efdf490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f7e0efdf490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "621/621 - 451s - loss: 0.2653 - iou_score: 0.6196 - f1-score: 0.7343 - val_loss: 0.2223 - val_iou_score: 0.6664 - val_f1-score: 0.7777 - 451s/epoch - 727ms/step\n",
      "Epoch 2/15\n",
      "621/621 - 421s - loss: 0.2163 - iou_score: 0.6756 - f1-score: 0.7837 - val_loss: 0.2145 - val_iou_score: 0.6753 - val_f1-score: 0.7855 - 421s/epoch - 678ms/step\n",
      "Epoch 3/15\n",
      "621/621 - 421s - loss: 0.2007 - iou_score: 0.6949 - f1-score: 0.7993 - val_loss: 0.1867 - val_iou_score: 0.7097 - val_f1-score: 0.8133 - 421s/epoch - 678ms/step\n",
      "Epoch 4/15\n",
      "621/621 - 421s - loss: 0.1926 - iou_score: 0.7049 - f1-score: 0.8073 - val_loss: 0.1922 - val_iou_score: 0.7036 - val_f1-score: 0.8078 - 421s/epoch - 678ms/step\n",
      "Epoch 5/15\n",
      "621/621 - 421s - loss: 0.1858 - iou_score: 0.7136 - f1-score: 0.8140 - val_loss: 0.1763 - val_iou_score: 0.7227 - val_f1-score: 0.8237 - 421s/epoch - 678ms/step\n",
      "Epoch 6/15\n",
      "621/621 - 422s - loss: 0.1844 - iou_score: 0.7157 - f1-score: 0.8152 - val_loss: 0.1797 - val_iou_score: 0.7182 - val_f1-score: 0.8203 - 422s/epoch - 680ms/step\n",
      "Epoch 7/15\n",
      "621/621 - 422s - loss: 0.1786 - iou_score: 0.7225 - f1-score: 0.8213 - val_loss: 0.1799 - val_iou_score: 0.7177 - val_f1-score: 0.8201 - 422s/epoch - 679ms/step\n",
      "Epoch 8/15\n",
      "621/621 - 429s - loss: 0.1757 - iou_score: 0.7261 - f1-score: 0.8243 - val_loss: 0.1695 - val_iou_score: 0.7315 - val_f1-score: 0.8305 - 429s/epoch - 690ms/step\n",
      "Epoch 9/15\n",
      "621/621 - 420s - loss: 0.1691 - iou_score: 0.7347 - f1-score: 0.8307 - val_loss: 0.1770 - val_iou_score: 0.7220 - val_f1-score: 0.8230 - 420s/epoch - 677ms/step\n",
      "Epoch 10/15\n",
      "621/621 - 420s - loss: 0.1721 - iou_score: 0.7318 - f1-score: 0.8277 - val_loss: 0.1740 - val_iou_score: 0.7257 - val_f1-score: 0.8260 - 420s/epoch - 676ms/step\n",
      "Epoch 11/15\n",
      "621/621 - 425s - loss: 0.1651 - iou_score: 0.7402 - f1-score: 0.8346 - val_loss: 0.1766 - val_iou_score: 0.7208 - val_f1-score: 0.8234 - 425s/epoch - 685ms/step\n",
      "2023/09/29 21:25:14 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/09/29 21:25:47 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpd6lfuv2i/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/09/29 21:25:47 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/09/29 21:25:47 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/09/29 21:25:47 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 156\n",
      "Created version '156' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py generator.auglist.geo=rdcrop \\\n",
    "                    generator.auglist.ker=gnoise \\\n",
    "                    generator.auglist.clim=0.14 \\\n",
    "                    generator.auglist.blim=0.2 \\\n",
    "                    data.input_height=256 \\\n",
    "                    data.input_width=512 \\\n",
    "                    generator.batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-02 17:48:28.907747: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-02 17:48:29.357354: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-02 17:48:29.357390: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-02 17:48:29.357395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/10/02 17:48:31 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/10/02 17:48:31 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9dc4993490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9dc4993490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9dc4993490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9dc4993490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 151s - loss: 0.3014 - iou_score: 0.5791 - f1-score: 0.6972 - val_loss: 0.2903 - val_iou_score: 0.5838 - val_f1-score: 0.7085 - 151s/epoch - 968ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 127s - loss: 0.2292 - iou_score: 0.6562 - f1-score: 0.7703 - val_loss: 0.2588 - val_iou_score: 0.6268 - val_f1-score: 0.7393 - 127s/epoch - 813ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 119s - loss: 0.2094 - iou_score: 0.6812 - f1-score: 0.7905 - val_loss: 0.2225 - val_iou_score: 0.6698 - val_f1-score: 0.7779 - 119s/epoch - 760ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 118s - loss: 0.1963 - iou_score: 0.6977 - f1-score: 0.8035 - val_loss: 0.2041 - val_iou_score: 0.6870 - val_f1-score: 0.7929 - 118s/epoch - 755ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 114s - loss: 0.1872 - iou_score: 0.7079 - f1-score: 0.8118 - val_loss: 0.1980 - val_iou_score: 0.6931 - val_f1-score: 0.8002 - 114s/epoch - 731ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 111s - loss: 0.1833 - iou_score: 0.7116 - f1-score: 0.8147 - val_loss: 0.1864 - val_iou_score: 0.7083 - val_f1-score: 0.8127 - 111s/epoch - 712ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 118s - loss: 0.1786 - iou_score: 0.7198 - f1-score: 0.8211 - val_loss: 0.1806 - val_iou_score: 0.7171 - val_f1-score: 0.8190 - 118s/epoch - 756ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 116s - loss: 0.1718 - iou_score: 0.7287 - f1-score: 0.8281 - val_loss: 0.1821 - val_iou_score: 0.7160 - val_f1-score: 0.8184 - 116s/epoch - 745ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 117s - loss: 0.1701 - iou_score: 0.7297 - f1-score: 0.8288 - val_loss: 0.1786 - val_iou_score: 0.7201 - val_f1-score: 0.8214 - 117s/epoch - 747ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 116s - loss: 0.1748 - iou_score: 0.7221 - f1-score: 0.8226 - val_loss: 0.1878 - val_iou_score: 0.7047 - val_f1-score: 0.8101 - 116s/epoch - 741ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 116s - loss: 0.1696 - iou_score: 0.7295 - f1-score: 0.8285 - val_loss: 0.1770 - val_iou_score: 0.7223 - val_f1-score: 0.8231 - 116s/epoch - 743ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 110s - loss: 0.1657 - iou_score: 0.7354 - f1-score: 0.8334 - val_loss: 0.1740 - val_iou_score: 0.7244 - val_f1-score: 0.8255 - 110s/epoch - 703ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 111s - loss: 0.1613 - iou_score: 0.7403 - f1-score: 0.8370 - val_loss: 0.1694 - val_iou_score: 0.7322 - val_f1-score: 0.8312 - 111s/epoch - 713ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 110s - loss: 0.1638 - iou_score: 0.7375 - f1-score: 0.8350 - val_loss: 0.1723 - val_iou_score: 0.7279 - val_f1-score: 0.8274 - 110s/epoch - 704ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 114s - loss: 0.1603 - iou_score: 0.7434 - f1-score: 0.8396 - val_loss: 0.1674 - val_iou_score: 0.7347 - val_f1-score: 0.8332 - 114s/epoch - 733ms/step\n",
      "2023/10/02 18:19:02 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/10/02 18:19:40 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp_6c1es6_/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/10/02 18:19:40 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/10/02 18:19:40 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/10/02 18:19:40 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 162\n",
      "Created version '162' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py generator.auglist.geo=rdcrop \\\n",
    "                    generator.auglist.ker=gnoise \\\n",
    "                    generator.auglist.clim=0.14 \\\n",
    "                    generator.auglist.blim=0.2 \\\n",
    "                    generator.attention_mask=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-02 18:32:58.467228: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-02 18:32:59.152938: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-02 18:32:59.152997: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-02 18:32:59.153005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/10/02 18:33:01 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/10/02 18:33:01 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fc6035df5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fc6035df5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fc6035df5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fc6035df5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 142s - loss: 0.2822 - iou_score: 0.5840 - f1-score: 0.7158 - val_loss: 0.3189 - val_iou_score: 0.5656 - val_f1-score: 0.6799 - 142s/epoch - 912ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 112s - loss: 0.2100 - iou_score: 0.6692 - f1-score: 0.7897 - val_loss: 0.2881 - val_iou_score: 0.5976 - val_f1-score: 0.7101 - 112s/epoch - 715ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 112s - loss: 0.1908 - iou_score: 0.6937 - f1-score: 0.8088 - val_loss: 0.2423 - val_iou_score: 0.6441 - val_f1-score: 0.7583 - 112s/epoch - 715ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 112s - loss: 0.1775 - iou_score: 0.7121 - f1-score: 0.8225 - val_loss: 0.2084 - val_iou_score: 0.6843 - val_f1-score: 0.7885 - 112s/epoch - 717ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 112s - loss: 0.1703 - iou_score: 0.7209 - f1-score: 0.8289 - val_loss: 0.2013 - val_iou_score: 0.6939 - val_f1-score: 0.7973 - 112s/epoch - 718ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 109s - loss: 0.1627 - iou_score: 0.7300 - f1-score: 0.8350 - val_loss: 0.1981 - val_iou_score: 0.6989 - val_f1-score: 0.8017 - 109s/epoch - 698ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 110s - loss: 0.1593 - iou_score: 0.7370 - f1-score: 0.8402 - val_loss: 0.2031 - val_iou_score: 0.6926 - val_f1-score: 0.7969 - 110s/epoch - 706ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 107s - loss: 0.1585 - iou_score: 0.7381 - f1-score: 0.8410 - val_loss: 0.1916 - val_iou_score: 0.7053 - val_f1-score: 0.8087 - 107s/epoch - 688ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 111s - loss: 0.1575 - iou_score: 0.7383 - f1-score: 0.8411 - val_loss: 0.2019 - val_iou_score: 0.6953 - val_f1-score: 0.7980 - 111s/epoch - 713ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 109s - loss: 0.1524 - iou_score: 0.7449 - f1-score: 0.8457 - val_loss: 0.2122 - val_iou_score: 0.6819 - val_f1-score: 0.7856 - 109s/epoch - 699ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 107s - loss: 0.1515 - iou_score: 0.7474 - f1-score: 0.8476 - val_loss: 0.1858 - val_iou_score: 0.7145 - val_f1-score: 0.8141 - 107s/epoch - 687ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 110s - loss: 0.1471 - iou_score: 0.7536 - f1-score: 0.8521 - val_loss: 0.1893 - val_iou_score: 0.7072 - val_f1-score: 0.8103 - 110s/epoch - 707ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 108s - loss: 0.1434 - iou_score: 0.7576 - f1-score: 0.8547 - val_loss: 0.1862 - val_iou_score: 0.7127 - val_f1-score: 0.8144 - 108s/epoch - 690ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 109s - loss: 0.1463 - iou_score: 0.7541 - f1-score: 0.8525 - val_loss: 0.1887 - val_iou_score: 0.7110 - val_f1-score: 0.8107 - 109s/epoch - 701ms/step\n",
      "2023/10/02 18:59:29 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/10/02 19:00:02 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpkhs78jve/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/10/02 19:00:02 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/10/02 19:00:02 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/10/02 19:00:02 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 163\n",
      "Created version '163' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py generator.auglist.geo=rdcrop \\\n",
    "                    generator.auglist.ker=gnoise \\\n",
    "                    generator.auglist.clim=0.14 \\\n",
    "                    generator.auglist.blim=0.2 \\\n",
    "                    generator.attention_mask=True \\\n",
    "                    generator.oversampling=True \\\n",
    "                    generator.oversampling_n=3 \\\n",
    "                    generator.oversampling_max=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-04 11:23:25.443997: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-04 11:23:25.895371: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-04 11:23:25.895412: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-04 11:23:25.895418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "2023/10/04 11:23:27 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/10/04 11:23:27 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5cd17d7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f5cd17d7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5cd17d7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNI [tensorflow] 6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f5cd17d7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "156/156 - 144s - loss: 0.3024 - iou_score: 0.5775 - f1-score: 0.6965 - val_loss: 0.3037 - val_iou_score: 0.5705 - val_f1-score: 0.6952 - 144s/epoch - 926ms/step\n",
      "Epoch 2/15\n",
      "156/156 - 113s - loss: 0.2320 - iou_score: 0.6532 - f1-score: 0.7681 - val_loss: 0.2713 - val_iou_score: 0.6211 - val_f1-score: 0.7271 - 113s/epoch - 723ms/step\n",
      "Epoch 3/15\n",
      "156/156 - 113s - loss: 0.2086 - iou_score: 0.6818 - f1-score: 0.7907 - val_loss: 0.2264 - val_iou_score: 0.6653 - val_f1-score: 0.7737 - 113s/epoch - 722ms/step\n",
      "Epoch 4/15\n",
      "156/156 - 113s - loss: 0.1976 - iou_score: 0.6949 - f1-score: 0.8017 - val_loss: 0.2034 - val_iou_score: 0.6859 - val_f1-score: 0.7928 - 113s/epoch - 727ms/step\n",
      "Epoch 5/15\n",
      "156/156 - 114s - loss: 0.1898 - iou_score: 0.7045 - f1-score: 0.8089 - val_loss: 0.2686 - val_iou_score: 0.6079 - val_f1-score: 0.7299 - 114s/epoch - 732ms/step\n",
      "Epoch 6/15\n",
      "156/156 - 111s - loss: 0.1921 - iou_score: 0.7020 - f1-score: 0.8065 - val_loss: 0.1926 - val_iou_score: 0.7010 - val_f1-score: 0.8065 - 111s/epoch - 714ms/step\n",
      "Epoch 7/15\n",
      "156/156 - 111s - loss: 0.1825 - iou_score: 0.7153 - f1-score: 0.8171 - val_loss: 0.1857 - val_iou_score: 0.7105 - val_f1-score: 0.8140 - 111s/epoch - 713ms/step\n",
      "Epoch 8/15\n",
      "156/156 - 110s - loss: 0.1759 - iou_score: 0.7234 - f1-score: 0.8240 - val_loss: 0.1859 - val_iou_score: 0.7134 - val_f1-score: 0.8148 - 110s/epoch - 707ms/step\n",
      "Epoch 9/15\n",
      "156/156 - 111s - loss: 0.1723 - iou_score: 0.7273 - f1-score: 0.8269 - val_loss: 0.1780 - val_iou_score: 0.7215 - val_f1-score: 0.8220 - 111s/epoch - 715ms/step\n",
      "Epoch 10/15\n",
      "156/156 - 111s - loss: 0.1702 - iou_score: 0.7296 - f1-score: 0.8285 - val_loss: 0.1779 - val_iou_score: 0.7180 - val_f1-score: 0.8205 - 111s/epoch - 712ms/step\n",
      "Epoch 11/15\n",
      "156/156 - 112s - loss: 0.1682 - iou_score: 0.7318 - f1-score: 0.8302 - val_loss: 0.1828 - val_iou_score: 0.7122 - val_f1-score: 0.8168 - 112s/epoch - 720ms/step\n",
      "Epoch 12/15\n",
      "156/156 - 107s - loss: 0.1654 - iou_score: 0.7359 - f1-score: 0.8337 - val_loss: 0.1716 - val_iou_score: 0.7272 - val_f1-score: 0.8278 - 107s/epoch - 686ms/step\n",
      "Epoch 13/15\n",
      "156/156 - 112s - loss: 0.1629 - iou_score: 0.7390 - f1-score: 0.8361 - val_loss: 0.1688 - val_iou_score: 0.7328 - val_f1-score: 0.8318 - 112s/epoch - 717ms/step\n",
      "Epoch 14/15\n",
      "156/156 - 111s - loss: 0.1618 - iou_score: 0.7397 - f1-score: 0.8361 - val_loss: 0.1847 - val_iou_score: 0.7132 - val_f1-score: 0.8142 - 111s/epoch - 709ms/step\n",
      "Epoch 15/15\n",
      "156/156 - 111s - loss: 0.1605 - iou_score: 0.7426 - f1-score: 0.8391 - val_loss: 0.1717 - val_iou_score: 0.7282 - val_f1-score: 0.8289 - 111s/epoch - 714ms/step\n",
      "2023/10/04 11:52:11 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNI [absl] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 175). These functions will not be directly callable after loading.\n",
      "2023/10/04 11:52:45 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpgfq3bh87/model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/10/04 11:52:45 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/10/04 11:52:45 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'fpn' already exists. Creating a new version of this model...\n",
      "2023/10/04 11:52:45 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: fpn, version 166\n",
      "Created version '166' of model 'fpn'.\n",
      "job end\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/modeling/pretrained-models_aug.py generator.auglist.geo=rdcrop \\\n",
    "                    generator.auglist.ker=gnoise \\\n",
    "                    generator.auglist.clim=0.14 \\\n",
    "                    generator.auglist.blim=0.2 \\\n",
    "                    generator.attention_mask_size=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 15:23:34.868505: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-05 15:23:35.364955: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-05 15:23:35.364994: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-05 15:23:35.365000: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "2023-10-05 15:23:36.502274: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "[2023-10-05 15:23:37,274][tensorflow][WARNING] - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "[2023-10-05 15:23:37,274][tensorflow][WARNING] - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "[2023-10-05 15:23:47,111][absl][WARNING] - Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n",
      "[2023-10-05 15:23:49,203][absl][INFO] - Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n",
      "2023-10-05 15:23:49.293275: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-10-05 15:23:49.293299: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} src/deployment/convert_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEPLOYMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} src/deployment/extract_images.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet8",
   "language": "python",
   "name": "projet8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
